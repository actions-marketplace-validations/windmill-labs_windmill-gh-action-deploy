{"version":3,"file":"index.js","sources":["../webpack://windmill-gh-action/./lib/main.js","../webpack://windmill-gh-action/./node_modules/@actions/core/lib/command.js","../webpack://windmill-gh-action/./node_modules/@actions/core/lib/core.js","../webpack://windmill-gh-action/./node_modules/@actions/core/lib/file-command.js","../webpack://windmill-gh-action/./node_modules/@actions/core/lib/oidc-utils.js","../webpack://windmill-gh-action/./node_modules/@actions/core/lib/utils.js","../webpack://windmill-gh-action/./node_modules/@actions/http-client/auth.js","../webpack://windmill-gh-action/./node_modules/@actions/http-client/index.js","../webpack://windmill-gh-action/./node_modules/@actions/http-client/proxy.js","../webpack://windmill-gh-action/./node_modules/chownr/chownr.js","../webpack://windmill-gh-action/./node_modules/fetch-blob/file.js","../webpack://windmill-gh-action/external \"node:fs\"","../webpack://windmill-gh-action/external \"node:path\"","../webpack://windmill-gh-action/./node_modules/fetch-blob/from.js","../webpack://windmill-gh-action/./node_modules/fetch-blob/index.js","../webpack://windmill-gh-action/./node_modules/formdata-polyfill/esm.min.js","../webpack://windmill-gh-action/./node_modules/fs-minipass/index.js","../webpack://windmill-gh-action/./node_modules/minipass/index.js","../webpack://windmill-gh-action/./node_modules/minizlib/constants.js","../webpack://windmill-gh-action/./node_modules/minizlib/index.js","../webpack://windmill-gh-action/./node_modules/mkdirp/index.js","../webpack://windmill-gh-action/./node_modules/mkdirp/lib/find-made.js","../webpack://windmill-gh-action/./node_modules/mkdirp/lib/mkdirp-manual.js","../webpack://windmill-gh-action/./node_modules/mkdirp/lib/mkdirp-native.js","../webpack://windmill-gh-action/./node_modules/mkdirp/lib/opts-arg.js","../webpack://windmill-gh-action/./node_modules/mkdirp/lib/path-arg.js","../webpack://windmill-gh-action/./node_modules/mkdirp/lib/use-native.js","../webpack://windmill-gh-action/./node_modules/node-domexception/index.js","../webpack://windmill-gh-action/external \"node:http\"","../webpack://windmill-gh-action/external \"node:https\"","../webpack://windmill-gh-action/external \"node:zlib\"","../webpack://windmill-gh-action/external \"node:stream\"","../webpack://windmill-gh-action/external \"node:buffer\"","../webpack://windmill-gh-action/./node_modules/data-uri-to-buffer/dist/index.js","../webpack://windmill-gh-action/external \"node:util\"","../webpack://windmill-gh-action/./node_modules/node-fetch/src/errors/base.js","../webpack://windmill-gh-action/./node_modules/node-fetch/src/errors/fetch-error.js","../webpack://windmill-gh-action/./node_modules/node-fetch/src/utils/is.js","../webpack://windmill-gh-action/./node_modules/node-fetch/src/body.js","../webpack://windmill-gh-action/./node_modules/node-fetch/src/headers.js","../webpack://windmill-gh-action/./node_modules/node-fetch/src/utils/is-redirect.js","../webpack://windmill-gh-action/./node_modules/node-fetch/src/response.js","../webpack://windmill-gh-action/external \"node:url\"","../webpack://windmill-gh-action/./node_modules/node-fetch/src/utils/get-search.js","../webpack://windmill-gh-action/external \"node:net\"","../webpack://windmill-gh-action/./node_modules/node-fetch/src/utils/referrer.js","../webpack://windmill-gh-action/./node_modules/node-fetch/src/request.js","../webpack://windmill-gh-action/./node_modules/node-fetch/src/errors/abort-error.js","../webpack://windmill-gh-action/./node_modules/node-fetch/src/index.js","../webpack://windmill-gh-action/./node_modules/tar/index.js","../webpack://windmill-gh-action/./node_modules/tar/lib/create.js","../webpack://windmill-gh-action/./node_modules/tar/lib/extract.js","../webpack://windmill-gh-action/./node_modules/tar/lib/get-write-flag.js","../webpack://windmill-gh-action/./node_modules/tar/lib/header.js","../webpack://windmill-gh-action/./node_modules/tar/lib/high-level-opt.js","../webpack://windmill-gh-action/./node_modules/tar/lib/large-numbers.js","../webpack://windmill-gh-action/./node_modules/tar/lib/list.js","../webpack://windmill-gh-action/./node_modules/tar/lib/mkdir.js","../webpack://windmill-gh-action/./node_modules/tar/lib/mode-fix.js","../webpack://windmill-gh-action/./node_modules/tar/lib/normalize-unicode.js","../webpack://windmill-gh-action/./node_modules/tar/lib/normalize-windows-path.js","../webpack://windmill-gh-action/./node_modules/tar/lib/pack.js","../webpack://windmill-gh-action/./node_modules/tar/lib/parse.js","../webpack://windmill-gh-action/./node_modules/tar/lib/path-reservations.js","../webpack://windmill-gh-action/./node_modules/tar/lib/pax.js","../webpack://windmill-gh-action/./node_modules/tar/lib/read-entry.js","../webpack://windmill-gh-action/./node_modules/tar/lib/replace.js","../webpack://windmill-gh-action/./node_modules/tar/lib/strip-absolute-path.js","../webpack://windmill-gh-action/./node_modules/tar/lib/strip-trailing-slashes.js","../webpack://windmill-gh-action/./node_modules/tar/lib/types.js","../webpack://windmill-gh-action/./node_modules/tar/lib/unpack.js","../webpack://windmill-gh-action/./node_modules/tar/lib/update.js","../webpack://windmill-gh-action/./node_modules/tar/lib/warn-mixin.js","../webpack://windmill-gh-action/./node_modules/tar/lib/winchars.js","../webpack://windmill-gh-action/./node_modules/tar/lib/write-entry.js","../webpack://windmill-gh-action/./node_modules/tunnel/index.js","../webpack://windmill-gh-action/./node_modules/tunnel/lib/tunnel.js","../webpack://windmill-gh-action/./node_modules/web-streams-polyfill/dist/ponyfill.es2018.js","../webpack://windmill-gh-action/./node_modules/yallist/iterator.js","../webpack://windmill-gh-action/./node_modules/yallist/yallist.js","../webpack://windmill-gh-action/./node_modules/fetch-blob/streams.cjs","../webpack://windmill-gh-action/external \"assert\"","../webpack://windmill-gh-action/external \"buffer\"","../webpack://windmill-gh-action/external \"crypto\"","../webpack://windmill-gh-action/external \"events\"","../webpack://windmill-gh-action/external \"fs\"","../webpack://windmill-gh-action/external \"fs/promises\"","../webpack://windmill-gh-action/external \"http\"","../webpack://windmill-gh-action/external \"https\"","../webpack://windmill-gh-action/external \"net\"","../webpack://windmill-gh-action/external \"node:process\"","../webpack://windmill-gh-action/external \"node:stream/web\"","../webpack://windmill-gh-action/external \"os\"","../webpack://windmill-gh-action/external \"path\"","../webpack://windmill-gh-action/external \"stream\"","../webpack://windmill-gh-action/external \"string_decoder\"","../webpack://windmill-gh-action/external \"tls\"","../webpack://windmill-gh-action/external \"util\"","../webpack://windmill-gh-action/external \"worker_threads\"","../webpack://windmill-gh-action/external \"zlib\"","../webpack://windmill-gh-action/webpack/bootstrap","../webpack://windmill-gh-action/webpack/runtime/define property getters","../webpack://windmill-gh-action/webpack/runtime/ensure chunk","../webpack://windmill-gh-action/webpack/runtime/get javascript chunk filename","../webpack://windmill-gh-action/webpack/runtime/hasOwnProperty shorthand","../webpack://windmill-gh-action/webpack/runtime/make namespace object","../webpack://windmill-gh-action/webpack/runtime/compat","../webpack://windmill-gh-action/webpack/runtime/require chunk loading","../webpack://windmill-gh-action/webpack/startup"],"sourcesContent":["\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst core = __importStar(require(\"@actions/core\"));\nconst fs = __importStar(require(\"fs/promises\"));\nconst tar = __importStar(require(\"tar\"));\nconst node_fetch_1 = __importDefault(require(\"node-fetch\"));\nfunction run() {\n    var _a, _b, _c;\n    return __awaiter(this, void 0, void 0, function* () {\n        try {\n            const dryRun = core.getInput('dry_run') === 'true';\n            const inputDir = (_a = core.getInput('input_dir')) !== null && _a !== void 0 ? _a : './';\n            const windmillToken = core.getInput('windmill_token');\n            const windmillWorkspace = core.getInput('windmill_workspace');\n            const windmillUrl = (_b = core.getInput('windmill_url')) !== null && _b !== void 0 ? _b : 'https://alpha.windmill.dev';\n            const scriptName = (_c = core.getInput('script_name')) !== null && _c !== void 0 ? _c : 'u/bot/import_workspace_from_tarball';\n            core.info(`dryRun: ${dryRun}`);\n            core.info(`inputDir: ${inputDir}}`);\n            core.info(`windmillWorkspace: ${windmillWorkspace}`);\n            core.info(`windmillUrl: ${windmillUrl}`);\n            core.info(`scriptName: ${scriptName}`);\n            yield tar.c({\n                gzip: false,\n                file: 'tarball.tar'\n            }, [inputDir]);\n            core.info('tarball has been created');\n            const content = yield fs.readFile('./tarball.tar', {\n                encoding: 'base64'\n            });\n            const settings = {\n                method: 'POST',\n                headers: {\n                    Accept: 'application/json',\n                    'Content-Type': 'application/json',\n                    Authorization: `Bearer ${windmillToken}`\n                },\n                body: JSON.stringify({\n                    tarball: content\n                })\n            };\n            const fetchResponse = yield (0, node_fetch_1.default)(`${windmillUrl}/api/w/${windmillWorkspace}/jobs/run/p/${scriptName}`, settings);\n            const output = yield fetchResponse.text();\n            core.info(`script run uuid: ${output}`);\n        }\n        catch (error) {\n            if (error instanceof Error) {\n                core.error(error.message);\n                core.setFailed(error.message);\n            }\n        }\n    });\n}\nrun();\n//# sourceMappingURL=main.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issue = exports.issueCommand = void 0;\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\n/**\n * Commands\n *\n * Command Format:\n *   ::name key=value,key=value::message\n *\n * Examples:\n *   ::warning::This is the message\n *   ::set-env name=MY_VAR::some value\n */\nfunction issueCommand(command, properties, message) {\n    const cmd = new Command(command, properties, message);\n    process.stdout.write(cmd.toString() + os.EOL);\n}\nexports.issueCommand = issueCommand;\nfunction issue(name, message = '') {\n    issueCommand(name, {}, message);\n}\nexports.issue = issue;\nconst CMD_STRING = '::';\nclass Command {\n    constructor(command, properties, message) {\n        if (!command) {\n            command = 'missing.command';\n        }\n        this.command = command;\n        this.properties = properties;\n        this.message = message;\n    }\n    toString() {\n        let cmdStr = CMD_STRING + this.command;\n        if (this.properties && Object.keys(this.properties).length > 0) {\n            cmdStr += ' ';\n            let first = true;\n            for (const key in this.properties) {\n                if (this.properties.hasOwnProperty(key)) {\n                    const val = this.properties[key];\n                    if (val) {\n                        if (first) {\n                            first = false;\n                        }\n                        else {\n                            cmdStr += ',';\n                        }\n                        cmdStr += `${key}=${escapeProperty(val)}`;\n                    }\n                }\n            }\n        }\n        cmdStr += `${CMD_STRING}${escapeData(this.message)}`;\n        return cmdStr;\n    }\n}\nfunction escapeData(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A');\n}\nfunction escapeProperty(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A')\n        .replace(/:/g, '%3A')\n        .replace(/,/g, '%2C');\n}\n//# sourceMappingURL=command.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getIDToken = exports.getState = exports.saveState = exports.group = exports.endGroup = exports.startGroup = exports.info = exports.notice = exports.warning = exports.error = exports.debug = exports.isDebug = exports.setFailed = exports.setCommandEcho = exports.setOutput = exports.getBooleanInput = exports.getMultilineInput = exports.getInput = exports.addPath = exports.setSecret = exports.exportVariable = exports.ExitCode = void 0;\nconst command_1 = require(\"./command\");\nconst file_command_1 = require(\"./file-command\");\nconst utils_1 = require(\"./utils\");\nconst os = __importStar(require(\"os\"));\nconst path = __importStar(require(\"path\"));\nconst oidc_utils_1 = require(\"./oidc-utils\");\n/**\n * The code to exit an action\n */\nvar ExitCode;\n(function (ExitCode) {\n    /**\n     * A code indicating that the action was successful\n     */\n    ExitCode[ExitCode[\"Success\"] = 0] = \"Success\";\n    /**\n     * A code indicating that the action was a failure\n     */\n    ExitCode[ExitCode[\"Failure\"] = 1] = \"Failure\";\n})(ExitCode = exports.ExitCode || (exports.ExitCode = {}));\n//-----------------------------------------------------------------------\n// Variables\n//-----------------------------------------------------------------------\n/**\n * Sets env variable for this action and future actions in the job\n * @param name the name of the variable to set\n * @param val the value of the variable. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction exportVariable(name, val) {\n    const convertedVal = utils_1.toCommandValue(val);\n    process.env[name] = convertedVal;\n    const filePath = process.env['GITHUB_ENV'] || '';\n    if (filePath) {\n        const delimiter = '_GitHubActionsFileCommandDelimeter_';\n        const commandValue = `${name}<<${delimiter}${os.EOL}${convertedVal}${os.EOL}${delimiter}`;\n        file_command_1.issueCommand('ENV', commandValue);\n    }\n    else {\n        command_1.issueCommand('set-env', { name }, convertedVal);\n    }\n}\nexports.exportVariable = exportVariable;\n/**\n * Registers a secret which will get masked from logs\n * @param secret value of the secret\n */\nfunction setSecret(secret) {\n    command_1.issueCommand('add-mask', {}, secret);\n}\nexports.setSecret = setSecret;\n/**\n * Prepends inputPath to the PATH (for this action and future actions)\n * @param inputPath\n */\nfunction addPath(inputPath) {\n    const filePath = process.env['GITHUB_PATH'] || '';\n    if (filePath) {\n        file_command_1.issueCommand('PATH', inputPath);\n    }\n    else {\n        command_1.issueCommand('add-path', {}, inputPath);\n    }\n    process.env['PATH'] = `${inputPath}${path.delimiter}${process.env['PATH']}`;\n}\nexports.addPath = addPath;\n/**\n * Gets the value of an input.\n * Unless trimWhitespace is set to false in InputOptions, the value is also trimmed.\n * Returns an empty string if the value is not defined.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string\n */\nfunction getInput(name, options) {\n    const val = process.env[`INPUT_${name.replace(/ /g, '_').toUpperCase()}`] || '';\n    if (options && options.required && !val) {\n        throw new Error(`Input required and not supplied: ${name}`);\n    }\n    if (options && options.trimWhitespace === false) {\n        return val;\n    }\n    return val.trim();\n}\nexports.getInput = getInput;\n/**\n * Gets the values of an multiline input.  Each value is also trimmed.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string[]\n *\n */\nfunction getMultilineInput(name, options) {\n    const inputs = getInput(name, options)\n        .split('\\n')\n        .filter(x => x !== '');\n    return inputs;\n}\nexports.getMultilineInput = getMultilineInput;\n/**\n * Gets the input value of the boolean type in the YAML 1.2 \"core schema\" specification.\n * Support boolean input list: `true | True | TRUE | false | False | FALSE` .\n * The return value is also in boolean type.\n * ref: https://yaml.org/spec/1.2/spec.html#id2804923\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   boolean\n */\nfunction getBooleanInput(name, options) {\n    const trueValue = ['true', 'True', 'TRUE'];\n    const falseValue = ['false', 'False', 'FALSE'];\n    const val = getInput(name, options);\n    if (trueValue.includes(val))\n        return true;\n    if (falseValue.includes(val))\n        return false;\n    throw new TypeError(`Input does not meet YAML 1.2 \"Core Schema\" specification: ${name}\\n` +\n        `Support boolean input list: \\`true | True | TRUE | false | False | FALSE\\``);\n}\nexports.getBooleanInput = getBooleanInput;\n/**\n * Sets the value of an output.\n *\n * @param     name     name of the output to set\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction setOutput(name, value) {\n    process.stdout.write(os.EOL);\n    command_1.issueCommand('set-output', { name }, value);\n}\nexports.setOutput = setOutput;\n/**\n * Enables or disables the echoing of commands into stdout for the rest of the step.\n * Echoing is disabled by default if ACTIONS_STEP_DEBUG is not set.\n *\n */\nfunction setCommandEcho(enabled) {\n    command_1.issue('echo', enabled ? 'on' : 'off');\n}\nexports.setCommandEcho = setCommandEcho;\n//-----------------------------------------------------------------------\n// Results\n//-----------------------------------------------------------------------\n/**\n * Sets the action status to failed.\n * When the action exits it will be with an exit code of 1\n * @param message add error issue message\n */\nfunction setFailed(message) {\n    process.exitCode = ExitCode.Failure;\n    error(message);\n}\nexports.setFailed = setFailed;\n//-----------------------------------------------------------------------\n// Logging Commands\n//-----------------------------------------------------------------------\n/**\n * Gets whether Actions Step Debug is on or not\n */\nfunction isDebug() {\n    return process.env['RUNNER_DEBUG'] === '1';\n}\nexports.isDebug = isDebug;\n/**\n * Writes debug message to user log\n * @param message debug message\n */\nfunction debug(message) {\n    command_1.issueCommand('debug', {}, message);\n}\nexports.debug = debug;\n/**\n * Adds an error issue\n * @param message error issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction error(message, properties = {}) {\n    command_1.issueCommand('error', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.error = error;\n/**\n * Adds a warning issue\n * @param message warning issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction warning(message, properties = {}) {\n    command_1.issueCommand('warning', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.warning = warning;\n/**\n * Adds a notice issue\n * @param message notice issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction notice(message, properties = {}) {\n    command_1.issueCommand('notice', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.notice = notice;\n/**\n * Writes info to log with console.log.\n * @param message info message\n */\nfunction info(message) {\n    process.stdout.write(message + os.EOL);\n}\nexports.info = info;\n/**\n * Begin an output group.\n *\n * Output until the next `groupEnd` will be foldable in this group\n *\n * @param name The name of the output group\n */\nfunction startGroup(name) {\n    command_1.issue('group', name);\n}\nexports.startGroup = startGroup;\n/**\n * End an output group.\n */\nfunction endGroup() {\n    command_1.issue('endgroup');\n}\nexports.endGroup = endGroup;\n/**\n * Wrap an asynchronous function call in a group.\n *\n * Returns the same type as the function itself.\n *\n * @param name The name of the group\n * @param fn The function to wrap in the group\n */\nfunction group(name, fn) {\n    return __awaiter(this, void 0, void 0, function* () {\n        startGroup(name);\n        let result;\n        try {\n            result = yield fn();\n        }\n        finally {\n            endGroup();\n        }\n        return result;\n    });\n}\nexports.group = group;\n//-----------------------------------------------------------------------\n// Wrapper action state\n//-----------------------------------------------------------------------\n/**\n * Saves state for current action, the state can only be retrieved by this action's post job execution.\n *\n * @param     name     name of the state to store\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction saveState(name, value) {\n    command_1.issueCommand('save-state', { name }, value);\n}\nexports.saveState = saveState;\n/**\n * Gets the value of an state set by this action's main execution.\n *\n * @param     name     name of the state to get\n * @returns   string\n */\nfunction getState(name) {\n    return process.env[`STATE_${name}`] || '';\n}\nexports.getState = getState;\nfunction getIDToken(aud) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return yield oidc_utils_1.OidcClient.getIDToken(aud);\n    });\n}\nexports.getIDToken = getIDToken;\n//# sourceMappingURL=core.js.map","\"use strict\";\n// For internal use, subject to change.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issueCommand = void 0;\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nconst fs = __importStar(require(\"fs\"));\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\nfunction issueCommand(command, message) {\n    const filePath = process.env[`GITHUB_${command}`];\n    if (!filePath) {\n        throw new Error(`Unable to find environment variable for file command ${command}`);\n    }\n    if (!fs.existsSync(filePath)) {\n        throw new Error(`Missing file at path: ${filePath}`);\n    }\n    fs.appendFileSync(filePath, `${utils_1.toCommandValue(message)}${os.EOL}`, {\n        encoding: 'utf8'\n    });\n}\nexports.issueCommand = issueCommand;\n//# sourceMappingURL=file-command.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.OidcClient = void 0;\nconst http_client_1 = require(\"@actions/http-client\");\nconst auth_1 = require(\"@actions/http-client/auth\");\nconst core_1 = require(\"./core\");\nclass OidcClient {\n    static createHttpClient(allowRetry = true, maxRetry = 10) {\n        const requestOptions = {\n            allowRetries: allowRetry,\n            maxRetries: maxRetry\n        };\n        return new http_client_1.HttpClient('actions/oidc-client', [new auth_1.BearerCredentialHandler(OidcClient.getRequestToken())], requestOptions);\n    }\n    static getRequestToken() {\n        const token = process.env['ACTIONS_ID_TOKEN_REQUEST_TOKEN'];\n        if (!token) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_TOKEN env variable');\n        }\n        return token;\n    }\n    static getIDTokenUrl() {\n        const runtimeUrl = process.env['ACTIONS_ID_TOKEN_REQUEST_URL'];\n        if (!runtimeUrl) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_URL env variable');\n        }\n        return runtimeUrl;\n    }\n    static getCall(id_token_url) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            const httpclient = OidcClient.createHttpClient();\n            const res = yield httpclient\n                .getJson(id_token_url)\n                .catch(error => {\n                throw new Error(`Failed to get ID Token. \\n \n        Error Code : ${error.statusCode}\\n \n        Error Message: ${error.result.message}`);\n            });\n            const id_token = (_a = res.result) === null || _a === void 0 ? void 0 : _a.value;\n            if (!id_token) {\n                throw new Error('Response json body do not have ID Token field');\n            }\n            return id_token;\n        });\n    }\n    static getIDToken(audience) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                // New ID Token is requested from action service\n                let id_token_url = OidcClient.getIDTokenUrl();\n                if (audience) {\n                    const encodedAudience = encodeURIComponent(audience);\n                    id_token_url = `${id_token_url}&audience=${encodedAudience}`;\n                }\n                core_1.debug(`ID token url is ${id_token_url}`);\n                const id_token = yield OidcClient.getCall(id_token_url);\n                core_1.setSecret(id_token);\n                return id_token;\n            }\n            catch (error) {\n                throw new Error(`Error message: ${error.message}`);\n            }\n        });\n    }\n}\nexports.OidcClient = OidcClient;\n//# sourceMappingURL=oidc-utils.js.map","\"use strict\";\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toCommandProperties = exports.toCommandValue = void 0;\n/**\n * Sanitizes an input into a string so it can be passed into issueCommand safely\n * @param input input to sanitize into a string\n */\nfunction toCommandValue(input) {\n    if (input === null || input === undefined) {\n        return '';\n    }\n    else if (typeof input === 'string' || input instanceof String) {\n        return input;\n    }\n    return JSON.stringify(input);\n}\nexports.toCommandValue = toCommandValue;\n/**\n *\n * @param annotationProperties\n * @returns The command properties to send with the actual annotation command\n * See IssueCommandProperties: https://github.com/actions/runner/blob/main/src/Runner.Worker/ActionCommandManager.cs#L646\n */\nfunction toCommandProperties(annotationProperties) {\n    if (!Object.keys(annotationProperties).length) {\n        return {};\n    }\n    return {\n        title: annotationProperties.title,\n        file: annotationProperties.file,\n        line: annotationProperties.startLine,\n        endLine: annotationProperties.endLine,\n        col: annotationProperties.startColumn,\n        endColumn: annotationProperties.endColumn\n    };\n}\nexports.toCommandProperties = toCommandProperties;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nclass BasicCredentialHandler {\n    constructor(username, password) {\n        this.username = username;\n        this.password = password;\n    }\n    prepareRequest(options) {\n        options.headers['Authorization'] =\n            'Basic ' +\n                Buffer.from(this.username + ':' + this.password).toString('base64');\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication(response) {\n        return false;\n    }\n    handleAuthentication(httpClient, requestInfo, objs) {\n        return null;\n    }\n}\nexports.BasicCredentialHandler = BasicCredentialHandler;\nclass BearerCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        options.headers['Authorization'] = 'Bearer ' + this.token;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication(response) {\n        return false;\n    }\n    handleAuthentication(httpClient, requestInfo, objs) {\n        return null;\n    }\n}\nexports.BearerCredentialHandler = BearerCredentialHandler;\nclass PersonalAccessTokenCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        options.headers['Authorization'] =\n            'Basic ' + Buffer.from('PAT:' + this.token).toString('base64');\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication(response) {\n        return false;\n    }\n    handleAuthentication(httpClient, requestInfo, objs) {\n        return null;\n    }\n}\nexports.PersonalAccessTokenCredentialHandler = PersonalAccessTokenCredentialHandler;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst http = require(\"http\");\nconst https = require(\"https\");\nconst pm = require(\"./proxy\");\nlet tunnel;\nvar HttpCodes;\n(function (HttpCodes) {\n    HttpCodes[HttpCodes[\"OK\"] = 200] = \"OK\";\n    HttpCodes[HttpCodes[\"MultipleChoices\"] = 300] = \"MultipleChoices\";\n    HttpCodes[HttpCodes[\"MovedPermanently\"] = 301] = \"MovedPermanently\";\n    HttpCodes[HttpCodes[\"ResourceMoved\"] = 302] = \"ResourceMoved\";\n    HttpCodes[HttpCodes[\"SeeOther\"] = 303] = \"SeeOther\";\n    HttpCodes[HttpCodes[\"NotModified\"] = 304] = \"NotModified\";\n    HttpCodes[HttpCodes[\"UseProxy\"] = 305] = \"UseProxy\";\n    HttpCodes[HttpCodes[\"SwitchProxy\"] = 306] = \"SwitchProxy\";\n    HttpCodes[HttpCodes[\"TemporaryRedirect\"] = 307] = \"TemporaryRedirect\";\n    HttpCodes[HttpCodes[\"PermanentRedirect\"] = 308] = \"PermanentRedirect\";\n    HttpCodes[HttpCodes[\"BadRequest\"] = 400] = \"BadRequest\";\n    HttpCodes[HttpCodes[\"Unauthorized\"] = 401] = \"Unauthorized\";\n    HttpCodes[HttpCodes[\"PaymentRequired\"] = 402] = \"PaymentRequired\";\n    HttpCodes[HttpCodes[\"Forbidden\"] = 403] = \"Forbidden\";\n    HttpCodes[HttpCodes[\"NotFound\"] = 404] = \"NotFound\";\n    HttpCodes[HttpCodes[\"MethodNotAllowed\"] = 405] = \"MethodNotAllowed\";\n    HttpCodes[HttpCodes[\"NotAcceptable\"] = 406] = \"NotAcceptable\";\n    HttpCodes[HttpCodes[\"ProxyAuthenticationRequired\"] = 407] = \"ProxyAuthenticationRequired\";\n    HttpCodes[HttpCodes[\"RequestTimeout\"] = 408] = \"RequestTimeout\";\n    HttpCodes[HttpCodes[\"Conflict\"] = 409] = \"Conflict\";\n    HttpCodes[HttpCodes[\"Gone\"] = 410] = \"Gone\";\n    HttpCodes[HttpCodes[\"TooManyRequests\"] = 429] = \"TooManyRequests\";\n    HttpCodes[HttpCodes[\"InternalServerError\"] = 500] = \"InternalServerError\";\n    HttpCodes[HttpCodes[\"NotImplemented\"] = 501] = \"NotImplemented\";\n    HttpCodes[HttpCodes[\"BadGateway\"] = 502] = \"BadGateway\";\n    HttpCodes[HttpCodes[\"ServiceUnavailable\"] = 503] = \"ServiceUnavailable\";\n    HttpCodes[HttpCodes[\"GatewayTimeout\"] = 504] = \"GatewayTimeout\";\n})(HttpCodes = exports.HttpCodes || (exports.HttpCodes = {}));\nvar Headers;\n(function (Headers) {\n    Headers[\"Accept\"] = \"accept\";\n    Headers[\"ContentType\"] = \"content-type\";\n})(Headers = exports.Headers || (exports.Headers = {}));\nvar MediaTypes;\n(function (MediaTypes) {\n    MediaTypes[\"ApplicationJson\"] = \"application/json\";\n})(MediaTypes = exports.MediaTypes || (exports.MediaTypes = {}));\n/**\n * Returns the proxy URL, depending upon the supplied url and proxy environment variables.\n * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n */\nfunction getProxyUrl(serverUrl) {\n    let proxyUrl = pm.getProxyUrl(new URL(serverUrl));\n    return proxyUrl ? proxyUrl.href : '';\n}\nexports.getProxyUrl = getProxyUrl;\nconst HttpRedirectCodes = [\n    HttpCodes.MovedPermanently,\n    HttpCodes.ResourceMoved,\n    HttpCodes.SeeOther,\n    HttpCodes.TemporaryRedirect,\n    HttpCodes.PermanentRedirect\n];\nconst HttpResponseRetryCodes = [\n    HttpCodes.BadGateway,\n    HttpCodes.ServiceUnavailable,\n    HttpCodes.GatewayTimeout\n];\nconst RetryableHttpVerbs = ['OPTIONS', 'GET', 'DELETE', 'HEAD'];\nconst ExponentialBackoffCeiling = 10;\nconst ExponentialBackoffTimeSlice = 5;\nclass HttpClientError extends Error {\n    constructor(message, statusCode) {\n        super(message);\n        this.name = 'HttpClientError';\n        this.statusCode = statusCode;\n        Object.setPrototypeOf(this, HttpClientError.prototype);\n    }\n}\nexports.HttpClientError = HttpClientError;\nclass HttpClientResponse {\n    constructor(message) {\n        this.message = message;\n    }\n    readBody() {\n        return new Promise(async (resolve, reject) => {\n            let output = Buffer.alloc(0);\n            this.message.on('data', (chunk) => {\n                output = Buffer.concat([output, chunk]);\n            });\n            this.message.on('end', () => {\n                resolve(output.toString());\n            });\n        });\n    }\n}\nexports.HttpClientResponse = HttpClientResponse;\nfunction isHttps(requestUrl) {\n    let parsedUrl = new URL(requestUrl);\n    return parsedUrl.protocol === 'https:';\n}\nexports.isHttps = isHttps;\nclass HttpClient {\n    constructor(userAgent, handlers, requestOptions) {\n        this._ignoreSslError = false;\n        this._allowRedirects = true;\n        this._allowRedirectDowngrade = false;\n        this._maxRedirects = 50;\n        this._allowRetries = false;\n        this._maxRetries = 1;\n        this._keepAlive = false;\n        this._disposed = false;\n        this.userAgent = userAgent;\n        this.handlers = handlers || [];\n        this.requestOptions = requestOptions;\n        if (requestOptions) {\n            if (requestOptions.ignoreSslError != null) {\n                this._ignoreSslError = requestOptions.ignoreSslError;\n            }\n            this._socketTimeout = requestOptions.socketTimeout;\n            if (requestOptions.allowRedirects != null) {\n                this._allowRedirects = requestOptions.allowRedirects;\n            }\n            if (requestOptions.allowRedirectDowngrade != null) {\n                this._allowRedirectDowngrade = requestOptions.allowRedirectDowngrade;\n            }\n            if (requestOptions.maxRedirects != null) {\n                this._maxRedirects = Math.max(requestOptions.maxRedirects, 0);\n            }\n            if (requestOptions.keepAlive != null) {\n                this._keepAlive = requestOptions.keepAlive;\n            }\n            if (requestOptions.allowRetries != null) {\n                this._allowRetries = requestOptions.allowRetries;\n            }\n            if (requestOptions.maxRetries != null) {\n                this._maxRetries = requestOptions.maxRetries;\n            }\n        }\n    }\n    options(requestUrl, additionalHeaders) {\n        return this.request('OPTIONS', requestUrl, null, additionalHeaders || {});\n    }\n    get(requestUrl, additionalHeaders) {\n        return this.request('GET', requestUrl, null, additionalHeaders || {});\n    }\n    del(requestUrl, additionalHeaders) {\n        return this.request('DELETE', requestUrl, null, additionalHeaders || {});\n    }\n    post(requestUrl, data, additionalHeaders) {\n        return this.request('POST', requestUrl, data, additionalHeaders || {});\n    }\n    patch(requestUrl, data, additionalHeaders) {\n        return this.request('PATCH', requestUrl, data, additionalHeaders || {});\n    }\n    put(requestUrl, data, additionalHeaders) {\n        return this.request('PUT', requestUrl, data, additionalHeaders || {});\n    }\n    head(requestUrl, additionalHeaders) {\n        return this.request('HEAD', requestUrl, null, additionalHeaders || {});\n    }\n    sendStream(verb, requestUrl, stream, additionalHeaders) {\n        return this.request(verb, requestUrl, stream, additionalHeaders);\n    }\n    /**\n     * Gets a typed object from an endpoint\n     * Be aware that not found returns a null.  Other errors (4xx, 5xx) reject the promise\n     */\n    async getJson(requestUrl, additionalHeaders = {}) {\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        let res = await this.get(requestUrl, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    async postJson(requestUrl, obj, additionalHeaders = {}) {\n        let data = JSON.stringify(obj, null, 2);\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n        let res = await this.post(requestUrl, data, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    async putJson(requestUrl, obj, additionalHeaders = {}) {\n        let data = JSON.stringify(obj, null, 2);\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n        let res = await this.put(requestUrl, data, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    async patchJson(requestUrl, obj, additionalHeaders = {}) {\n        let data = JSON.stringify(obj, null, 2);\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n        let res = await this.patch(requestUrl, data, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    /**\n     * Makes a raw http request.\n     * All other methods such as get, post, patch, and request ultimately call this.\n     * Prefer get, del, post and patch\n     */\n    async request(verb, requestUrl, data, headers) {\n        if (this._disposed) {\n            throw new Error('Client has already been disposed.');\n        }\n        let parsedUrl = new URL(requestUrl);\n        let info = this._prepareRequest(verb, parsedUrl, headers);\n        // Only perform retries on reads since writes may not be idempotent.\n        let maxTries = this._allowRetries && RetryableHttpVerbs.indexOf(verb) != -1\n            ? this._maxRetries + 1\n            : 1;\n        let numTries = 0;\n        let response;\n        while (numTries < maxTries) {\n            response = await this.requestRaw(info, data);\n            // Check if it's an authentication challenge\n            if (response &&\n                response.message &&\n                response.message.statusCode === HttpCodes.Unauthorized) {\n                let authenticationHandler;\n                for (let i = 0; i < this.handlers.length; i++) {\n                    if (this.handlers[i].canHandleAuthentication(response)) {\n                        authenticationHandler = this.handlers[i];\n                        break;\n                    }\n                }\n                if (authenticationHandler) {\n                    return authenticationHandler.handleAuthentication(this, info, data);\n                }\n                else {\n                    // We have received an unauthorized response but have no handlers to handle it.\n                    // Let the response return to the caller.\n                    return response;\n                }\n            }\n            let redirectsRemaining = this._maxRedirects;\n            while (HttpRedirectCodes.indexOf(response.message.statusCode) != -1 &&\n                this._allowRedirects &&\n                redirectsRemaining > 0) {\n                const redirectUrl = response.message.headers['location'];\n                if (!redirectUrl) {\n                    // if there's no location to redirect to, we won't\n                    break;\n                }\n                let parsedRedirectUrl = new URL(redirectUrl);\n                if (parsedUrl.protocol == 'https:' &&\n                    parsedUrl.protocol != parsedRedirectUrl.protocol &&\n                    !this._allowRedirectDowngrade) {\n                    throw new Error('Redirect from HTTPS to HTTP protocol. This downgrade is not allowed for security reasons. If you want to allow this behavior, set the allowRedirectDowngrade option to true.');\n                }\n                // we need to finish reading the response before reassigning response\n                // which will leak the open socket.\n                await response.readBody();\n                // strip authorization header if redirected to a different hostname\n                if (parsedRedirectUrl.hostname !== parsedUrl.hostname) {\n                    for (let header in headers) {\n                        // header names are case insensitive\n                        if (header.toLowerCase() === 'authorization') {\n                            delete headers[header];\n                        }\n                    }\n                }\n                // let's make the request with the new redirectUrl\n                info = this._prepareRequest(verb, parsedRedirectUrl, headers);\n                response = await this.requestRaw(info, data);\n                redirectsRemaining--;\n            }\n            if (HttpResponseRetryCodes.indexOf(response.message.statusCode) == -1) {\n                // If not a retry code, return immediately instead of retrying\n                return response;\n            }\n            numTries += 1;\n            if (numTries < maxTries) {\n                await response.readBody();\n                await this._performExponentialBackoff(numTries);\n            }\n        }\n        return response;\n    }\n    /**\n     * Needs to be called if keepAlive is set to true in request options.\n     */\n    dispose() {\n        if (this._agent) {\n            this._agent.destroy();\n        }\n        this._disposed = true;\n    }\n    /**\n     * Raw request.\n     * @param info\n     * @param data\n     */\n    requestRaw(info, data) {\n        return new Promise((resolve, reject) => {\n            let callbackForResult = function (err, res) {\n                if (err) {\n                    reject(err);\n                }\n                resolve(res);\n            };\n            this.requestRawWithCallback(info, data, callbackForResult);\n        });\n    }\n    /**\n     * Raw request with callback.\n     * @param info\n     * @param data\n     * @param onResult\n     */\n    requestRawWithCallback(info, data, onResult) {\n        let socket;\n        if (typeof data === 'string') {\n            info.options.headers['Content-Length'] = Buffer.byteLength(data, 'utf8');\n        }\n        let callbackCalled = false;\n        let handleResult = (err, res) => {\n            if (!callbackCalled) {\n                callbackCalled = true;\n                onResult(err, res);\n            }\n        };\n        let req = info.httpModule.request(info.options, (msg) => {\n            let res = new HttpClientResponse(msg);\n            handleResult(null, res);\n        });\n        req.on('socket', sock => {\n            socket = sock;\n        });\n        // If we ever get disconnected, we want the socket to timeout eventually\n        req.setTimeout(this._socketTimeout || 3 * 60000, () => {\n            if (socket) {\n                socket.end();\n            }\n            handleResult(new Error('Request timeout: ' + info.options.path), null);\n        });\n        req.on('error', function (err) {\n            // err has statusCode property\n            // res should have headers\n            handleResult(err, null);\n        });\n        if (data && typeof data === 'string') {\n            req.write(data, 'utf8');\n        }\n        if (data && typeof data !== 'string') {\n            data.on('close', function () {\n                req.end();\n            });\n            data.pipe(req);\n        }\n        else {\n            req.end();\n        }\n    }\n    /**\n     * Gets an http agent. This function is useful when you need an http agent that handles\n     * routing through a proxy server - depending upon the url and proxy environment variables.\n     * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n     */\n    getAgent(serverUrl) {\n        let parsedUrl = new URL(serverUrl);\n        return this._getAgent(parsedUrl);\n    }\n    _prepareRequest(method, requestUrl, headers) {\n        const info = {};\n        info.parsedUrl = requestUrl;\n        const usingSsl = info.parsedUrl.protocol === 'https:';\n        info.httpModule = usingSsl ? https : http;\n        const defaultPort = usingSsl ? 443 : 80;\n        info.options = {};\n        info.options.host = info.parsedUrl.hostname;\n        info.options.port = info.parsedUrl.port\n            ? parseInt(info.parsedUrl.port)\n            : defaultPort;\n        info.options.path =\n            (info.parsedUrl.pathname || '') + (info.parsedUrl.search || '');\n        info.options.method = method;\n        info.options.headers = this._mergeHeaders(headers);\n        if (this.userAgent != null) {\n            info.options.headers['user-agent'] = this.userAgent;\n        }\n        info.options.agent = this._getAgent(info.parsedUrl);\n        // gives handlers an opportunity to participate\n        if (this.handlers) {\n            this.handlers.forEach(handler => {\n                handler.prepareRequest(info.options);\n            });\n        }\n        return info;\n    }\n    _mergeHeaders(headers) {\n        const lowercaseKeys = obj => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});\n        if (this.requestOptions && this.requestOptions.headers) {\n            return Object.assign({}, lowercaseKeys(this.requestOptions.headers), lowercaseKeys(headers));\n        }\n        return lowercaseKeys(headers || {});\n    }\n    _getExistingOrDefaultHeader(additionalHeaders, header, _default) {\n        const lowercaseKeys = obj => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});\n        let clientHeader;\n        if (this.requestOptions && this.requestOptions.headers) {\n            clientHeader = lowercaseKeys(this.requestOptions.headers)[header];\n        }\n        return additionalHeaders[header] || clientHeader || _default;\n    }\n    _getAgent(parsedUrl) {\n        let agent;\n        let proxyUrl = pm.getProxyUrl(parsedUrl);\n        let useProxy = proxyUrl && proxyUrl.hostname;\n        if (this._keepAlive && useProxy) {\n            agent = this._proxyAgent;\n        }\n        if (this._keepAlive && !useProxy) {\n            agent = this._agent;\n        }\n        // if agent is already assigned use that agent.\n        if (!!agent) {\n            return agent;\n        }\n        const usingSsl = parsedUrl.protocol === 'https:';\n        let maxSockets = 100;\n        if (!!this.requestOptions) {\n            maxSockets = this.requestOptions.maxSockets || http.globalAgent.maxSockets;\n        }\n        if (useProxy) {\n            // If using proxy, need tunnel\n            if (!tunnel) {\n                tunnel = require('tunnel');\n            }\n            const agentOptions = {\n                maxSockets: maxSockets,\n                keepAlive: this._keepAlive,\n                proxy: {\n                    ...((proxyUrl.username || proxyUrl.password) && {\n                        proxyAuth: `${proxyUrl.username}:${proxyUrl.password}`\n                    }),\n                    host: proxyUrl.hostname,\n                    port: proxyUrl.port\n                }\n            };\n            let tunnelAgent;\n            const overHttps = proxyUrl.protocol === 'https:';\n            if (usingSsl) {\n                tunnelAgent = overHttps ? tunnel.httpsOverHttps : tunnel.httpsOverHttp;\n            }\n            else {\n                tunnelAgent = overHttps ? tunnel.httpOverHttps : tunnel.httpOverHttp;\n            }\n            agent = tunnelAgent(agentOptions);\n            this._proxyAgent = agent;\n        }\n        // if reusing agent across request and tunneling agent isn't assigned create a new agent\n        if (this._keepAlive && !agent) {\n            const options = { keepAlive: this._keepAlive, maxSockets: maxSockets };\n            agent = usingSsl ? new https.Agent(options) : new http.Agent(options);\n            this._agent = agent;\n        }\n        // if not using private agent and tunnel agent isn't setup then use global agent\n        if (!agent) {\n            agent = usingSsl ? https.globalAgent : http.globalAgent;\n        }\n        if (usingSsl && this._ignoreSslError) {\n            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process\n            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options\n            // we have to cast it to any and change it directly\n            agent.options = Object.assign(agent.options || {}, {\n                rejectUnauthorized: false\n            });\n        }\n        return agent;\n    }\n    _performExponentialBackoff(retryNumber) {\n        retryNumber = Math.min(ExponentialBackoffCeiling, retryNumber);\n        const ms = ExponentialBackoffTimeSlice * Math.pow(2, retryNumber);\n        return new Promise(resolve => setTimeout(() => resolve(), ms));\n    }\n    static dateTimeDeserializer(key, value) {\n        if (typeof value === 'string') {\n            let a = new Date(value);\n            if (!isNaN(a.valueOf())) {\n                return a;\n            }\n        }\n        return value;\n    }\n    async _processResponse(res, options) {\n        return new Promise(async (resolve, reject) => {\n            const statusCode = res.message.statusCode;\n            const response = {\n                statusCode: statusCode,\n                result: null,\n                headers: {}\n            };\n            // not found leads to null obj returned\n            if (statusCode == HttpCodes.NotFound) {\n                resolve(response);\n            }\n            let obj;\n            let contents;\n            // get the result from the body\n            try {\n                contents = await res.readBody();\n                if (contents && contents.length > 0) {\n                    if (options && options.deserializeDates) {\n                        obj = JSON.parse(contents, HttpClient.dateTimeDeserializer);\n                    }\n                    else {\n                        obj = JSON.parse(contents);\n                    }\n                    response.result = obj;\n                }\n                response.headers = res.message.headers;\n            }\n            catch (err) {\n                // Invalid resource (contents not json);  leaving result obj null\n            }\n            // note that 3xx redirects are handled by the http layer.\n            if (statusCode > 299) {\n                let msg;\n                // if exception/error in body, attempt to get better error\n                if (obj && obj.message) {\n                    msg = obj.message;\n                }\n                else if (contents && contents.length > 0) {\n                    // it may be the case that the exception is in the body message as string\n                    msg = contents;\n                }\n                else {\n                    msg = 'Failed request: (' + statusCode + ')';\n                }\n                let err = new HttpClientError(msg, statusCode);\n                err.result = response.result;\n                reject(err);\n            }\n            else {\n                resolve(response);\n            }\n        });\n    }\n}\nexports.HttpClient = HttpClient;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction getProxyUrl(reqUrl) {\n    let usingSsl = reqUrl.protocol === 'https:';\n    let proxyUrl;\n    if (checkBypass(reqUrl)) {\n        return proxyUrl;\n    }\n    let proxyVar;\n    if (usingSsl) {\n        proxyVar = process.env['https_proxy'] || process.env['HTTPS_PROXY'];\n    }\n    else {\n        proxyVar = process.env['http_proxy'] || process.env['HTTP_PROXY'];\n    }\n    if (proxyVar) {\n        proxyUrl = new URL(proxyVar);\n    }\n    return proxyUrl;\n}\nexports.getProxyUrl = getProxyUrl;\nfunction checkBypass(reqUrl) {\n    if (!reqUrl.hostname) {\n        return false;\n    }\n    let noProxy = process.env['no_proxy'] || process.env['NO_PROXY'] || '';\n    if (!noProxy) {\n        return false;\n    }\n    // Determine the request port\n    let reqPort;\n    if (reqUrl.port) {\n        reqPort = Number(reqUrl.port);\n    }\n    else if (reqUrl.protocol === 'http:') {\n        reqPort = 80;\n    }\n    else if (reqUrl.protocol === 'https:') {\n        reqPort = 443;\n    }\n    // Format the request hostname and hostname with port\n    let upperReqHosts = [reqUrl.hostname.toUpperCase()];\n    if (typeof reqPort === 'number') {\n        upperReqHosts.push(`${upperReqHosts[0]}:${reqPort}`);\n    }\n    // Compare request host against noproxy\n    for (let upperNoProxyItem of noProxy\n        .split(',')\n        .map(x => x.trim().toUpperCase())\n        .filter(x => x)) {\n        if (upperReqHosts.some(x => x === upperNoProxyItem)) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.checkBypass = checkBypass;\n","'use strict'\nconst fs = require('fs')\nconst path = require('path')\n\n/* istanbul ignore next */\nconst LCHOWN = fs.lchown ? 'lchown' : 'chown'\n/* istanbul ignore next */\nconst LCHOWNSYNC = fs.lchownSync ? 'lchownSync' : 'chownSync'\n\n/* istanbul ignore next */\nconst needEISDIRHandled = fs.lchown &&\n  !process.version.match(/v1[1-9]+\\./) &&\n  !process.version.match(/v10\\.[6-9]/)\n\nconst lchownSync = (path, uid, gid) => {\n  try {\n    return fs[LCHOWNSYNC](path, uid, gid)\n  } catch (er) {\n    if (er.code !== 'ENOENT')\n      throw er\n  }\n}\n\n/* istanbul ignore next */\nconst chownSync = (path, uid, gid) => {\n  try {\n    return fs.chownSync(path, uid, gid)\n  } catch (er) {\n    if (er.code !== 'ENOENT')\n      throw er\n  }\n}\n\n/* istanbul ignore next */\nconst handleEISDIR =\n  needEISDIRHandled ? (path, uid, gid, cb) => er => {\n    // Node prior to v10 had a very questionable implementation of\n    // fs.lchown, which would always try to call fs.open on a directory\n    // Fall back to fs.chown in those cases.\n    if (!er || er.code !== 'EISDIR')\n      cb(er)\n    else\n      fs.chown(path, uid, gid, cb)\n  }\n  : (_, __, ___, cb) => cb\n\n/* istanbul ignore next */\nconst handleEISDirSync =\n  needEISDIRHandled ? (path, uid, gid) => {\n    try {\n      return lchownSync(path, uid, gid)\n    } catch (er) {\n      if (er.code !== 'EISDIR')\n        throw er\n      chownSync(path, uid, gid)\n    }\n  }\n  : (path, uid, gid) => lchownSync(path, uid, gid)\n\n// fs.readdir could only accept an options object as of node v6\nconst nodeVersion = process.version\nlet readdir = (path, options, cb) => fs.readdir(path, options, cb)\nlet readdirSync = (path, options) => fs.readdirSync(path, options)\n/* istanbul ignore next */\nif (/^v4\\./.test(nodeVersion))\n  readdir = (path, options, cb) => fs.readdir(path, cb)\n\nconst chown = (cpath, uid, gid, cb) => {\n  fs[LCHOWN](cpath, uid, gid, handleEISDIR(cpath, uid, gid, er => {\n    // Skip ENOENT error\n    cb(er && er.code !== 'ENOENT' ? er : null)\n  }))\n}\n\nconst chownrKid = (p, child, uid, gid, cb) => {\n  if (typeof child === 'string')\n    return fs.lstat(path.resolve(p, child), (er, stats) => {\n      // Skip ENOENT error\n      if (er)\n        return cb(er.code !== 'ENOENT' ? er : null)\n      stats.name = child\n      chownrKid(p, stats, uid, gid, cb)\n    })\n\n  if (child.isDirectory()) {\n    chownr(path.resolve(p, child.name), uid, gid, er => {\n      if (er)\n        return cb(er)\n      const cpath = path.resolve(p, child.name)\n      chown(cpath, uid, gid, cb)\n    })\n  } else {\n    const cpath = path.resolve(p, child.name)\n    chown(cpath, uid, gid, cb)\n  }\n}\n\n\nconst chownr = (p, uid, gid, cb) => {\n  readdir(p, { withFileTypes: true }, (er, children) => {\n    // any error other than ENOTDIR or ENOTSUP means it's not readable,\n    // or doesn't exist.  give up.\n    if (er) {\n      if (er.code === 'ENOENT')\n        return cb()\n      else if (er.code !== 'ENOTDIR' && er.code !== 'ENOTSUP')\n        return cb(er)\n    }\n    if (er || !children.length)\n      return chown(p, uid, gid, cb)\n\n    let len = children.length\n    let errState = null\n    const then = er => {\n      if (errState)\n        return\n      if (er)\n        return cb(errState = er)\n      if (-- len === 0)\n        return chown(p, uid, gid, cb)\n    }\n\n    children.forEach(child => chownrKid(p, child, uid, gid, then))\n  })\n}\n\nconst chownrKidSync = (p, child, uid, gid) => {\n  if (typeof child === 'string') {\n    try {\n      const stats = fs.lstatSync(path.resolve(p, child))\n      stats.name = child\n      child = stats\n    } catch (er) {\n      if (er.code === 'ENOENT')\n        return\n      else\n        throw er\n    }\n  }\n\n  if (child.isDirectory())\n    chownrSync(path.resolve(p, child.name), uid, gid)\n\n  handleEISDirSync(path.resolve(p, child.name), uid, gid)\n}\n\nconst chownrSync = (p, uid, gid) => {\n  let children\n  try {\n    children = readdirSync(p, { withFileTypes: true })\n  } catch (er) {\n    if (er.code === 'ENOENT')\n      return\n    else if (er.code === 'ENOTDIR' || er.code === 'ENOTSUP')\n      return handleEISDirSync(p, uid, gid)\n    else\n      throw er\n  }\n\n  if (children && children.length)\n    children.forEach(child => chownrKidSync(p, child, uid, gid))\n\n  return handleEISDirSync(p, uid, gid)\n}\n\nmodule.exports = chownr\nchownr.sync = chownrSync\n","import Blob from './index.js'\n\nconst _File = class File extends Blob {\n  #lastModified = 0\n  #name = ''\n\n  /**\n   * @param {*[]} fileBits\n   * @param {string} fileName\n   * @param {{lastModified?: number, type?: string}} options\n   */// @ts-ignore\n  constructor (fileBits, fileName, options = {}) {\n    if (arguments.length < 2) {\n      throw new TypeError(`Failed to construct 'File': 2 arguments required, but only ${arguments.length} present.`)\n    }\n    super(fileBits, options)\n\n    if (options === null) options = {}\n\n    // Simulate WebIDL type casting for NaN value in lastModified option.\n    const lastModified = options.lastModified === undefined ? Date.now() : Number(options.lastModified)\n    if (!Number.isNaN(lastModified)) {\n      this.#lastModified = lastModified\n    }\n\n    this.#name = String(fileName)\n  }\n\n  get name () {\n    return this.#name\n  }\n\n  get lastModified () {\n    return this.#lastModified\n  }\n\n  get [Symbol.toStringTag] () {\n    return 'File'\n  }\n\n  static [Symbol.hasInstance] (object) {\n    return !!object && object instanceof Blob &&\n      /^(File)$/.test(object[Symbol.toStringTag])\n  }\n}\n\n/** @type {typeof globalThis.File} */// @ts-ignore\nexport const File = _File\nexport default File\n","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"node:fs\");","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"node:path\");","import { statSync, createReadStream, promises as fs } from 'node:fs'\nimport { basename } from 'node:path'\nimport DOMException from 'node-domexception'\n\nimport File from './file.js'\nimport Blob from './index.js'\n\nconst { stat } = fs\n\n/**\n * @param {string} path filepath on the disk\n * @param {string} [type] mimetype to use\n */\nconst blobFromSync = (path, type) => fromBlob(statSync(path), path, type)\n\n/**\n * @param {string} path filepath on the disk\n * @param {string} [type] mimetype to use\n * @returns {Promise<Blob>}\n */\nconst blobFrom = (path, type) => stat(path).then(stat => fromBlob(stat, path, type))\n\n/**\n * @param {string} path filepath on the disk\n * @param {string} [type] mimetype to use\n * @returns {Promise<File>}\n */\nconst fileFrom = (path, type) => stat(path).then(stat => fromFile(stat, path, type))\n\n/**\n * @param {string} path filepath on the disk\n * @param {string} [type] mimetype to use\n */\nconst fileFromSync = (path, type) => fromFile(statSync(path), path, type)\n\n// @ts-ignore\nconst fromBlob = (stat, path, type = '') => new Blob([new BlobDataItem({\n  path,\n  size: stat.size,\n  lastModified: stat.mtimeMs,\n  start: 0\n})], { type })\n\n// @ts-ignore\nconst fromFile = (stat, path, type = '') => new File([new BlobDataItem({\n  path,\n  size: stat.size,\n  lastModified: stat.mtimeMs,\n  start: 0\n})], basename(path), { type, lastModified: stat.mtimeMs })\n\n/**\n * This is a blob backed up by a file on the disk\n * with minium requirement. Its wrapped around a Blob as a blobPart\n * so you have no direct access to this.\n *\n * @private\n */\nclass BlobDataItem {\n  #path\n  #start\n\n  constructor (options) {\n    this.#path = options.path\n    this.#start = options.start\n    this.size = options.size\n    this.lastModified = options.lastModified\n  }\n\n  /**\n   * Slicing arguments is first validated and formatted\n   * to not be out of range by Blob.prototype.slice\n   */\n  slice (start, end) {\n    return new BlobDataItem({\n      path: this.#path,\n      lastModified: this.lastModified,\n      size: end - start,\n      start: this.#start + start\n    })\n  }\n\n  async * stream () {\n    const { mtimeMs } = await stat(this.#path)\n    if (mtimeMs > this.lastModified) {\n      throw new DOMException('The requested file could not be read, typically due to permission problems that have occurred after a reference to a file was acquired.', 'NotReadableError')\n    }\n    yield * createReadStream(this.#path, {\n      start: this.#start,\n      end: this.#start + this.size - 1\n    })\n  }\n\n  get [Symbol.toStringTag] () {\n    return 'Blob'\n  }\n}\n\nexport default blobFromSync\nexport { File, Blob, blobFrom, blobFromSync, fileFrom, fileFromSync }\n","/*! fetch-blob. MIT License. Jimmy Wärting <https://jimmy.warting.se/opensource> */\n\n// TODO (jimmywarting): in the feature use conditional loading with top level await (requires 14.x)\n// Node has recently added whatwg stream into core\n\nimport './streams.cjs'\n\n// 64 KiB (same size chrome slice theirs blob into Uint8array's)\nconst POOL_SIZE = 65536\n\n/** @param {(Blob | Uint8Array)[]} parts */\nasync function * toIterator (parts, clone = true) {\n  for (const part of parts) {\n    if ('stream' in part) {\n      yield * (/** @type {AsyncIterableIterator<Uint8Array>} */ (part.stream()))\n    } else if (ArrayBuffer.isView(part)) {\n      if (clone) {\n        let position = part.byteOffset\n        const end = part.byteOffset + part.byteLength\n        while (position !== end) {\n          const size = Math.min(end - position, POOL_SIZE)\n          const chunk = part.buffer.slice(position, position + size)\n          position += chunk.byteLength\n          yield new Uint8Array(chunk)\n        }\n      } else {\n        yield part\n      }\n    /* c8 ignore next 10 */\n    } else {\n      // For blobs that have arrayBuffer but no stream method (nodes buffer.Blob)\n      let position = 0, b = (/** @type {Blob} */ (part))\n      while (position !== b.size) {\n        const chunk = b.slice(position, Math.min(b.size, position + POOL_SIZE))\n        const buffer = await chunk.arrayBuffer()\n        position += buffer.byteLength\n        yield new Uint8Array(buffer)\n      }\n    }\n  }\n}\n\nconst _Blob = class Blob {\n  /** @type {Array.<(Blob|Uint8Array)>} */\n  #parts = []\n  #type = ''\n  #size = 0\n  #endings = 'transparent'\n\n  /**\n   * The Blob() constructor returns a new Blob object. The content\n   * of the blob consists of the concatenation of the values given\n   * in the parameter array.\n   *\n   * @param {*} blobParts\n   * @param {{ type?: string, endings?: string }} [options]\n   */\n  constructor (blobParts = [], options = {}) {\n    if (typeof blobParts !== 'object' || blobParts === null) {\n      throw new TypeError('Failed to construct \\'Blob\\': The provided value cannot be converted to a sequence.')\n    }\n\n    if (typeof blobParts[Symbol.iterator] !== 'function') {\n      throw new TypeError('Failed to construct \\'Blob\\': The object must have a callable @@iterator property.')\n    }\n\n    if (typeof options !== 'object' && typeof options !== 'function') {\n      throw new TypeError('Failed to construct \\'Blob\\': parameter 2 cannot convert to dictionary.')\n    }\n\n    if (options === null) options = {}\n\n    const encoder = new TextEncoder()\n    for (const element of blobParts) {\n      let part\n      if (ArrayBuffer.isView(element)) {\n        part = new Uint8Array(element.buffer.slice(element.byteOffset, element.byteOffset + element.byteLength))\n      } else if (element instanceof ArrayBuffer) {\n        part = new Uint8Array(element.slice(0))\n      } else if (element instanceof Blob) {\n        part = element\n      } else {\n        part = encoder.encode(`${element}`)\n      }\n\n      this.#size += ArrayBuffer.isView(part) ? part.byteLength : part.size\n      this.#parts.push(part)\n    }\n\n    this.#endings = `${options.endings === undefined ? 'transparent' : options.endings}`\n    const type = options.type === undefined ? '' : String(options.type)\n    this.#type = /^[\\x20-\\x7E]*$/.test(type) ? type : ''\n  }\n\n  /**\n   * The Blob interface's size property returns the\n   * size of the Blob in bytes.\n   */\n  get size () {\n    return this.#size\n  }\n\n  /**\n   * The type property of a Blob object returns the MIME type of the file.\n   */\n  get type () {\n    return this.#type\n  }\n\n  /**\n   * The text() method in the Blob interface returns a Promise\n   * that resolves with a string containing the contents of\n   * the blob, interpreted as UTF-8.\n   *\n   * @return {Promise<string>}\n   */\n  async text () {\n    // More optimized than using this.arrayBuffer()\n    // that requires twice as much ram\n    const decoder = new TextDecoder()\n    let str = ''\n    for await (const part of toIterator(this.#parts, false)) {\n      str += decoder.decode(part, { stream: true })\n    }\n    // Remaining\n    str += decoder.decode()\n    return str\n  }\n\n  /**\n   * The arrayBuffer() method in the Blob interface returns a\n   * Promise that resolves with the contents of the blob as\n   * binary data contained in an ArrayBuffer.\n   *\n   * @return {Promise<ArrayBuffer>}\n   */\n  async arrayBuffer () {\n    // Easier way... Just a unnecessary overhead\n    // const view = new Uint8Array(this.size);\n    // await this.stream().getReader({mode: 'byob'}).read(view);\n    // return view.buffer;\n\n    const data = new Uint8Array(this.size)\n    let offset = 0\n    for await (const chunk of toIterator(this.#parts, false)) {\n      data.set(chunk, offset)\n      offset += chunk.length\n    }\n\n    return data.buffer\n  }\n\n  stream () {\n    const it = toIterator(this.#parts, true)\n\n    return new globalThis.ReadableStream({\n      // @ts-ignore\n      type: 'bytes',\n      async pull (ctrl) {\n        const chunk = await it.next()\n        chunk.done ? ctrl.close() : ctrl.enqueue(chunk.value)\n      },\n\n      async cancel () {\n        await it.return()\n      }\n    })\n  }\n\n  /**\n   * The Blob interface's slice() method creates and returns a\n   * new Blob object which contains data from a subset of the\n   * blob on which it's called.\n   *\n   * @param {number} [start]\n   * @param {number} [end]\n   * @param {string} [type]\n   */\n  slice (start = 0, end = this.size, type = '') {\n    const { size } = this\n\n    let relativeStart = start < 0 ? Math.max(size + start, 0) : Math.min(start, size)\n    let relativeEnd = end < 0 ? Math.max(size + end, 0) : Math.min(end, size)\n\n    const span = Math.max(relativeEnd - relativeStart, 0)\n    const parts = this.#parts\n    const blobParts = []\n    let added = 0\n\n    for (const part of parts) {\n      // don't add the overflow to new blobParts\n      if (added >= span) {\n        break\n      }\n\n      const size = ArrayBuffer.isView(part) ? part.byteLength : part.size\n      if (relativeStart && size <= relativeStart) {\n        // Skip the beginning and change the relative\n        // start & end position as we skip the unwanted parts\n        relativeStart -= size\n        relativeEnd -= size\n      } else {\n        let chunk\n        if (ArrayBuffer.isView(part)) {\n          chunk = part.subarray(relativeStart, Math.min(size, relativeEnd))\n          added += chunk.byteLength\n        } else {\n          chunk = part.slice(relativeStart, Math.min(size, relativeEnd))\n          added += chunk.size\n        }\n        relativeEnd -= size\n        blobParts.push(chunk)\n        relativeStart = 0 // All next sequential parts should start at 0\n      }\n    }\n\n    const blob = new Blob([], { type: String(type).toLowerCase() })\n    blob.#size = span\n    blob.#parts = blobParts\n\n    return blob\n  }\n\n  get [Symbol.toStringTag] () {\n    return 'Blob'\n  }\n\n  static [Symbol.hasInstance] (object) {\n    return (\n      object &&\n      typeof object === 'object' &&\n      typeof object.constructor === 'function' &&\n      (\n        typeof object.stream === 'function' ||\n        typeof object.arrayBuffer === 'function'\n      ) &&\n      /^(Blob|File)$/.test(object[Symbol.toStringTag])\n    )\n  }\n}\n\nObject.defineProperties(_Blob.prototype, {\n  size: { enumerable: true },\n  type: { enumerable: true },\n  slice: { enumerable: true }\n})\n\n/** @type {typeof globalThis.Blob} */\nexport const Blob = _Blob\nexport default Blob\n","/*! formdata-polyfill. MIT License. Jimmy Wärting <https://jimmy.warting.se/opensource> */\n\nimport C from 'fetch-blob'\nimport F from 'fetch-blob/file.js'\n\nvar {toStringTag:t,iterator:i,hasInstance:h}=Symbol,\nr=Math.random,\nm='append,set,get,getAll,delete,keys,values,entries,forEach,constructor'.split(','),\nf=(a,b,c)=>(a+='',/^(Blob|File)$/.test(b && b[t])?[(c=c!==void 0?c+'':b[t]=='File'?b.name:'blob',a),b.name!==c||b[t]=='blob'?new F([b],c,b):b]:[a,b+'']),\ne=(c,f)=>(f?c:c.replace(/\\r?\\n|\\r/g,'\\r\\n')).replace(/\\n/g,'%0A').replace(/\\r/g,'%0D').replace(/\"/g,'%22'),\nx=(n, a, e)=>{if(a.length<e){throw new TypeError(`Failed to execute '${n}' on 'FormData': ${e} arguments required, but only ${a.length} present.`)}}\n\nexport const File = F\n\n/** @type {typeof globalThis.FormData} */\nexport const FormData = class FormData {\n#d=[];\nconstructor(...a){if(a.length)throw new TypeError(`Failed to construct 'FormData': parameter 1 is not of type 'HTMLFormElement'.`)}\nget [t]() {return 'FormData'}\n[i](){return this.entries()}\nstatic [h](o) {return o&&typeof o==='object'&&o[t]==='FormData'&&!m.some(m=>typeof o[m]!='function')}\nappend(...a){x('append',arguments,2);this.#d.push(f(...a))}\ndelete(a){x('delete',arguments,1);a+='';this.#d=this.#d.filter(([b])=>b!==a)}\nget(a){x('get',arguments,1);a+='';for(var b=this.#d,l=b.length,c=0;c<l;c++)if(b[c][0]===a)return b[c][1];return null}\ngetAll(a,b){x('getAll',arguments,1);b=[];a+='';this.#d.forEach(c=>c[0]===a&&b.push(c[1]));return b}\nhas(a){x('has',arguments,1);a+='';return this.#d.some(b=>b[0]===a)}\nforEach(a,b){x('forEach',arguments,1);for(var [c,d]of this)a.call(b,d,c,this)}\nset(...a){x('set',arguments,2);var b=[],c=!0;a=f(...a);this.#d.forEach(d=>{d[0]===a[0]?c&&(c=!b.push(a)):b.push(d)});c&&b.push(a);this.#d=b}\n*entries(){yield*this.#d}\n*keys(){for(var[a]of this)yield a}\n*values(){for(var[,a]of this)yield a}}\n\n/** @param {FormData} F */\nexport function formDataToBlob (F,B=C){\nvar b=`${r()}${r()}`.replace(/\\./g, '').slice(-28).padStart(32, '-'),c=[],p=`--${b}\\r\\nContent-Disposition: form-data; name=\"`\nF.forEach((v,n)=>typeof v=='string'\n?c.push(p+e(n)+`\"\\r\\n\\r\\n${v.replace(/\\r(?!\\n)|(?<!\\r)\\n/g, '\\r\\n')}\\r\\n`)\n:c.push(p+e(n)+`\"; filename=\"${e(v.name, 1)}\"\\r\\nContent-Type: ${v.type||\"application/octet-stream\"}\\r\\n\\r\\n`, v, '\\r\\n'))\nc.push(`--${b}--`)\nreturn new B(c,{type:\"multipart/form-data; boundary=\"+b})}\n","'use strict'\nconst MiniPass = require('minipass')\nconst EE = require('events').EventEmitter\nconst fs = require('fs')\n\nlet writev = fs.writev\n/* istanbul ignore next */\nif (!writev) {\n  // This entire block can be removed if support for earlier than Node.js\n  // 12.9.0 is not needed.\n  const binding = process.binding('fs')\n  const FSReqWrap = binding.FSReqWrap || binding.FSReqCallback\n\n  writev = (fd, iovec, pos, cb) => {\n    const done = (er, bw) => cb(er, bw, iovec)\n    const req = new FSReqWrap()\n    req.oncomplete = done\n    binding.writeBuffers(fd, iovec, pos, req)\n  }\n}\n\nconst _autoClose = Symbol('_autoClose')\nconst _close = Symbol('_close')\nconst _ended = Symbol('_ended')\nconst _fd = Symbol('_fd')\nconst _finished = Symbol('_finished')\nconst _flags = Symbol('_flags')\nconst _flush = Symbol('_flush')\nconst _handleChunk = Symbol('_handleChunk')\nconst _makeBuf = Symbol('_makeBuf')\nconst _mode = Symbol('_mode')\nconst _needDrain = Symbol('_needDrain')\nconst _onerror = Symbol('_onerror')\nconst _onopen = Symbol('_onopen')\nconst _onread = Symbol('_onread')\nconst _onwrite = Symbol('_onwrite')\nconst _open = Symbol('_open')\nconst _path = Symbol('_path')\nconst _pos = Symbol('_pos')\nconst _queue = Symbol('_queue')\nconst _read = Symbol('_read')\nconst _readSize = Symbol('_readSize')\nconst _reading = Symbol('_reading')\nconst _remain = Symbol('_remain')\nconst _size = Symbol('_size')\nconst _write = Symbol('_write')\nconst _writing = Symbol('_writing')\nconst _defaultFlag = Symbol('_defaultFlag')\nconst _errored = Symbol('_errored')\n\nclass ReadStream extends MiniPass {\n  constructor (path, opt) {\n    opt = opt || {}\n    super(opt)\n\n    this.readable = true\n    this.writable = false\n\n    if (typeof path !== 'string')\n      throw new TypeError('path must be a string')\n\n    this[_errored] = false\n    this[_fd] = typeof opt.fd === 'number' ? opt.fd : null\n    this[_path] = path\n    this[_readSize] = opt.readSize || 16*1024*1024\n    this[_reading] = false\n    this[_size] = typeof opt.size === 'number' ? opt.size : Infinity\n    this[_remain] = this[_size]\n    this[_autoClose] = typeof opt.autoClose === 'boolean' ?\n      opt.autoClose : true\n\n    if (typeof this[_fd] === 'number')\n      this[_read]()\n    else\n      this[_open]()\n  }\n\n  get fd () { return this[_fd] }\n  get path () { return this[_path] }\n\n  write () {\n    throw new TypeError('this is a readable stream')\n  }\n\n  end () {\n    throw new TypeError('this is a readable stream')\n  }\n\n  [_open] () {\n    fs.open(this[_path], 'r', (er, fd) => this[_onopen](er, fd))\n  }\n\n  [_onopen] (er, fd) {\n    if (er)\n      this[_onerror](er)\n    else {\n      this[_fd] = fd\n      this.emit('open', fd)\n      this[_read]()\n    }\n  }\n\n  [_makeBuf] () {\n    return Buffer.allocUnsafe(Math.min(this[_readSize], this[_remain]))\n  }\n\n  [_read] () {\n    if (!this[_reading]) {\n      this[_reading] = true\n      const buf = this[_makeBuf]()\n      /* istanbul ignore if */\n      if (buf.length === 0)\n        return process.nextTick(() => this[_onread](null, 0, buf))\n      fs.read(this[_fd], buf, 0, buf.length, null, (er, br, buf) =>\n        this[_onread](er, br, buf))\n    }\n  }\n\n  [_onread] (er, br, buf) {\n    this[_reading] = false\n    if (er)\n      this[_onerror](er)\n    else if (this[_handleChunk](br, buf))\n      this[_read]()\n  }\n\n  [_close] () {\n    if (this[_autoClose] && typeof this[_fd] === 'number') {\n      const fd = this[_fd]\n      this[_fd] = null\n      fs.close(fd, er => er ? this.emit('error', er) : this.emit('close'))\n    }\n  }\n\n  [_onerror] (er) {\n    this[_reading] = true\n    this[_close]()\n    this.emit('error', er)\n  }\n\n  [_handleChunk] (br, buf) {\n    let ret = false\n    // no effect if infinite\n    this[_remain] -= br\n    if (br > 0)\n      ret = super.write(br < buf.length ? buf.slice(0, br) : buf)\n\n    if (br === 0 || this[_remain] <= 0) {\n      ret = false\n      this[_close]()\n      super.end()\n    }\n\n    return ret\n  }\n\n  emit (ev, data) {\n    switch (ev) {\n      case 'prefinish':\n      case 'finish':\n        break\n\n      case 'drain':\n        if (typeof this[_fd] === 'number')\n          this[_read]()\n        break\n\n      case 'error':\n        if (this[_errored])\n          return\n        this[_errored] = true\n        return super.emit(ev, data)\n\n      default:\n        return super.emit(ev, data)\n    }\n  }\n}\n\nclass ReadStreamSync extends ReadStream {\n  [_open] () {\n    let threw = true\n    try {\n      this[_onopen](null, fs.openSync(this[_path], 'r'))\n      threw = false\n    } finally {\n      if (threw)\n        this[_close]()\n    }\n  }\n\n  [_read] () {\n    let threw = true\n    try {\n      if (!this[_reading]) {\n        this[_reading] = true\n        do {\n          const buf = this[_makeBuf]()\n          /* istanbul ignore next */\n          const br = buf.length === 0 ? 0\n            : fs.readSync(this[_fd], buf, 0, buf.length, null)\n          if (!this[_handleChunk](br, buf))\n            break\n        } while (true)\n        this[_reading] = false\n      }\n      threw = false\n    } finally {\n      if (threw)\n        this[_close]()\n    }\n  }\n\n  [_close] () {\n    if (this[_autoClose] && typeof this[_fd] === 'number') {\n      const fd = this[_fd]\n      this[_fd] = null\n      fs.closeSync(fd)\n      this.emit('close')\n    }\n  }\n}\n\nclass WriteStream extends EE {\n  constructor (path, opt) {\n    opt = opt || {}\n    super(opt)\n    this.readable = false\n    this.writable = true\n    this[_errored] = false\n    this[_writing] = false\n    this[_ended] = false\n    this[_needDrain] = false\n    this[_queue] = []\n    this[_path] = path\n    this[_fd] = typeof opt.fd === 'number' ? opt.fd : null\n    this[_mode] = opt.mode === undefined ? 0o666 : opt.mode\n    this[_pos] = typeof opt.start === 'number' ? opt.start : null\n    this[_autoClose] = typeof opt.autoClose === 'boolean' ?\n      opt.autoClose : true\n\n    // truncating makes no sense when writing into the middle\n    const defaultFlag = this[_pos] !== null ? 'r+' : 'w'\n    this[_defaultFlag] = opt.flags === undefined\n    this[_flags] = this[_defaultFlag] ? defaultFlag : opt.flags\n\n    if (this[_fd] === null)\n      this[_open]()\n  }\n\n  emit (ev, data) {\n    if (ev === 'error') {\n      if (this[_errored])\n        return\n      this[_errored] = true\n    }\n    return super.emit(ev, data)\n  }\n\n\n  get fd () { return this[_fd] }\n  get path () { return this[_path] }\n\n  [_onerror] (er) {\n    this[_close]()\n    this[_writing] = true\n    this.emit('error', er)\n  }\n\n  [_open] () {\n    fs.open(this[_path], this[_flags], this[_mode],\n      (er, fd) => this[_onopen](er, fd))\n  }\n\n  [_onopen] (er, fd) {\n    if (this[_defaultFlag] &&\n        this[_flags] === 'r+' &&\n        er && er.code === 'ENOENT') {\n      this[_flags] = 'w'\n      this[_open]()\n    } else if (er)\n      this[_onerror](er)\n    else {\n      this[_fd] = fd\n      this.emit('open', fd)\n      this[_flush]()\n    }\n  }\n\n  end (buf, enc) {\n    if (buf)\n      this.write(buf, enc)\n\n    this[_ended] = true\n\n    // synthetic after-write logic, where drain/finish live\n    if (!this[_writing] && !this[_queue].length &&\n        typeof this[_fd] === 'number')\n      this[_onwrite](null, 0)\n    return this\n  }\n\n  write (buf, enc) {\n    if (typeof buf === 'string')\n      buf = Buffer.from(buf, enc)\n\n    if (this[_ended]) {\n      this.emit('error', new Error('write() after end()'))\n      return false\n    }\n\n    if (this[_fd] === null || this[_writing] || this[_queue].length) {\n      this[_queue].push(buf)\n      this[_needDrain] = true\n      return false\n    }\n\n    this[_writing] = true\n    this[_write](buf)\n    return true\n  }\n\n  [_write] (buf) {\n    fs.write(this[_fd], buf, 0, buf.length, this[_pos], (er, bw) =>\n      this[_onwrite](er, bw))\n  }\n\n  [_onwrite] (er, bw) {\n    if (er)\n      this[_onerror](er)\n    else {\n      if (this[_pos] !== null)\n        this[_pos] += bw\n      if (this[_queue].length)\n        this[_flush]()\n      else {\n        this[_writing] = false\n\n        if (this[_ended] && !this[_finished]) {\n          this[_finished] = true\n          this[_close]()\n          this.emit('finish')\n        } else if (this[_needDrain]) {\n          this[_needDrain] = false\n          this.emit('drain')\n        }\n      }\n    }\n  }\n\n  [_flush] () {\n    if (this[_queue].length === 0) {\n      if (this[_ended])\n        this[_onwrite](null, 0)\n    } else if (this[_queue].length === 1)\n      this[_write](this[_queue].pop())\n    else {\n      const iovec = this[_queue]\n      this[_queue] = []\n      writev(this[_fd], iovec, this[_pos],\n        (er, bw) => this[_onwrite](er, bw))\n    }\n  }\n\n  [_close] () {\n    if (this[_autoClose] && typeof this[_fd] === 'number') {\n      const fd = this[_fd]\n      this[_fd] = null\n      fs.close(fd, er => er ? this.emit('error', er) : this.emit('close'))\n    }\n  }\n}\n\nclass WriteStreamSync extends WriteStream {\n  [_open] () {\n    let fd\n    // only wrap in a try{} block if we know we'll retry, to avoid\n    // the rethrow obscuring the error's source frame in most cases.\n    if (this[_defaultFlag] && this[_flags] === 'r+') {\n      try {\n        fd = fs.openSync(this[_path], this[_flags], this[_mode])\n      } catch (er) {\n        if (er.code === 'ENOENT') {\n          this[_flags] = 'w'\n          return this[_open]()\n        } else\n          throw er\n      }\n    } else\n      fd = fs.openSync(this[_path], this[_flags], this[_mode])\n\n    this[_onopen](null, fd)\n  }\n\n  [_close] () {\n    if (this[_autoClose] && typeof this[_fd] === 'number') {\n      const fd = this[_fd]\n      this[_fd] = null\n      fs.closeSync(fd)\n      this.emit('close')\n    }\n  }\n\n  [_write] (buf) {\n    // throw the original, but try to close if it fails\n    let threw = true\n    try {\n      this[_onwrite](null,\n        fs.writeSync(this[_fd], buf, 0, buf.length, this[_pos]))\n      threw = false\n    } finally {\n      if (threw)\n        try { this[_close]() } catch (_) {}\n    }\n  }\n}\n\nexports.ReadStream = ReadStream\nexports.ReadStreamSync = ReadStreamSync\n\nexports.WriteStream = WriteStream\nexports.WriteStreamSync = WriteStreamSync\n","'use strict'\nconst proc = typeof process === 'object' && process ? process : {\n  stdout: null,\n  stderr: null,\n}\nconst EE = require('events')\nconst Stream = require('stream')\nconst Yallist = require('yallist')\nconst SD = require('string_decoder').StringDecoder\n\nconst EOF = Symbol('EOF')\nconst MAYBE_EMIT_END = Symbol('maybeEmitEnd')\nconst EMITTED_END = Symbol('emittedEnd')\nconst EMITTING_END = Symbol('emittingEnd')\nconst EMITTED_ERROR = Symbol('emittedError')\nconst CLOSED = Symbol('closed')\nconst READ = Symbol('read')\nconst FLUSH = Symbol('flush')\nconst FLUSHCHUNK = Symbol('flushChunk')\nconst ENCODING = Symbol('encoding')\nconst DECODER = Symbol('decoder')\nconst FLOWING = Symbol('flowing')\nconst PAUSED = Symbol('paused')\nconst RESUME = Symbol('resume')\nconst BUFFERLENGTH = Symbol('bufferLength')\nconst BUFFERPUSH = Symbol('bufferPush')\nconst BUFFERSHIFT = Symbol('bufferShift')\nconst OBJECTMODE = Symbol('objectMode')\nconst DESTROYED = Symbol('destroyed')\n\n// TODO remove when Node v8 support drops\nconst doIter = global._MP_NO_ITERATOR_SYMBOLS_  !== '1'\nconst ASYNCITERATOR = doIter && Symbol.asyncIterator\n  || Symbol('asyncIterator not implemented')\nconst ITERATOR = doIter && Symbol.iterator\n  || Symbol('iterator not implemented')\n\n// events that mean 'the stream is over'\n// these are treated specially, and re-emitted\n// if they are listened for after emitting.\nconst isEndish = ev =>\n  ev === 'end' ||\n  ev === 'finish' ||\n  ev === 'prefinish'\n\nconst isArrayBuffer = b => b instanceof ArrayBuffer ||\n  typeof b === 'object' &&\n  b.constructor &&\n  b.constructor.name === 'ArrayBuffer' &&\n  b.byteLength >= 0\n\nconst isArrayBufferView = b => !Buffer.isBuffer(b) && ArrayBuffer.isView(b)\n\nmodule.exports = class Minipass extends Stream {\n  constructor (options) {\n    super()\n    this[FLOWING] = false\n    // whether we're explicitly paused\n    this[PAUSED] = false\n    this.pipes = new Yallist()\n    this.buffer = new Yallist()\n    this[OBJECTMODE] = options && options.objectMode || false\n    if (this[OBJECTMODE])\n      this[ENCODING] = null\n    else\n      this[ENCODING] = options && options.encoding || null\n    if (this[ENCODING] === 'buffer')\n      this[ENCODING] = null\n    this[DECODER] = this[ENCODING] ? new SD(this[ENCODING]) : null\n    this[EOF] = false\n    this[EMITTED_END] = false\n    this[EMITTING_END] = false\n    this[CLOSED] = false\n    this[EMITTED_ERROR] = null\n    this.writable = true\n    this.readable = true\n    this[BUFFERLENGTH] = 0\n    this[DESTROYED] = false\n  }\n\n  get bufferLength () { return this[BUFFERLENGTH] }\n\n  get encoding () { return this[ENCODING] }\n  set encoding (enc) {\n    if (this[OBJECTMODE])\n      throw new Error('cannot set encoding in objectMode')\n\n    if (this[ENCODING] && enc !== this[ENCODING] &&\n        (this[DECODER] && this[DECODER].lastNeed || this[BUFFERLENGTH]))\n      throw new Error('cannot change encoding')\n\n    if (this[ENCODING] !== enc) {\n      this[DECODER] = enc ? new SD(enc) : null\n      if (this.buffer.length)\n        this.buffer = this.buffer.map(chunk => this[DECODER].write(chunk))\n    }\n\n    this[ENCODING] = enc\n  }\n\n  setEncoding (enc) {\n    this.encoding = enc\n  }\n\n  get objectMode () { return this[OBJECTMODE] }\n  set objectMode (om) { this[OBJECTMODE] = this[OBJECTMODE] || !!om }\n\n  write (chunk, encoding, cb) {\n    if (this[EOF])\n      throw new Error('write after end')\n\n    if (this[DESTROYED]) {\n      this.emit('error', Object.assign(\n        new Error('Cannot call write after a stream was destroyed'),\n        { code: 'ERR_STREAM_DESTROYED' }\n      ))\n      return true\n    }\n\n    if (typeof encoding === 'function')\n      cb = encoding, encoding = 'utf8'\n\n    if (!encoding)\n      encoding = 'utf8'\n\n    // convert array buffers and typed array views into buffers\n    // at some point in the future, we may want to do the opposite!\n    // leave strings and buffers as-is\n    // anything else switches us into object mode\n    if (!this[OBJECTMODE] && !Buffer.isBuffer(chunk)) {\n      if (isArrayBufferView(chunk))\n        chunk = Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength)\n      else if (isArrayBuffer(chunk))\n        chunk = Buffer.from(chunk)\n      else if (typeof chunk !== 'string')\n        // use the setter so we throw if we have encoding set\n        this.objectMode = true\n    }\n\n    // this ensures at this point that the chunk is a buffer or string\n    // don't buffer it up or send it to the decoder\n    if (!this.objectMode && !chunk.length) {\n      if (this[BUFFERLENGTH] !== 0)\n        this.emit('readable')\n      if (cb)\n        cb()\n      return this.flowing\n    }\n\n    // fast-path writing strings of same encoding to a stream with\n    // an empty buffer, skipping the buffer/decoder dance\n    if (typeof chunk === 'string' && !this[OBJECTMODE] &&\n        // unless it is a string already ready for us to use\n        !(encoding === this[ENCODING] && !this[DECODER].lastNeed)) {\n      chunk = Buffer.from(chunk, encoding)\n    }\n\n    if (Buffer.isBuffer(chunk) && this[ENCODING])\n      chunk = this[DECODER].write(chunk)\n\n    if (this.flowing) {\n      // if we somehow have something in the buffer, but we think we're\n      // flowing, then we need to flush all that out first, or we get\n      // chunks coming in out of order.  Can't emit 'drain' here though,\n      // because we're mid-write, so that'd be bad.\n      if (this[BUFFERLENGTH] !== 0)\n        this[FLUSH](true)\n\n      // if we are still flowing after flushing the buffer we can emit the\n      // chunk otherwise we have to buffer it.\n      this.flowing\n        ? this.emit('data', chunk)\n        : this[BUFFERPUSH](chunk)\n    } else\n      this[BUFFERPUSH](chunk)\n\n    if (this[BUFFERLENGTH] !== 0)\n      this.emit('readable')\n\n    if (cb)\n      cb()\n\n    return this.flowing\n  }\n\n  read (n) {\n    if (this[DESTROYED])\n      return null\n\n    try {\n      if (this[BUFFERLENGTH] === 0 || n === 0 || n > this[BUFFERLENGTH])\n        return null\n\n      if (this[OBJECTMODE])\n        n = null\n\n      if (this.buffer.length > 1 && !this[OBJECTMODE]) {\n        if (this.encoding)\n          this.buffer = new Yallist([\n            Array.from(this.buffer).join('')\n          ])\n        else\n          this.buffer = new Yallist([\n            Buffer.concat(Array.from(this.buffer), this[BUFFERLENGTH])\n          ])\n      }\n\n      return this[READ](n || null, this.buffer.head.value)\n    } finally {\n      this[MAYBE_EMIT_END]()\n    }\n  }\n\n  [READ] (n, chunk) {\n    if (n === chunk.length || n === null)\n      this[BUFFERSHIFT]()\n    else {\n      this.buffer.head.value = chunk.slice(n)\n      chunk = chunk.slice(0, n)\n      this[BUFFERLENGTH] -= n\n    }\n\n    this.emit('data', chunk)\n\n    if (!this.buffer.length && !this[EOF])\n      this.emit('drain')\n\n    return chunk\n  }\n\n  end (chunk, encoding, cb) {\n    if (typeof chunk === 'function')\n      cb = chunk, chunk = null\n    if (typeof encoding === 'function')\n      cb = encoding, encoding = 'utf8'\n    if (chunk)\n      this.write(chunk, encoding)\n    if (cb)\n      this.once('end', cb)\n    this[EOF] = true\n    this.writable = false\n\n    // if we haven't written anything, then go ahead and emit,\n    // even if we're not reading.\n    // we'll re-emit if a new 'end' listener is added anyway.\n    // This makes MP more suitable to write-only use cases.\n    if (this.flowing || !this[PAUSED])\n      this[MAYBE_EMIT_END]()\n    return this\n  }\n\n  // don't let the internal resume be overwritten\n  [RESUME] () {\n    if (this[DESTROYED])\n      return\n\n    this[PAUSED] = false\n    this[FLOWING] = true\n    this.emit('resume')\n    if (this.buffer.length)\n      this[FLUSH]()\n    else if (this[EOF])\n      this[MAYBE_EMIT_END]()\n    else\n      this.emit('drain')\n  }\n\n  resume () {\n    return this[RESUME]()\n  }\n\n  pause () {\n    this[FLOWING] = false\n    this[PAUSED] = true\n  }\n\n  get destroyed () {\n    return this[DESTROYED]\n  }\n\n  get flowing () {\n    return this[FLOWING]\n  }\n\n  get paused () {\n    return this[PAUSED]\n  }\n\n  [BUFFERPUSH] (chunk) {\n    if (this[OBJECTMODE])\n      this[BUFFERLENGTH] += 1\n    else\n      this[BUFFERLENGTH] += chunk.length\n    return this.buffer.push(chunk)\n  }\n\n  [BUFFERSHIFT] () {\n    if (this.buffer.length) {\n      if (this[OBJECTMODE])\n        this[BUFFERLENGTH] -= 1\n      else\n        this[BUFFERLENGTH] -= this.buffer.head.value.length\n    }\n    return this.buffer.shift()\n  }\n\n  [FLUSH] (noDrain) {\n    do {} while (this[FLUSHCHUNK](this[BUFFERSHIFT]()))\n\n    if (!noDrain && !this.buffer.length && !this[EOF])\n      this.emit('drain')\n  }\n\n  [FLUSHCHUNK] (chunk) {\n    return chunk ? (this.emit('data', chunk), this.flowing) : false\n  }\n\n  pipe (dest, opts) {\n    if (this[DESTROYED])\n      return\n\n    const ended = this[EMITTED_END]\n    opts = opts || {}\n    if (dest === proc.stdout || dest === proc.stderr)\n      opts.end = false\n    else\n      opts.end = opts.end !== false\n\n    const p = { dest: dest, opts: opts, ondrain: _ => this[RESUME]() }\n    this.pipes.push(p)\n\n    dest.on('drain', p.ondrain)\n    this[RESUME]()\n    // piping an ended stream ends immediately\n    if (ended && p.opts.end)\n      p.dest.end()\n    return dest\n  }\n\n  addListener (ev, fn) {\n    return this.on(ev, fn)\n  }\n\n  on (ev, fn) {\n    try {\n      return super.on(ev, fn)\n    } finally {\n      if (ev === 'data' && !this.pipes.length && !this.flowing)\n        this[RESUME]()\n      else if (isEndish(ev) && this[EMITTED_END]) {\n        super.emit(ev)\n        this.removeAllListeners(ev)\n      } else if (ev === 'error' && this[EMITTED_ERROR]) {\n        fn.call(this, this[EMITTED_ERROR])\n      }\n    }\n  }\n\n  get emittedEnd () {\n    return this[EMITTED_END]\n  }\n\n  [MAYBE_EMIT_END] () {\n    if (!this[EMITTING_END] &&\n        !this[EMITTED_END] &&\n        !this[DESTROYED] &&\n        this.buffer.length === 0 &&\n        this[EOF]) {\n      this[EMITTING_END] = true\n      this.emit('end')\n      this.emit('prefinish')\n      this.emit('finish')\n      if (this[CLOSED])\n        this.emit('close')\n      this[EMITTING_END] = false\n    }\n  }\n\n  emit (ev, data) {\n    // error and close are only events allowed after calling destroy()\n    if (ev !== 'error' && ev !== 'close' && ev !== DESTROYED && this[DESTROYED])\n      return\n    else if (ev === 'data') {\n      if (!data)\n        return\n\n      if (this.pipes.length)\n        this.pipes.forEach(p =>\n          p.dest.write(data) === false && this.pause())\n    } else if (ev === 'end') {\n      // only actual end gets this treatment\n      if (this[EMITTED_END] === true)\n        return\n\n      this[EMITTED_END] = true\n      this.readable = false\n\n      if (this[DECODER]) {\n        data = this[DECODER].end()\n        if (data) {\n          this.pipes.forEach(p => p.dest.write(data))\n          super.emit('data', data)\n        }\n      }\n\n      this.pipes.forEach(p => {\n        p.dest.removeListener('drain', p.ondrain)\n        if (p.opts.end)\n          p.dest.end()\n      })\n    } else if (ev === 'close') {\n      this[CLOSED] = true\n      // don't emit close before 'end' and 'finish'\n      if (!this[EMITTED_END] && !this[DESTROYED])\n        return\n    } else if (ev === 'error') {\n      this[EMITTED_ERROR] = data\n    }\n\n    // TODO: replace with a spread operator when Node v4 support drops\n    const args = new Array(arguments.length)\n    args[0] = ev\n    args[1] = data\n    if (arguments.length > 2) {\n      for (let i = 2; i < arguments.length; i++) {\n        args[i] = arguments[i]\n      }\n    }\n\n    try {\n      return super.emit.apply(this, args)\n    } finally {\n      if (!isEndish(ev))\n        this[MAYBE_EMIT_END]()\n      else\n        this.removeAllListeners(ev)\n    }\n  }\n\n  // const all = await stream.collect()\n  collect () {\n    const buf = []\n    if (!this[OBJECTMODE])\n      buf.dataLength = 0\n    // set the promise first, in case an error is raised\n    // by triggering the flow here.\n    const p = this.promise()\n    this.on('data', c => {\n      buf.push(c)\n      if (!this[OBJECTMODE])\n        buf.dataLength += c.length\n    })\n    return p.then(() => buf)\n  }\n\n  // const data = await stream.concat()\n  concat () {\n    return this[OBJECTMODE]\n      ? Promise.reject(new Error('cannot concat in objectMode'))\n      : this.collect().then(buf =>\n          this[OBJECTMODE]\n            ? Promise.reject(new Error('cannot concat in objectMode'))\n            : this[ENCODING] ? buf.join('') : Buffer.concat(buf, buf.dataLength))\n  }\n\n  // stream.promise().then(() => done, er => emitted error)\n  promise () {\n    return new Promise((resolve, reject) => {\n      this.on(DESTROYED, () => reject(new Error('stream destroyed')))\n      this.on('error', er => reject(er))\n      this.on('end', () => resolve())\n    })\n  }\n\n  // for await (let chunk of stream)\n  [ASYNCITERATOR] () {\n    const next = () => {\n      const res = this.read()\n      if (res !== null)\n        return Promise.resolve({ done: false, value: res })\n\n      if (this[EOF])\n        return Promise.resolve({ done: true })\n\n      let resolve = null\n      let reject = null\n      const onerr = er => {\n        this.removeListener('data', ondata)\n        this.removeListener('end', onend)\n        reject(er)\n      }\n      const ondata = value => {\n        this.removeListener('error', onerr)\n        this.removeListener('end', onend)\n        this.pause()\n        resolve({ value: value, done: !!this[EOF] })\n      }\n      const onend = () => {\n        this.removeListener('error', onerr)\n        this.removeListener('data', ondata)\n        resolve({ done: true })\n      }\n      const ondestroy = () => onerr(new Error('stream destroyed'))\n      return new Promise((res, rej) => {\n        reject = rej\n        resolve = res\n        this.once(DESTROYED, ondestroy)\n        this.once('error', onerr)\n        this.once('end', onend)\n        this.once('data', ondata)\n      })\n    }\n\n    return { next }\n  }\n\n  // for (let chunk of stream)\n  [ITERATOR] () {\n    const next = () => {\n      const value = this.read()\n      const done = value === null\n      return { value, done }\n    }\n    return { next }\n  }\n\n  destroy (er) {\n    if (this[DESTROYED]) {\n      if (er)\n        this.emit('error', er)\n      else\n        this.emit(DESTROYED)\n      return this\n    }\n\n    this[DESTROYED] = true\n\n    // throw away all buffered data, it's never coming out\n    this.buffer = new Yallist()\n    this[BUFFERLENGTH] = 0\n\n    if (typeof this.close === 'function' && !this[CLOSED])\n      this.close()\n\n    if (er)\n      this.emit('error', er)\n    else // if no error to emit, still reject pending promises\n      this.emit(DESTROYED)\n\n    return this\n  }\n\n  static isStream (s) {\n    return !!s && (s instanceof Minipass || s instanceof Stream ||\n      s instanceof EE && (\n        typeof s.pipe === 'function' || // readable\n        (typeof s.write === 'function' && typeof s.end === 'function') // writable\n      ))\n  }\n}\n","// Update with any zlib constants that are added or changed in the future.\n// Node v6 didn't export this, so we just hard code the version and rely\n// on all the other hard-coded values from zlib v4736.  When node v6\n// support drops, we can just export the realZlibConstants object.\nconst realZlibConstants = require('zlib').constants ||\n  /* istanbul ignore next */ { ZLIB_VERNUM: 4736 }\n\nmodule.exports = Object.freeze(Object.assign(Object.create(null), {\n  Z_NO_FLUSH: 0,\n  Z_PARTIAL_FLUSH: 1,\n  Z_SYNC_FLUSH: 2,\n  Z_FULL_FLUSH: 3,\n  Z_FINISH: 4,\n  Z_BLOCK: 5,\n  Z_OK: 0,\n  Z_STREAM_END: 1,\n  Z_NEED_DICT: 2,\n  Z_ERRNO: -1,\n  Z_STREAM_ERROR: -2,\n  Z_DATA_ERROR: -3,\n  Z_MEM_ERROR: -4,\n  Z_BUF_ERROR: -5,\n  Z_VERSION_ERROR: -6,\n  Z_NO_COMPRESSION: 0,\n  Z_BEST_SPEED: 1,\n  Z_BEST_COMPRESSION: 9,\n  Z_DEFAULT_COMPRESSION: -1,\n  Z_FILTERED: 1,\n  Z_HUFFMAN_ONLY: 2,\n  Z_RLE: 3,\n  Z_FIXED: 4,\n  Z_DEFAULT_STRATEGY: 0,\n  DEFLATE: 1,\n  INFLATE: 2,\n  GZIP: 3,\n  GUNZIP: 4,\n  DEFLATERAW: 5,\n  INFLATERAW: 6,\n  UNZIP: 7,\n  BROTLI_DECODE: 8,\n  BROTLI_ENCODE: 9,\n  Z_MIN_WINDOWBITS: 8,\n  Z_MAX_WINDOWBITS: 15,\n  Z_DEFAULT_WINDOWBITS: 15,\n  Z_MIN_CHUNK: 64,\n  Z_MAX_CHUNK: Infinity,\n  Z_DEFAULT_CHUNK: 16384,\n  Z_MIN_MEMLEVEL: 1,\n  Z_MAX_MEMLEVEL: 9,\n  Z_DEFAULT_MEMLEVEL: 8,\n  Z_MIN_LEVEL: -1,\n  Z_MAX_LEVEL: 9,\n  Z_DEFAULT_LEVEL: -1,\n  BROTLI_OPERATION_PROCESS: 0,\n  BROTLI_OPERATION_FLUSH: 1,\n  BROTLI_OPERATION_FINISH: 2,\n  BROTLI_OPERATION_EMIT_METADATA: 3,\n  BROTLI_MODE_GENERIC: 0,\n  BROTLI_MODE_TEXT: 1,\n  BROTLI_MODE_FONT: 2,\n  BROTLI_DEFAULT_MODE: 0,\n  BROTLI_MIN_QUALITY: 0,\n  BROTLI_MAX_QUALITY: 11,\n  BROTLI_DEFAULT_QUALITY: 11,\n  BROTLI_MIN_WINDOW_BITS: 10,\n  BROTLI_MAX_WINDOW_BITS: 24,\n  BROTLI_LARGE_MAX_WINDOW_BITS: 30,\n  BROTLI_DEFAULT_WINDOW: 22,\n  BROTLI_MIN_INPUT_BLOCK_BITS: 16,\n  BROTLI_MAX_INPUT_BLOCK_BITS: 24,\n  BROTLI_PARAM_MODE: 0,\n  BROTLI_PARAM_QUALITY: 1,\n  BROTLI_PARAM_LGWIN: 2,\n  BROTLI_PARAM_LGBLOCK: 3,\n  BROTLI_PARAM_DISABLE_LITERAL_CONTEXT_MODELING: 4,\n  BROTLI_PARAM_SIZE_HINT: 5,\n  BROTLI_PARAM_LARGE_WINDOW: 6,\n  BROTLI_PARAM_NPOSTFIX: 7,\n  BROTLI_PARAM_NDIRECT: 8,\n  BROTLI_DECODER_RESULT_ERROR: 0,\n  BROTLI_DECODER_RESULT_SUCCESS: 1,\n  BROTLI_DECODER_RESULT_NEEDS_MORE_INPUT: 2,\n  BROTLI_DECODER_RESULT_NEEDS_MORE_OUTPUT: 3,\n  BROTLI_DECODER_PARAM_DISABLE_RING_BUFFER_REALLOCATION: 0,\n  BROTLI_DECODER_PARAM_LARGE_WINDOW: 1,\n  BROTLI_DECODER_NO_ERROR: 0,\n  BROTLI_DECODER_SUCCESS: 1,\n  BROTLI_DECODER_NEEDS_MORE_INPUT: 2,\n  BROTLI_DECODER_NEEDS_MORE_OUTPUT: 3,\n  BROTLI_DECODER_ERROR_FORMAT_EXUBERANT_NIBBLE: -1,\n  BROTLI_DECODER_ERROR_FORMAT_RESERVED: -2,\n  BROTLI_DECODER_ERROR_FORMAT_EXUBERANT_META_NIBBLE: -3,\n  BROTLI_DECODER_ERROR_FORMAT_SIMPLE_HUFFMAN_ALPHABET: -4,\n  BROTLI_DECODER_ERROR_FORMAT_SIMPLE_HUFFMAN_SAME: -5,\n  BROTLI_DECODER_ERROR_FORMAT_CL_SPACE: -6,\n  BROTLI_DECODER_ERROR_FORMAT_HUFFMAN_SPACE: -7,\n  BROTLI_DECODER_ERROR_FORMAT_CONTEXT_MAP_REPEAT: -8,\n  BROTLI_DECODER_ERROR_FORMAT_BLOCK_LENGTH_1: -9,\n  BROTLI_DECODER_ERROR_FORMAT_BLOCK_LENGTH_2: -10,\n  BROTLI_DECODER_ERROR_FORMAT_TRANSFORM: -11,\n  BROTLI_DECODER_ERROR_FORMAT_DICTIONARY: -12,\n  BROTLI_DECODER_ERROR_FORMAT_WINDOW_BITS: -13,\n  BROTLI_DECODER_ERROR_FORMAT_PADDING_1: -14,\n  BROTLI_DECODER_ERROR_FORMAT_PADDING_2: -15,\n  BROTLI_DECODER_ERROR_FORMAT_DISTANCE: -16,\n  BROTLI_DECODER_ERROR_DICTIONARY_NOT_SET: -19,\n  BROTLI_DECODER_ERROR_INVALID_ARGUMENTS: -20,\n  BROTLI_DECODER_ERROR_ALLOC_CONTEXT_MODES: -21,\n  BROTLI_DECODER_ERROR_ALLOC_TREE_GROUPS: -22,\n  BROTLI_DECODER_ERROR_ALLOC_CONTEXT_MAP: -25,\n  BROTLI_DECODER_ERROR_ALLOC_RING_BUFFER_1: -26,\n  BROTLI_DECODER_ERROR_ALLOC_RING_BUFFER_2: -27,\n  BROTLI_DECODER_ERROR_ALLOC_BLOCK_TYPE_TREES: -30,\n  BROTLI_DECODER_ERROR_UNREACHABLE: -31,\n}, realZlibConstants))\n","'use strict'\n\nconst assert = require('assert')\nconst Buffer = require('buffer').Buffer\nconst realZlib = require('zlib')\n\nconst constants = exports.constants = require('./constants.js')\nconst Minipass = require('minipass')\n\nconst OriginalBufferConcat = Buffer.concat\n\nconst _superWrite = Symbol('_superWrite')\nclass ZlibError extends Error {\n  constructor (err) {\n    super('zlib: ' + err.message)\n    this.code = err.code\n    this.errno = err.errno\n    /* istanbul ignore if */\n    if (!this.code)\n      this.code = 'ZLIB_ERROR'\n\n    this.message = 'zlib: ' + err.message\n    Error.captureStackTrace(this, this.constructor)\n  }\n\n  get name () {\n    return 'ZlibError'\n  }\n}\n\n// the Zlib class they all inherit from\n// This thing manages the queue of requests, and returns\n// true or false if there is anything in the queue when\n// you call the .write() method.\nconst _opts = Symbol('opts')\nconst _flushFlag = Symbol('flushFlag')\nconst _finishFlushFlag = Symbol('finishFlushFlag')\nconst _fullFlushFlag = Symbol('fullFlushFlag')\nconst _handle = Symbol('handle')\nconst _onError = Symbol('onError')\nconst _sawError = Symbol('sawError')\nconst _level = Symbol('level')\nconst _strategy = Symbol('strategy')\nconst _ended = Symbol('ended')\nconst _defaultFullFlush = Symbol('_defaultFullFlush')\n\nclass ZlibBase extends Minipass {\n  constructor (opts, mode) {\n    if (!opts || typeof opts !== 'object')\n      throw new TypeError('invalid options for ZlibBase constructor')\n\n    super(opts)\n    this[_sawError] = false\n    this[_ended] = false\n    this[_opts] = opts\n\n    this[_flushFlag] = opts.flush\n    this[_finishFlushFlag] = opts.finishFlush\n    // this will throw if any options are invalid for the class selected\n    try {\n      this[_handle] = new realZlib[mode](opts)\n    } catch (er) {\n      // make sure that all errors get decorated properly\n      throw new ZlibError(er)\n    }\n\n    this[_onError] = (err) => {\n      // no sense raising multiple errors, since we abort on the first one.\n      if (this[_sawError])\n        return\n\n      this[_sawError] = true\n\n      // there is no way to cleanly recover.\n      // continuing only obscures problems.\n      this.close()\n      this.emit('error', err)\n    }\n\n    this[_handle].on('error', er => this[_onError](new ZlibError(er)))\n    this.once('end', () => this.close)\n  }\n\n  close () {\n    if (this[_handle]) {\n      this[_handle].close()\n      this[_handle] = null\n      this.emit('close')\n    }\n  }\n\n  reset () {\n    if (!this[_sawError]) {\n      assert(this[_handle], 'zlib binding closed')\n      return this[_handle].reset()\n    }\n  }\n\n  flush (flushFlag) {\n    if (this.ended)\n      return\n\n    if (typeof flushFlag !== 'number')\n      flushFlag = this[_fullFlushFlag]\n    this.write(Object.assign(Buffer.alloc(0), { [_flushFlag]: flushFlag }))\n  }\n\n  end (chunk, encoding, cb) {\n    if (chunk)\n      this.write(chunk, encoding)\n    this.flush(this[_finishFlushFlag])\n    this[_ended] = true\n    return super.end(null, null, cb)\n  }\n\n  get ended () {\n    return this[_ended]\n  }\n\n  write (chunk, encoding, cb) {\n    // process the chunk using the sync process\n    // then super.write() all the outputted chunks\n    if (typeof encoding === 'function')\n      cb = encoding, encoding = 'utf8'\n\n    if (typeof chunk === 'string')\n      chunk = Buffer.from(chunk, encoding)\n\n    if (this[_sawError])\n      return\n    assert(this[_handle], 'zlib binding closed')\n\n    // _processChunk tries to .close() the native handle after it's done, so we\n    // intercept that by temporarily making it a no-op.\n    const nativeHandle = this[_handle]._handle\n    const originalNativeClose = nativeHandle.close\n    nativeHandle.close = () => {}\n    const originalClose = this[_handle].close\n    this[_handle].close = () => {}\n    // It also calls `Buffer.concat()` at the end, which may be convenient\n    // for some, but which we are not interested in as it slows us down.\n    Buffer.concat = (args) => args\n    let result\n    try {\n      const flushFlag = typeof chunk[_flushFlag] === 'number'\n        ? chunk[_flushFlag] : this[_flushFlag]\n      result = this[_handle]._processChunk(chunk, flushFlag)\n      // if we don't throw, reset it back how it was\n      Buffer.concat = OriginalBufferConcat\n    } catch (err) {\n      // or if we do, put Buffer.concat() back before we emit error\n      // Error events call into user code, which may call Buffer.concat()\n      Buffer.concat = OriginalBufferConcat\n      this[_onError](new ZlibError(err))\n    } finally {\n      if (this[_handle]) {\n        // Core zlib resets `_handle` to null after attempting to close the\n        // native handle. Our no-op handler prevented actual closure, but we\n        // need to restore the `._handle` property.\n        this[_handle]._handle = nativeHandle\n        nativeHandle.close = originalNativeClose\n        this[_handle].close = originalClose\n        // `_processChunk()` adds an 'error' listener. If we don't remove it\n        // after each call, these handlers start piling up.\n        this[_handle].removeAllListeners('error')\n        // make sure OUR error listener is still attached tho\n      }\n    }\n\n    if (this[_handle])\n      this[_handle].on('error', er => this[_onError](new ZlibError(er)))\n\n    let writeReturn\n    if (result) {\n      if (Array.isArray(result) && result.length > 0) {\n        // The first buffer is always `handle._outBuffer`, which would be\n        // re-used for later invocations; so, we always have to copy that one.\n        writeReturn = this[_superWrite](Buffer.from(result[0]))\n        for (let i = 1; i < result.length; i++) {\n          writeReturn = this[_superWrite](result[i])\n        }\n      } else {\n        writeReturn = this[_superWrite](Buffer.from(result))\n      }\n    }\n\n    if (cb)\n      cb()\n    return writeReturn\n  }\n\n  [_superWrite] (data) {\n    return super.write(data)\n  }\n}\n\nclass Zlib extends ZlibBase {\n  constructor (opts, mode) {\n    opts = opts || {}\n\n    opts.flush = opts.flush || constants.Z_NO_FLUSH\n    opts.finishFlush = opts.finishFlush || constants.Z_FINISH\n    super(opts, mode)\n\n    this[_fullFlushFlag] = constants.Z_FULL_FLUSH\n    this[_level] = opts.level\n    this[_strategy] = opts.strategy\n  }\n\n  params (level, strategy) {\n    if (this[_sawError])\n      return\n\n    if (!this[_handle])\n      throw new Error('cannot switch params when binding is closed')\n\n    // no way to test this without also not supporting params at all\n    /* istanbul ignore if */\n    if (!this[_handle].params)\n      throw new Error('not supported in this implementation')\n\n    if (this[_level] !== level || this[_strategy] !== strategy) {\n      this.flush(constants.Z_SYNC_FLUSH)\n      assert(this[_handle], 'zlib binding closed')\n      // .params() calls .flush(), but the latter is always async in the\n      // core zlib. We override .flush() temporarily to intercept that and\n      // flush synchronously.\n      const origFlush = this[_handle].flush\n      this[_handle].flush = (flushFlag, cb) => {\n        this.flush(flushFlag)\n        cb()\n      }\n      try {\n        this[_handle].params(level, strategy)\n      } finally {\n        this[_handle].flush = origFlush\n      }\n      /* istanbul ignore else */\n      if (this[_handle]) {\n        this[_level] = level\n        this[_strategy] = strategy\n      }\n    }\n  }\n}\n\n// minimal 2-byte header\nclass Deflate extends Zlib {\n  constructor (opts) {\n    super(opts, 'Deflate')\n  }\n}\n\nclass Inflate extends Zlib {\n  constructor (opts) {\n    super(opts, 'Inflate')\n  }\n}\n\n// gzip - bigger header, same deflate compression\nconst _portable = Symbol('_portable')\nclass Gzip extends Zlib {\n  constructor (opts) {\n    super(opts, 'Gzip')\n    this[_portable] = opts && !!opts.portable\n  }\n\n  [_superWrite] (data) {\n    if (!this[_portable])\n      return super[_superWrite](data)\n\n    // we'll always get the header emitted in one first chunk\n    // overwrite the OS indicator byte with 0xFF\n    this[_portable] = false\n    data[9] = 255\n    return super[_superWrite](data)\n  }\n}\n\nclass Gunzip extends Zlib {\n  constructor (opts) {\n    super(opts, 'Gunzip')\n  }\n}\n\n// raw - no header\nclass DeflateRaw extends Zlib {\n  constructor (opts) {\n    super(opts, 'DeflateRaw')\n  }\n}\n\nclass InflateRaw extends Zlib {\n  constructor (opts) {\n    super(opts, 'InflateRaw')\n  }\n}\n\n// auto-detect header.\nclass Unzip extends Zlib {\n  constructor (opts) {\n    super(opts, 'Unzip')\n  }\n}\n\nclass Brotli extends ZlibBase {\n  constructor (opts, mode) {\n    opts = opts || {}\n\n    opts.flush = opts.flush || constants.BROTLI_OPERATION_PROCESS\n    opts.finishFlush = opts.finishFlush || constants.BROTLI_OPERATION_FINISH\n\n    super(opts, mode)\n\n    this[_fullFlushFlag] = constants.BROTLI_OPERATION_FLUSH\n  }\n}\n\nclass BrotliCompress extends Brotli {\n  constructor (opts) {\n    super(opts, 'BrotliCompress')\n  }\n}\n\nclass BrotliDecompress extends Brotli {\n  constructor (opts) {\n    super(opts, 'BrotliDecompress')\n  }\n}\n\nexports.Deflate = Deflate\nexports.Inflate = Inflate\nexports.Gzip = Gzip\nexports.Gunzip = Gunzip\nexports.DeflateRaw = DeflateRaw\nexports.InflateRaw = InflateRaw\nexports.Unzip = Unzip\n/* istanbul ignore else */\nif (typeof realZlib.BrotliCompress === 'function') {\n  exports.BrotliCompress = BrotliCompress\n  exports.BrotliDecompress = BrotliDecompress\n} else {\n  exports.BrotliCompress = exports.BrotliDecompress = class {\n    constructor () {\n      throw new Error('Brotli is not supported in this version of Node.js')\n    }\n  }\n}\n","const optsArg = require('./lib/opts-arg.js')\nconst pathArg = require('./lib/path-arg.js')\n\nconst {mkdirpNative, mkdirpNativeSync} = require('./lib/mkdirp-native.js')\nconst {mkdirpManual, mkdirpManualSync} = require('./lib/mkdirp-manual.js')\nconst {useNative, useNativeSync} = require('./lib/use-native.js')\n\n\nconst mkdirp = (path, opts) => {\n  path = pathArg(path)\n  opts = optsArg(opts)\n  return useNative(opts)\n    ? mkdirpNative(path, opts)\n    : mkdirpManual(path, opts)\n}\n\nconst mkdirpSync = (path, opts) => {\n  path = pathArg(path)\n  opts = optsArg(opts)\n  return useNativeSync(opts)\n    ? mkdirpNativeSync(path, opts)\n    : mkdirpManualSync(path, opts)\n}\n\nmkdirp.sync = mkdirpSync\nmkdirp.native = (path, opts) => mkdirpNative(pathArg(path), optsArg(opts))\nmkdirp.manual = (path, opts) => mkdirpManual(pathArg(path), optsArg(opts))\nmkdirp.nativeSync = (path, opts) => mkdirpNativeSync(pathArg(path), optsArg(opts))\nmkdirp.manualSync = (path, opts) => mkdirpManualSync(pathArg(path), optsArg(opts))\n\nmodule.exports = mkdirp\n","const {dirname} = require('path')\n\nconst findMade = (opts, parent, path = undefined) => {\n  // we never want the 'made' return value to be a root directory\n  if (path === parent)\n    return Promise.resolve()\n\n  return opts.statAsync(parent).then(\n    st => st.isDirectory() ? path : undefined, // will fail later\n    er => er.code === 'ENOENT'\n      ? findMade(opts, dirname(parent), parent)\n      : undefined\n  )\n}\n\nconst findMadeSync = (opts, parent, path = undefined) => {\n  if (path === parent)\n    return undefined\n\n  try {\n    return opts.statSync(parent).isDirectory() ? path : undefined\n  } catch (er) {\n    return er.code === 'ENOENT'\n      ? findMadeSync(opts, dirname(parent), parent)\n      : undefined\n  }\n}\n\nmodule.exports = {findMade, findMadeSync}\n","const {dirname} = require('path')\n\nconst mkdirpManual = (path, opts, made) => {\n  opts.recursive = false\n  const parent = dirname(path)\n  if (parent === path) {\n    return opts.mkdirAsync(path, opts).catch(er => {\n      // swallowed by recursive implementation on posix systems\n      // any other error is a failure\n      if (er.code !== 'EISDIR')\n        throw er\n    })\n  }\n\n  return opts.mkdirAsync(path, opts).then(() => made || path, er => {\n    if (er.code === 'ENOENT')\n      return mkdirpManual(parent, opts)\n        .then(made => mkdirpManual(path, opts, made))\n    if (er.code !== 'EEXIST' && er.code !== 'EROFS')\n      throw er\n    return opts.statAsync(path).then(st => {\n      if (st.isDirectory())\n        return made\n      else\n        throw er\n    }, () => { throw er })\n  })\n}\n\nconst mkdirpManualSync = (path, opts, made) => {\n  const parent = dirname(path)\n  opts.recursive = false\n\n  if (parent === path) {\n    try {\n      return opts.mkdirSync(path, opts)\n    } catch (er) {\n      // swallowed by recursive implementation on posix systems\n      // any other error is a failure\n      if (er.code !== 'EISDIR')\n        throw er\n      else\n        return\n    }\n  }\n\n  try {\n    opts.mkdirSync(path, opts)\n    return made || path\n  } catch (er) {\n    if (er.code === 'ENOENT')\n      return mkdirpManualSync(path, opts, mkdirpManualSync(parent, opts, made))\n    if (er.code !== 'EEXIST' && er.code !== 'EROFS')\n      throw er\n    try {\n      if (!opts.statSync(path).isDirectory())\n        throw er\n    } catch (_) {\n      throw er\n    }\n  }\n}\n\nmodule.exports = {mkdirpManual, mkdirpManualSync}\n","const {dirname} = require('path')\nconst {findMade, findMadeSync} = require('./find-made.js')\nconst {mkdirpManual, mkdirpManualSync} = require('./mkdirp-manual.js')\n\nconst mkdirpNative = (path, opts) => {\n  opts.recursive = true\n  const parent = dirname(path)\n  if (parent === path)\n    return opts.mkdirAsync(path, opts)\n\n  return findMade(opts, path).then(made =>\n    opts.mkdirAsync(path, opts).then(() => made)\n    .catch(er => {\n      if (er.code === 'ENOENT')\n        return mkdirpManual(path, opts)\n      else\n        throw er\n    }))\n}\n\nconst mkdirpNativeSync = (path, opts) => {\n  opts.recursive = true\n  const parent = dirname(path)\n  if (parent === path)\n    return opts.mkdirSync(path, opts)\n\n  const made = findMadeSync(opts, path)\n  try {\n    opts.mkdirSync(path, opts)\n    return made\n  } catch (er) {\n    if (er.code === 'ENOENT')\n      return mkdirpManualSync(path, opts)\n    else\n      throw er\n  }\n}\n\nmodule.exports = {mkdirpNative, mkdirpNativeSync}\n","const { promisify } = require('util')\nconst fs = require('fs')\nconst optsArg = opts => {\n  if (!opts)\n    opts = { mode: 0o777, fs }\n  else if (typeof opts === 'object')\n    opts = { mode: 0o777, fs, ...opts }\n  else if (typeof opts === 'number')\n    opts = { mode: opts, fs }\n  else if (typeof opts === 'string')\n    opts = { mode: parseInt(opts, 8), fs }\n  else\n    throw new TypeError('invalid options argument')\n\n  opts.mkdir = opts.mkdir || opts.fs.mkdir || fs.mkdir\n  opts.mkdirAsync = promisify(opts.mkdir)\n  opts.stat = opts.stat || opts.fs.stat || fs.stat\n  opts.statAsync = promisify(opts.stat)\n  opts.statSync = opts.statSync || opts.fs.statSync || fs.statSync\n  opts.mkdirSync = opts.mkdirSync || opts.fs.mkdirSync || fs.mkdirSync\n  return opts\n}\nmodule.exports = optsArg\n","const platform = process.env.__TESTING_MKDIRP_PLATFORM__ || process.platform\nconst { resolve, parse } = require('path')\nconst pathArg = path => {\n  if (/\\0/.test(path)) {\n    // simulate same failure that node raises\n    throw Object.assign(\n      new TypeError('path must be a string without null bytes'),\n      {\n        path,\n        code: 'ERR_INVALID_ARG_VALUE',\n      }\n    )\n  }\n\n  path = resolve(path)\n  if (platform === 'win32') {\n    const badWinChars = /[*|\"<>?:]/\n    const {root} = parse(path)\n    if (badWinChars.test(path.substr(root.length))) {\n      throw Object.assign(new Error('Illegal characters in path.'), {\n        path,\n        code: 'EINVAL',\n      })\n    }\n  }\n\n  return path\n}\nmodule.exports = pathArg\n","const fs = require('fs')\n\nconst version = process.env.__TESTING_MKDIRP_NODE_VERSION__ || process.version\nconst versArr = version.replace(/^v/, '').split('.')\nconst hasNative = +versArr[0] > 10 || +versArr[0] === 10 && +versArr[1] >= 12\n\nconst useNative = !hasNative ? () => false : opts => opts.mkdir === fs.mkdir\nconst useNativeSync = !hasNative ? () => false : opts => opts.mkdirSync === fs.mkdirSync\n\nmodule.exports = {useNative, useNativeSync}\n","/*! node-domexception. MIT License. Jimmy Wärting <https://jimmy.warting.se/opensource> */\n\nif (!globalThis.DOMException) {\n  try {\n    const { MessageChannel } = require('worker_threads'),\n    port = new MessageChannel().port1,\n    ab = new ArrayBuffer()\n    port.postMessage(ab, [ab, ab])\n  } catch (err) {\n    err.constructor.name === 'DOMException' && (\n      globalThis.DOMException = err.constructor\n    )\n  }\n}\n\nmodule.exports = globalThis.DOMException\n","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"node:http\");","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"node:https\");","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"node:zlib\");","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"node:stream\");","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"node:buffer\");","/**\n * Returns a `Buffer` instance from the given data URI `uri`.\n *\n * @param {String} uri Data URI to turn into a Buffer instance\n * @returns {Buffer} Buffer instance from Data URI\n * @api public\n */\nexport function dataUriToBuffer(uri) {\n    if (!/^data:/i.test(uri)) {\n        throw new TypeError('`uri` does not appear to be a Data URI (must begin with \"data:\")');\n    }\n    // strip newlines\n    uri = uri.replace(/\\r?\\n/g, '');\n    // split the URI up into the \"metadata\" and the \"data\" portions\n    const firstComma = uri.indexOf(',');\n    if (firstComma === -1 || firstComma <= 4) {\n        throw new TypeError('malformed data: URI');\n    }\n    // remove the \"data:\" scheme and parse the metadata\n    const meta = uri.substring(5, firstComma).split(';');\n    let charset = '';\n    let base64 = false;\n    const type = meta[0] || 'text/plain';\n    let typeFull = type;\n    for (let i = 1; i < meta.length; i++) {\n        if (meta[i] === 'base64') {\n            base64 = true;\n        }\n        else {\n            typeFull += `;${meta[i]}`;\n            if (meta[i].indexOf('charset=') === 0) {\n                charset = meta[i].substring(8);\n            }\n        }\n    }\n    // defaults to US-ASCII only if type is not provided\n    if (!meta[0] && !charset.length) {\n        typeFull += ';charset=US-ASCII';\n        charset = 'US-ASCII';\n    }\n    // get the encoded data portion and decode URI-encoded chars\n    const encoding = base64 ? 'base64' : 'ascii';\n    const data = unescape(uri.substring(firstComma + 1));\n    const buffer = Buffer.from(data, encoding);\n    // set `.type` and `.typeFull` properties to MIME type\n    buffer.type = type;\n    buffer.typeFull = typeFull;\n    // set the `.charset` property\n    buffer.charset = charset;\n    return buffer;\n}\nexport default dataUriToBuffer;\n//# sourceMappingURL=index.js.map","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"node:util\");","export class FetchBaseError extends Error {\n\tconstructor(message, type) {\n\t\tsuper(message);\n\t\t// Hide custom error implementation details from end-users\n\t\tError.captureStackTrace(this, this.constructor);\n\n\t\tthis.type = type;\n\t}\n\n\tget name() {\n\t\treturn this.constructor.name;\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n}\n","\nimport {FetchBaseError} from './base.js';\n\n/**\n * @typedef {{ address?: string, code: string, dest?: string, errno: number, info?: object, message: string, path?: string, port?: number, syscall: string}} SystemError\n*/\n\n/**\n * FetchError interface for operational errors\n */\nexport class FetchError extends FetchBaseError {\n\t/**\n\t * @param  {string} message -      Error message for human\n\t * @param  {string} [type] -        Error type for machine\n\t * @param  {SystemError} [systemError] - For Node.js system error\n\t */\n\tconstructor(message, type, systemError) {\n\t\tsuper(message, type);\n\t\t// When err.type is `system`, err.erroredSysCall contains system error and err.code contains system error code\n\t\tif (systemError) {\n\t\t\t// eslint-disable-next-line no-multi-assign\n\t\t\tthis.code = this.errno = systemError.code;\n\t\t\tthis.erroredSysCall = systemError.syscall;\n\t\t}\n\t}\n}\n","/**\n * Is.js\n *\n * Object type checks.\n */\n\nconst NAME = Symbol.toStringTag;\n\n/**\n * Check if `obj` is a URLSearchParams object\n * ref: https://github.com/node-fetch/node-fetch/issues/296#issuecomment-307598143\n * @param {*} object - Object to check for\n * @return {boolean}\n */\nexport const isURLSearchParameters = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.append === 'function' &&\n\t\ttypeof object.delete === 'function' &&\n\t\ttypeof object.get === 'function' &&\n\t\ttypeof object.getAll === 'function' &&\n\t\ttypeof object.has === 'function' &&\n\t\ttypeof object.set === 'function' &&\n\t\ttypeof object.sort === 'function' &&\n\t\tobject[NAME] === 'URLSearchParams'\n\t);\n};\n\n/**\n * Check if `object` is a W3C `Blob` object (which `File` inherits from)\n * @param {*} object - Object to check for\n * @return {boolean}\n */\nexport const isBlob = object => {\n\treturn (\n\t\tobject &&\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.arrayBuffer === 'function' &&\n\t\ttypeof object.type === 'string' &&\n\t\ttypeof object.stream === 'function' &&\n\t\ttypeof object.constructor === 'function' &&\n\t\t/^(Blob|File)$/.test(object[NAME])\n\t);\n};\n\n/**\n * Check if `obj` is an instance of AbortSignal.\n * @param {*} object - Object to check for\n * @return {boolean}\n */\nexport const isAbortSignal = object => {\n\treturn (\n\t\ttypeof object === 'object' && (\n\t\t\tobject[NAME] === 'AbortSignal' ||\n\t\t\tobject[NAME] === 'EventTarget'\n\t\t)\n\t);\n};\n\n/**\n * isDomainOrSubdomain reports whether sub is a subdomain (or exact match) of\n * the parent domain.\n *\n * Both domains must already be in canonical form.\n * @param {string|URL} original\n * @param {string|URL} destination\n */\nexport const isDomainOrSubdomain = (destination, original) => {\n\tconst orig = new URL(original).hostname;\n\tconst dest = new URL(destination).hostname;\n\n\treturn orig === dest || orig.endsWith(`.${dest}`);\n};\n","\n/**\n * Body.js\n *\n * Body interface provides common methods for Request and Response\n */\n\nimport Stream, {PassThrough} from 'node:stream';\nimport {types, deprecate, promisify} from 'node:util';\nimport {Buffer} from 'node:buffer';\n\nimport Blob from 'fetch-blob';\nimport {FormData, formDataToBlob} from 'formdata-polyfill/esm.min.js';\n\nimport {FetchError} from './errors/fetch-error.js';\nimport {FetchBaseError} from './errors/base.js';\nimport {isBlob, isURLSearchParameters} from './utils/is.js';\n\nconst pipeline = promisify(Stream.pipeline);\nconst INTERNALS = Symbol('Body internals');\n\n/**\n * Body mixin\n *\n * Ref: https://fetch.spec.whatwg.org/#body\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nexport default class Body {\n\tconstructor(body, {\n\t\tsize = 0\n\t} = {}) {\n\t\tlet boundary = null;\n\n\t\tif (body === null) {\n\t\t\t// Body is undefined or null\n\t\t\tbody = null;\n\t\t} else if (isURLSearchParameters(body)) {\n\t\t\t// Body is a URLSearchParams\n\t\t\tbody = Buffer.from(body.toString());\n\t\t} else if (isBlob(body)) {\n\t\t\t// Body is blob\n\t\t} else if (Buffer.isBuffer(body)) {\n\t\t\t// Body is Buffer\n\t\t} else if (types.isAnyArrayBuffer(body)) {\n\t\t\t// Body is ArrayBuffer\n\t\t\tbody = Buffer.from(body);\n\t\t} else if (ArrayBuffer.isView(body)) {\n\t\t\t// Body is ArrayBufferView\n\t\t\tbody = Buffer.from(body.buffer, body.byteOffset, body.byteLength);\n\t\t} else if (body instanceof Stream) {\n\t\t\t// Body is stream\n\t\t} else if (body instanceof FormData) {\n\t\t\t// Body is FormData\n\t\t\tbody = formDataToBlob(body);\n\t\t\tboundary = body.type.split('=')[1];\n\t\t} else {\n\t\t\t// None of the above\n\t\t\t// coerce to string then buffer\n\t\t\tbody = Buffer.from(String(body));\n\t\t}\n\n\t\tlet stream = body;\n\n\t\tif (Buffer.isBuffer(body)) {\n\t\t\tstream = Stream.Readable.from(body);\n\t\t} else if (isBlob(body)) {\n\t\t\tstream = Stream.Readable.from(body.stream());\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\tbody,\n\t\t\tstream,\n\t\t\tboundary,\n\t\t\tdisturbed: false,\n\t\t\terror: null\n\t\t};\n\t\tthis.size = size;\n\n\t\tif (body instanceof Stream) {\n\t\t\tbody.on('error', error_ => {\n\t\t\t\tconst error = error_ instanceof FetchBaseError ?\n\t\t\t\t\terror_ :\n\t\t\t\t\tnew FetchError(`Invalid response body while trying to fetch ${this.url}: ${error_.message}`, 'system', error_);\n\t\t\t\tthis[INTERNALS].error = error;\n\t\t\t});\n\t\t}\n\t}\n\n\tget body() {\n\t\treturn this[INTERNALS].stream;\n\t}\n\n\tget bodyUsed() {\n\t\treturn this[INTERNALS].disturbed;\n\t}\n\n\t/**\n\t * Decode response as ArrayBuffer\n\t *\n\t * @return  Promise\n\t */\n\tasync arrayBuffer() {\n\t\tconst {buffer, byteOffset, byteLength} = await consumeBody(this);\n\t\treturn buffer.slice(byteOffset, byteOffset + byteLength);\n\t}\n\n\tasync formData() {\n\t\tconst ct = this.headers.get('content-type');\n\n\t\tif (ct.startsWith('application/x-www-form-urlencoded')) {\n\t\t\tconst formData = new FormData();\n\t\t\tconst parameters = new URLSearchParams(await this.text());\n\n\t\t\tfor (const [name, value] of parameters) {\n\t\t\t\tformData.append(name, value);\n\t\t\t}\n\n\t\t\treturn formData;\n\t\t}\n\n\t\tconst {toFormData} = await import('./utils/multipart-parser.js');\n\t\treturn toFormData(this.body, ct);\n\t}\n\n\t/**\n\t * Return raw response as Blob\n\t *\n\t * @return Promise\n\t */\n\tasync blob() {\n\t\tconst ct = (this.headers && this.headers.get('content-type')) || (this[INTERNALS].body && this[INTERNALS].body.type) || '';\n\t\tconst buf = await this.arrayBuffer();\n\n\t\treturn new Blob([buf], {\n\t\t\ttype: ct\n\t\t});\n\t}\n\n\t/**\n\t * Decode response as json\n\t *\n\t * @return  Promise\n\t */\n\tasync json() {\n\t\tconst buffer = await consumeBody(this);\n\t\treturn JSON.parse(buffer.toString());\n\t}\n\n\t/**\n\t * Decode response as text\n\t *\n\t * @return  Promise\n\t */\n\tasync text() {\n\t\tconst buffer = await consumeBody(this);\n\t\treturn buffer.toString();\n\t}\n\n\t/**\n\t * Decode response as buffer (non-spec api)\n\t *\n\t * @return  Promise\n\t */\n\tbuffer() {\n\t\treturn consumeBody(this);\n\t}\n}\n\nBody.prototype.buffer = deprecate(Body.prototype.buffer, 'Please use \\'response.arrayBuffer()\\' instead of \\'response.buffer()\\'', 'node-fetch#buffer');\n\n// In browsers, all properties are enumerable.\nObject.defineProperties(Body.prototype, {\n\tbody: {enumerable: true},\n\tbodyUsed: {enumerable: true},\n\tarrayBuffer: {enumerable: true},\n\tblob: {enumerable: true},\n\tjson: {enumerable: true},\n\ttext: {enumerable: true},\n\tdata: {get: deprecate(() => {},\n\t\t'data doesn\\'t exist, use json(), text(), arrayBuffer(), or body instead',\n\t\t'https://github.com/node-fetch/node-fetch/issues/1000 (response)')}\n});\n\n/**\n * Consume and convert an entire Body to a Buffer.\n *\n * Ref: https://fetch.spec.whatwg.org/#concept-body-consume-body\n *\n * @return Promise\n */\nasync function consumeBody(data) {\n\tif (data[INTERNALS].disturbed) {\n\t\tthrow new TypeError(`body used already for: ${data.url}`);\n\t}\n\n\tdata[INTERNALS].disturbed = true;\n\n\tif (data[INTERNALS].error) {\n\t\tthrow data[INTERNALS].error;\n\t}\n\n\tconst {body} = data;\n\n\t// Body is null\n\tif (body === null) {\n\t\treturn Buffer.alloc(0);\n\t}\n\n\t/* c8 ignore next 3 */\n\tif (!(body instanceof Stream)) {\n\t\treturn Buffer.alloc(0);\n\t}\n\n\t// Body is stream\n\t// get ready to actually consume the body\n\tconst accum = [];\n\tlet accumBytes = 0;\n\n\ttry {\n\t\tfor await (const chunk of body) {\n\t\t\tif (data.size > 0 && accumBytes + chunk.length > data.size) {\n\t\t\t\tconst error = new FetchError(`content size at ${data.url} over limit: ${data.size}`, 'max-size');\n\t\t\t\tbody.destroy(error);\n\t\t\t\tthrow error;\n\t\t\t}\n\n\t\t\taccumBytes += chunk.length;\n\t\t\taccum.push(chunk);\n\t\t}\n\t} catch (error) {\n\t\tconst error_ = error instanceof FetchBaseError ? error : new FetchError(`Invalid response body while trying to fetch ${data.url}: ${error.message}`, 'system', error);\n\t\tthrow error_;\n\t}\n\n\tif (body.readableEnded === true || body._readableState.ended === true) {\n\t\ttry {\n\t\t\tif (accum.every(c => typeof c === 'string')) {\n\t\t\t\treturn Buffer.from(accum.join(''));\n\t\t\t}\n\n\t\t\treturn Buffer.concat(accum, accumBytes);\n\t\t} catch (error) {\n\t\t\tthrow new FetchError(`Could not create Buffer from response body for ${data.url}: ${error.message}`, 'system', error);\n\t\t}\n\t} else {\n\t\tthrow new FetchError(`Premature close of server response while trying to fetch ${data.url}`);\n\t}\n}\n\n/**\n * Clone body given Res/Req instance\n *\n * @param   Mixed   instance       Response or Request instance\n * @param   String  highWaterMark  highWaterMark for both PassThrough body streams\n * @return  Mixed\n */\nexport const clone = (instance, highWaterMark) => {\n\tlet p1;\n\tlet p2;\n\tlet {body} = instance[INTERNALS];\n\n\t// Don't allow cloning a used body\n\tif (instance.bodyUsed) {\n\t\tthrow new Error('cannot clone body after it is used');\n\t}\n\n\t// Check that body is a stream and not form-data object\n\t// note: we can't clone the form-data object without having it as a dependency\n\tif ((body instanceof Stream) && (typeof body.getBoundary !== 'function')) {\n\t\t// Tee instance body\n\t\tp1 = new PassThrough({highWaterMark});\n\t\tp2 = new PassThrough({highWaterMark});\n\t\tbody.pipe(p1);\n\t\tbody.pipe(p2);\n\t\t// Set instance body to teed body and return the other teed body\n\t\tinstance[INTERNALS].stream = p1;\n\t\tbody = p2;\n\t}\n\n\treturn body;\n};\n\nconst getNonSpecFormDataBoundary = deprecate(\n\tbody => body.getBoundary(),\n\t'form-data doesn\\'t follow the spec and requires special treatment. Use alternative package',\n\t'https://github.com/node-fetch/node-fetch/issues/1167'\n);\n\n/**\n * Performs the operation \"extract a `Content-Type` value from |object|\" as\n * specified in the specification:\n * https://fetch.spec.whatwg.org/#concept-bodyinit-extract\n *\n * This function assumes that instance.body is present.\n *\n * @param {any} body Any options.body input\n * @returns {string | null}\n */\nexport const extractContentType = (body, request) => {\n\t// Body is null or undefined\n\tif (body === null) {\n\t\treturn null;\n\t}\n\n\t// Body is string\n\tif (typeof body === 'string') {\n\t\treturn 'text/plain;charset=UTF-8';\n\t}\n\n\t// Body is a URLSearchParams\n\tif (isURLSearchParameters(body)) {\n\t\treturn 'application/x-www-form-urlencoded;charset=UTF-8';\n\t}\n\n\t// Body is blob\n\tif (isBlob(body)) {\n\t\treturn body.type || null;\n\t}\n\n\t// Body is a Buffer (Buffer, ArrayBuffer or ArrayBufferView)\n\tif (Buffer.isBuffer(body) || types.isAnyArrayBuffer(body) || ArrayBuffer.isView(body)) {\n\t\treturn null;\n\t}\n\n\tif (body instanceof FormData) {\n\t\treturn `multipart/form-data; boundary=${request[INTERNALS].boundary}`;\n\t}\n\n\t// Detect form data input from form-data module\n\tif (body && typeof body.getBoundary === 'function') {\n\t\treturn `multipart/form-data;boundary=${getNonSpecFormDataBoundary(body)}`;\n\t}\n\n\t// Body is stream - can't really do much about this\n\tif (body instanceof Stream) {\n\t\treturn null;\n\t}\n\n\t// Body constructor defaults other things to string\n\treturn 'text/plain;charset=UTF-8';\n};\n\n/**\n * The Fetch Standard treats this as if \"total bytes\" is a property on the body.\n * For us, we have to explicitly get it with a function.\n *\n * ref: https://fetch.spec.whatwg.org/#concept-body-total-bytes\n *\n * @param {any} obj.body Body object from the Body instance.\n * @returns {number | null}\n */\nexport const getTotalBytes = request => {\n\tconst {body} = request[INTERNALS];\n\n\t// Body is null or undefined\n\tif (body === null) {\n\t\treturn 0;\n\t}\n\n\t// Body is Blob\n\tif (isBlob(body)) {\n\t\treturn body.size;\n\t}\n\n\t// Body is Buffer\n\tif (Buffer.isBuffer(body)) {\n\t\treturn body.length;\n\t}\n\n\t// Detect form data input from form-data module\n\tif (body && typeof body.getLengthSync === 'function') {\n\t\treturn body.hasKnownLength && body.hasKnownLength() ? body.getLengthSync() : null;\n\t}\n\n\t// Body is stream\n\treturn null;\n};\n\n/**\n * Write a Body to a Node.js WritableStream (e.g. http.Request) object.\n *\n * @param {Stream.Writable} dest The stream to write to.\n * @param obj.body Body object from the Body instance.\n * @returns {Promise<void>}\n */\nexport const writeToStream = async (dest, {body}) => {\n\tif (body === null) {\n\t\t// Body is null\n\t\tdest.end();\n\t} else {\n\t\t// Body is stream\n\t\tawait pipeline(body, dest);\n\t}\n};\n","/**\n * Headers.js\n *\n * Headers class offers convenient helpers\n */\n\nimport {types} from 'node:util';\nimport http from 'node:http';\n\n/* c8 ignore next 9 */\nconst validateHeaderName = typeof http.validateHeaderName === 'function' ?\n\thttp.validateHeaderName :\n\tname => {\n\t\tif (!/^[\\^`\\-\\w!#$%&'*+.|~]+$/.test(name)) {\n\t\t\tconst error = new TypeError(`Header name must be a valid HTTP token [${name}]`);\n\t\t\tObject.defineProperty(error, 'code', {value: 'ERR_INVALID_HTTP_TOKEN'});\n\t\t\tthrow error;\n\t\t}\n\t};\n\n/* c8 ignore next 9 */\nconst validateHeaderValue = typeof http.validateHeaderValue === 'function' ?\n\thttp.validateHeaderValue :\n\t(name, value) => {\n\t\tif (/[^\\t\\u0020-\\u007E\\u0080-\\u00FF]/.test(value)) {\n\t\t\tconst error = new TypeError(`Invalid character in header content [\"${name}\"]`);\n\t\t\tObject.defineProperty(error, 'code', {value: 'ERR_INVALID_CHAR'});\n\t\t\tthrow error;\n\t\t}\n\t};\n\n/**\n * @typedef {Headers | Record<string, string> | Iterable<readonly [string, string]> | Iterable<Iterable<string>>} HeadersInit\n */\n\n/**\n * This Fetch API interface allows you to perform various actions on HTTP request and response headers.\n * These actions include retrieving, setting, adding to, and removing.\n * A Headers object has an associated header list, which is initially empty and consists of zero or more name and value pairs.\n * You can add to this using methods like append() (see Examples.)\n * In all methods of this interface, header names are matched by case-insensitive byte sequence.\n *\n */\nexport default class Headers extends URLSearchParams {\n\t/**\n\t * Headers class\n\t *\n\t * @constructor\n\t * @param {HeadersInit} [init] - Response headers\n\t */\n\tconstructor(init) {\n\t\t// Validate and normalize init object in [name, value(s)][]\n\t\t/** @type {string[][]} */\n\t\tlet result = [];\n\t\tif (init instanceof Headers) {\n\t\t\tconst raw = init.raw();\n\t\t\tfor (const [name, values] of Object.entries(raw)) {\n\t\t\t\tresult.push(...values.map(value => [name, value]));\n\t\t\t}\n\t\t} else if (init == null) { // eslint-disable-line no-eq-null, eqeqeq\n\t\t\t// No op\n\t\t} else if (typeof init === 'object' && !types.isBoxedPrimitive(init)) {\n\t\t\tconst method = init[Symbol.iterator];\n\t\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\t\tif (method == null) {\n\t\t\t\t// Record<ByteString, ByteString>\n\t\t\t\tresult.push(...Object.entries(init));\n\t\t\t} else {\n\t\t\t\tif (typeof method !== 'function') {\n\t\t\t\t\tthrow new TypeError('Header pairs must be iterable');\n\t\t\t\t}\n\n\t\t\t\t// Sequence<sequence<ByteString>>\n\t\t\t\t// Note: per spec we have to first exhaust the lists then process them\n\t\t\t\tresult = [...init]\n\t\t\t\t\t.map(pair => {\n\t\t\t\t\t\tif (\n\t\t\t\t\t\t\ttypeof pair !== 'object' || types.isBoxedPrimitive(pair)\n\t\t\t\t\t\t) {\n\t\t\t\t\t\t\tthrow new TypeError('Each header pair must be an iterable object');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn [...pair];\n\t\t\t\t\t}).map(pair => {\n\t\t\t\t\t\tif (pair.length !== 2) {\n\t\t\t\t\t\t\tthrow new TypeError('Each header pair must be a name/value tuple');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn [...pair];\n\t\t\t\t\t});\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new TypeError('Failed to construct \\'Headers\\': The provided value is not of type \\'(sequence<sequence<ByteString>> or record<ByteString, ByteString>)');\n\t\t}\n\n\t\t// Validate and lowercase\n\t\tresult =\n\t\t\tresult.length > 0 ?\n\t\t\t\tresult.map(([name, value]) => {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn [String(name).toLowerCase(), String(value)];\n\t\t\t\t}) :\n\t\t\t\tundefined;\n\n\t\tsuper(result);\n\n\t\t// Returning a Proxy that will lowercase key names, validate parameters and sort keys\n\t\t// eslint-disable-next-line no-constructor-return\n\t\treturn new Proxy(this, {\n\t\t\tget(target, p, receiver) {\n\t\t\t\tswitch (p) {\n\t\t\t\t\tcase 'append':\n\t\t\t\t\tcase 'set':\n\t\t\t\t\t\treturn (name, value) => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\ttarget,\n\t\t\t\t\t\t\t\tString(name).toLowerCase(),\n\t\t\t\t\t\t\t\tString(value)\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'delete':\n\t\t\t\t\tcase 'has':\n\t\t\t\t\tcase 'getAll':\n\t\t\t\t\t\treturn name => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\ttarget,\n\t\t\t\t\t\t\t\tString(name).toLowerCase()\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'keys':\n\t\t\t\t\t\treturn () => {\n\t\t\t\t\t\t\ttarget.sort();\n\t\t\t\t\t\t\treturn new Set(URLSearchParams.prototype.keys.call(target)).keys();\n\t\t\t\t\t\t};\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn Reflect.get(target, p, receiver);\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\t/* c8 ignore next */\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n\n\ttoString() {\n\t\treturn Object.prototype.toString.call(this);\n\t}\n\n\tget(name) {\n\t\tconst values = this.getAll(name);\n\t\tif (values.length === 0) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlet value = values.join(', ');\n\t\tif (/^content-encoding$/i.test(name)) {\n\t\t\tvalue = value.toLowerCase();\n\t\t}\n\n\t\treturn value;\n\t}\n\n\tforEach(callback, thisArg = undefined) {\n\t\tfor (const name of this.keys()) {\n\t\t\tReflect.apply(callback, thisArg, [this.get(name), name, this]);\n\t\t}\n\t}\n\n\t* values() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield this.get(name);\n\t\t}\n\t}\n\n\t/**\n\t * @type {() => IterableIterator<[string, string]>}\n\t */\n\t* entries() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield [name, this.get(name)];\n\t\t}\n\t}\n\n\t[Symbol.iterator]() {\n\t\treturn this.entries();\n\t}\n\n\t/**\n\t * Node-fetch non-spec method\n\t * returning all headers and their values as array\n\t * @returns {Record<string, string[]>}\n\t */\n\traw() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tresult[key] = this.getAll(key);\n\t\t\treturn result;\n\t\t}, {});\n\t}\n\n\t/**\n\t * For better console.log(headers) and also to convert Headers into Node.js Request compatible format\n\t */\n\t[Symbol.for('nodejs.util.inspect.custom')]() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tconst values = this.getAll(key);\n\t\t\t// Http.request() only supports string as Host header.\n\t\t\t// This hack makes specifying custom Host header possible.\n\t\t\tif (key === 'host') {\n\t\t\t\tresult[key] = values[0];\n\t\t\t} else {\n\t\t\t\tresult[key] = values.length > 1 ? values : values[0];\n\t\t\t}\n\n\t\t\treturn result;\n\t\t}, {});\n\t}\n}\n\n/**\n * Re-shaping object for Web IDL tests\n * Only need to do it for overridden methods\n */\nObject.defineProperties(\n\tHeaders.prototype,\n\t['get', 'entries', 'forEach', 'values'].reduce((result, property) => {\n\t\tresult[property] = {enumerable: true};\n\t\treturn result;\n\t}, {})\n);\n\n/**\n * Create a Headers object from an http.IncomingMessage.rawHeaders, ignoring those that do\n * not conform to HTTP grammar productions.\n * @param {import('http').IncomingMessage['rawHeaders']} headers\n */\nexport function fromRawHeaders(headers = []) {\n\treturn new Headers(\n\t\theaders\n\t\t\t// Split into pairs\n\t\t\t.reduce((result, value, index, array) => {\n\t\t\t\tif (index % 2 === 0) {\n\t\t\t\t\tresult.push(array.slice(index, index + 2));\n\t\t\t\t}\n\n\t\t\t\treturn result;\n\t\t\t}, [])\n\t\t\t.filter(([name, value]) => {\n\t\t\t\ttry {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn true;\n\t\t\t\t} catch {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t})\n\n\t);\n}\n","const redirectStatus = new Set([301, 302, 303, 307, 308]);\n\n/**\n * Redirect code matching\n *\n * @param {number} code - Status code\n * @return {boolean}\n */\nexport const isRedirect = code => {\n\treturn redirectStatus.has(code);\n};\n","/**\n * Response.js\n *\n * Response class provides content decoding\n */\n\nimport Headers from './headers.js';\nimport Body, {clone, extractContentType} from './body.js';\nimport {isRedirect} from './utils/is-redirect.js';\n\nconst INTERNALS = Symbol('Response internals');\n\n/**\n * Response class\n *\n * Ref: https://fetch.spec.whatwg.org/#response-class\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nexport default class Response extends Body {\n\tconstructor(body = null, options = {}) {\n\t\tsuper(body, options);\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq, no-negated-condition\n\t\tconst status = options.status != null ? options.status : 200;\n\n\t\tconst headers = new Headers(options.headers);\n\n\t\tif (body !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(body, this);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\ttype: 'default',\n\t\t\turl: options.url,\n\t\t\tstatus,\n\t\t\tstatusText: options.statusText || '',\n\t\t\theaders,\n\t\t\tcounter: options.counter,\n\t\t\thighWaterMark: options.highWaterMark\n\t\t};\n\t}\n\n\tget type() {\n\t\treturn this[INTERNALS].type;\n\t}\n\n\tget url() {\n\t\treturn this[INTERNALS].url || '';\n\t}\n\n\tget status() {\n\t\treturn this[INTERNALS].status;\n\t}\n\n\t/**\n\t * Convenience property representing if the request ended normally\n\t */\n\tget ok() {\n\t\treturn this[INTERNALS].status >= 200 && this[INTERNALS].status < 300;\n\t}\n\n\tget redirected() {\n\t\treturn this[INTERNALS].counter > 0;\n\t}\n\n\tget statusText() {\n\t\treturn this[INTERNALS].statusText;\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS].headers;\n\t}\n\n\tget highWaterMark() {\n\t\treturn this[INTERNALS].highWaterMark;\n\t}\n\n\t/**\n\t * Clone this response\n\t *\n\t * @return  Response\n\t */\n\tclone() {\n\t\treturn new Response(clone(this, this.highWaterMark), {\n\t\t\ttype: this.type,\n\t\t\turl: this.url,\n\t\t\tstatus: this.status,\n\t\t\tstatusText: this.statusText,\n\t\t\theaders: this.headers,\n\t\t\tok: this.ok,\n\t\t\tredirected: this.redirected,\n\t\t\tsize: this.size,\n\t\t\thighWaterMark: this.highWaterMark\n\t\t});\n\t}\n\n\t/**\n\t * @param {string} url    The URL that the new response is to originate from.\n\t * @param {number} status An optional status code for the response (e.g., 302.)\n\t * @returns {Response}    A Response object.\n\t */\n\tstatic redirect(url, status = 302) {\n\t\tif (!isRedirect(status)) {\n\t\t\tthrow new RangeError('Failed to execute \"redirect\" on \"response\": Invalid status code');\n\t\t}\n\n\t\treturn new Response(null, {\n\t\t\theaders: {\n\t\t\t\tlocation: new URL(url).toString()\n\t\t\t},\n\t\t\tstatus\n\t\t});\n\t}\n\n\tstatic error() {\n\t\tconst response = new Response(null, {status: 0, statusText: ''});\n\t\tresponse[INTERNALS].type = 'error';\n\t\treturn response;\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Response';\n\t}\n}\n\nObject.defineProperties(Response.prototype, {\n\ttype: {enumerable: true},\n\turl: {enumerable: true},\n\tstatus: {enumerable: true},\n\tok: {enumerable: true},\n\tredirected: {enumerable: true},\n\tstatusText: {enumerable: true},\n\theaders: {enumerable: true},\n\tclone: {enumerable: true}\n});\n","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"node:url\");","export const getSearch = parsedURL => {\n\tif (parsedURL.search) {\n\t\treturn parsedURL.search;\n\t}\n\n\tconst lastOffset = parsedURL.href.length - 1;\n\tconst hash = parsedURL.hash || (parsedURL.href[lastOffset] === '#' ? '#' : '');\n\treturn parsedURL.href[lastOffset - hash.length] === '?' ? '?' : '';\n};\n","const __WEBPACK_NAMESPACE_OBJECT__ = require(\"node:net\");","import {isIP} from 'node:net';\n\n/**\n * @external URL\n * @see {@link https://developer.mozilla.org/en-US/docs/Web/API/URL|URL}\n */\n\n/**\n * @module utils/referrer\n * @private\n */\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#strip-url|Referrer Policy §8.4. Strip url for use as a referrer}\n * @param {string} URL\n * @param {boolean} [originOnly=false]\n */\nexport function stripURLForUseAsAReferrer(url, originOnly = false) {\n\t// 1. If url is null, return no referrer.\n\tif (url == null) { // eslint-disable-line no-eq-null, eqeqeq\n\t\treturn 'no-referrer';\n\t}\n\n\turl = new URL(url);\n\n\t// 2. If url's scheme is a local scheme, then return no referrer.\n\tif (/^(about|blob|data):$/.test(url.protocol)) {\n\t\treturn 'no-referrer';\n\t}\n\n\t// 3. Set url's username to the empty string.\n\turl.username = '';\n\n\t// 4. Set url's password to null.\n\t// Note: `null` appears to be a mistake as this actually results in the password being `\"null\"`.\n\turl.password = '';\n\n\t// 5. Set url's fragment to null.\n\t// Note: `null` appears to be a mistake as this actually results in the fragment being `\"#null\"`.\n\turl.hash = '';\n\n\t// 6. If the origin-only flag is true, then:\n\tif (originOnly) {\n\t\t// 6.1. Set url's path to null.\n\t\t// Note: `null` appears to be a mistake as this actually results in the path being `\"/null\"`.\n\t\turl.pathname = '';\n\n\t\t// 6.2. Set url's query to null.\n\t\t// Note: `null` appears to be a mistake as this actually results in the query being `\"?null\"`.\n\t\turl.search = '';\n\t}\n\n\t// 7. Return url.\n\treturn url;\n}\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#enumdef-referrerpolicy|enum ReferrerPolicy}\n */\nexport const ReferrerPolicy = new Set([\n\t'',\n\t'no-referrer',\n\t'no-referrer-when-downgrade',\n\t'same-origin',\n\t'origin',\n\t'strict-origin',\n\t'origin-when-cross-origin',\n\t'strict-origin-when-cross-origin',\n\t'unsafe-url'\n]);\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#default-referrer-policy|default referrer policy}\n */\nexport const DEFAULT_REFERRER_POLICY = 'strict-origin-when-cross-origin';\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#referrer-policies|Referrer Policy §3. Referrer Policies}\n * @param {string} referrerPolicy\n * @returns {string} referrerPolicy\n */\nexport function validateReferrerPolicy(referrerPolicy) {\n\tif (!ReferrerPolicy.has(referrerPolicy)) {\n\t\tthrow new TypeError(`Invalid referrerPolicy: ${referrerPolicy}`);\n\t}\n\n\treturn referrerPolicy;\n}\n\n/**\n * @see {@link https://w3c.github.io/webappsec-secure-contexts/#is-origin-trustworthy|Referrer Policy §3.2. Is origin potentially trustworthy?}\n * @param {external:URL} url\n * @returns `true`: \"Potentially Trustworthy\", `false`: \"Not Trustworthy\"\n */\nexport function isOriginPotentiallyTrustworthy(url) {\n\t// 1. If origin is an opaque origin, return \"Not Trustworthy\".\n\t// Not applicable\n\n\t// 2. Assert: origin is a tuple origin.\n\t// Not for implementations\n\n\t// 3. If origin's scheme is either \"https\" or \"wss\", return \"Potentially Trustworthy\".\n\tif (/^(http|ws)s:$/.test(url.protocol)) {\n\t\treturn true;\n\t}\n\n\t// 4. If origin's host component matches one of the CIDR notations 127.0.0.0/8 or ::1/128 [RFC4632], return \"Potentially Trustworthy\".\n\tconst hostIp = url.host.replace(/(^\\[)|(]$)/g, '');\n\tconst hostIPVersion = isIP(hostIp);\n\n\tif (hostIPVersion === 4 && /^127\\./.test(hostIp)) {\n\t\treturn true;\n\t}\n\n\tif (hostIPVersion === 6 && /^(((0+:){7})|(::(0+:){0,6}))0*1$/.test(hostIp)) {\n\t\treturn true;\n\t}\n\n\t// 5. If origin's host component is \"localhost\" or falls within \".localhost\", and the user agent conforms to the name resolution rules in [let-localhost-be-localhost], return \"Potentially Trustworthy\".\n\t// We are returning FALSE here because we cannot ensure conformance to\n\t// let-localhost-be-loalhost (https://tools.ietf.org/html/draft-west-let-localhost-be-localhost)\n\tif (/^(.+\\.)*localhost$/.test(url.host)) {\n\t\treturn false;\n\t}\n\n\t// 6. If origin's scheme component is file, return \"Potentially Trustworthy\".\n\tif (url.protocol === 'file:') {\n\t\treturn true;\n\t}\n\n\t// 7. If origin's scheme component is one which the user agent considers to be authenticated, return \"Potentially Trustworthy\".\n\t// Not supported\n\n\t// 8. If origin has been configured as a trustworthy origin, return \"Potentially Trustworthy\".\n\t// Not supported\n\n\t// 9. Return \"Not Trustworthy\".\n\treturn false;\n}\n\n/**\n * @see {@link https://w3c.github.io/webappsec-secure-contexts/#is-url-trustworthy|Referrer Policy §3.3. Is url potentially trustworthy?}\n * @param {external:URL} url\n * @returns `true`: \"Potentially Trustworthy\", `false`: \"Not Trustworthy\"\n */\nexport function isUrlPotentiallyTrustworthy(url) {\n\t// 1. If url is \"about:blank\" or \"about:srcdoc\", return \"Potentially Trustworthy\".\n\tif (/^about:(blank|srcdoc)$/.test(url)) {\n\t\treturn true;\n\t}\n\n\t// 2. If url's scheme is \"data\", return \"Potentially Trustworthy\".\n\tif (url.protocol === 'data:') {\n\t\treturn true;\n\t}\n\n\t// Note: The origin of blob: and filesystem: URLs is the origin of the context in which they were\n\t// created. Therefore, blobs created in a trustworthy origin will themselves be potentially\n\t// trustworthy.\n\tif (/^(blob|filesystem):$/.test(url.protocol)) {\n\t\treturn true;\n\t}\n\n\t// 3. Return the result of executing §3.2 Is origin potentially trustworthy? on url's origin.\n\treturn isOriginPotentiallyTrustworthy(url);\n}\n\n/**\n * Modifies the referrerURL to enforce any extra security policy considerations.\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer|Referrer Policy §8.3. Determine request's Referrer}, step 7\n * @callback module:utils/referrer~referrerURLCallback\n * @param {external:URL} referrerURL\n * @returns {external:URL} modified referrerURL\n */\n\n/**\n * Modifies the referrerOrigin to enforce any extra security policy considerations.\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer|Referrer Policy §8.3. Determine request's Referrer}, step 7\n * @callback module:utils/referrer~referrerOriginCallback\n * @param {external:URL} referrerOrigin\n * @returns {external:URL} modified referrerOrigin\n */\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer|Referrer Policy §8.3. Determine request's Referrer}\n * @param {Request} request\n * @param {object} o\n * @param {module:utils/referrer~referrerURLCallback} o.referrerURLCallback\n * @param {module:utils/referrer~referrerOriginCallback} o.referrerOriginCallback\n * @returns {external:URL} Request's referrer\n */\nexport function determineRequestsReferrer(request, {referrerURLCallback, referrerOriginCallback} = {}) {\n\t// There are 2 notes in the specification about invalid pre-conditions.  We return null, here, for\n\t// these cases:\n\t// > Note: If request's referrer is \"no-referrer\", Fetch will not call into this algorithm.\n\t// > Note: If request's referrer policy is the empty string, Fetch will not call into this\n\t// > algorithm.\n\tif (request.referrer === 'no-referrer' || request.referrerPolicy === '') {\n\t\treturn null;\n\t}\n\n\t// 1. Let policy be request's associated referrer policy.\n\tconst policy = request.referrerPolicy;\n\n\t// 2. Let environment be request's client.\n\t// not applicable to node.js\n\n\t// 3. Switch on request's referrer:\n\tif (request.referrer === 'about:client') {\n\t\treturn 'no-referrer';\n\t}\n\n\t// \"a URL\": Let referrerSource be request's referrer.\n\tconst referrerSource = request.referrer;\n\n\t// 4. Let request's referrerURL be the result of stripping referrerSource for use as a referrer.\n\tlet referrerURL = stripURLForUseAsAReferrer(referrerSource);\n\n\t// 5. Let referrerOrigin be the result of stripping referrerSource for use as a referrer, with the\n\t//    origin-only flag set to true.\n\tlet referrerOrigin = stripURLForUseAsAReferrer(referrerSource, true);\n\n\t// 6. If the result of serializing referrerURL is a string whose length is greater than 4096, set\n\t//    referrerURL to referrerOrigin.\n\tif (referrerURL.toString().length > 4096) {\n\t\treferrerURL = referrerOrigin;\n\t}\n\n\t// 7. The user agent MAY alter referrerURL or referrerOrigin at this point to enforce arbitrary\n\t//    policy considerations in the interests of minimizing data leakage. For example, the user\n\t//    agent could strip the URL down to an origin, modify its host, replace it with an empty\n\t//    string, etc.\n\tif (referrerURLCallback) {\n\t\treferrerURL = referrerURLCallback(referrerURL);\n\t}\n\n\tif (referrerOriginCallback) {\n\t\treferrerOrigin = referrerOriginCallback(referrerOrigin);\n\t}\n\n\t// 8.Execute the statements corresponding to the value of policy:\n\tconst currentURL = new URL(request.url);\n\n\tswitch (policy) {\n\t\tcase 'no-referrer':\n\t\t\treturn 'no-referrer';\n\n\t\tcase 'origin':\n\t\t\treturn referrerOrigin;\n\n\t\tcase 'unsafe-url':\n\t\t\treturn referrerURL;\n\n\t\tcase 'strict-origin':\n\t\t\t// 1. If referrerURL is a potentially trustworthy URL and request's current URL is not a\n\t\t\t//    potentially trustworthy URL, then return no referrer.\n\t\t\tif (isUrlPotentiallyTrustworthy(referrerURL) && !isUrlPotentiallyTrustworthy(currentURL)) {\n\t\t\t\treturn 'no-referrer';\n\t\t\t}\n\n\t\t\t// 2. Return referrerOrigin.\n\t\t\treturn referrerOrigin.toString();\n\n\t\tcase 'strict-origin-when-cross-origin':\n\t\t\t// 1. If the origin of referrerURL and the origin of request's current URL are the same, then\n\t\t\t//    return referrerURL.\n\t\t\tif (referrerURL.origin === currentURL.origin) {\n\t\t\t\treturn referrerURL;\n\t\t\t}\n\n\t\t\t// 2. If referrerURL is a potentially trustworthy URL and request's current URL is not a\n\t\t\t//    potentially trustworthy URL, then return no referrer.\n\t\t\tif (isUrlPotentiallyTrustworthy(referrerURL) && !isUrlPotentiallyTrustworthy(currentURL)) {\n\t\t\t\treturn 'no-referrer';\n\t\t\t}\n\n\t\t\t// 3. Return referrerOrigin.\n\t\t\treturn referrerOrigin;\n\n\t\tcase 'same-origin':\n\t\t\t// 1. If the origin of referrerURL and the origin of request's current URL are the same, then\n\t\t\t//    return referrerURL.\n\t\t\tif (referrerURL.origin === currentURL.origin) {\n\t\t\t\treturn referrerURL;\n\t\t\t}\n\n\t\t\t// 2. Return no referrer.\n\t\t\treturn 'no-referrer';\n\n\t\tcase 'origin-when-cross-origin':\n\t\t\t// 1. If the origin of referrerURL and the origin of request's current URL are the same, then\n\t\t\t//    return referrerURL.\n\t\t\tif (referrerURL.origin === currentURL.origin) {\n\t\t\t\treturn referrerURL;\n\t\t\t}\n\n\t\t\t// Return referrerOrigin.\n\t\t\treturn referrerOrigin;\n\n\t\tcase 'no-referrer-when-downgrade':\n\t\t\t// 1. If referrerURL is a potentially trustworthy URL and request's current URL is not a\n\t\t\t//    potentially trustworthy URL, then return no referrer.\n\t\t\tif (isUrlPotentiallyTrustworthy(referrerURL) && !isUrlPotentiallyTrustworthy(currentURL)) {\n\t\t\t\treturn 'no-referrer';\n\t\t\t}\n\n\t\t\t// 2. Return referrerURL.\n\t\t\treturn referrerURL;\n\n\t\tdefault:\n\t\t\tthrow new TypeError(`Invalid referrerPolicy: ${policy}`);\n\t}\n}\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#parse-referrer-policy-from-header|Referrer Policy §8.1. Parse a referrer policy from a Referrer-Policy header}\n * @param {Headers} headers Response headers\n * @returns {string} policy\n */\nexport function parseReferrerPolicyFromHeader(headers) {\n\t// 1. Let policy-tokens be the result of extracting header list values given `Referrer-Policy`\n\t//    and response’s header list.\n\tconst policyTokens = (headers.get('referrer-policy') || '').split(/[,\\s]+/);\n\n\t// 2. Let policy be the empty string.\n\tlet policy = '';\n\n\t// 3. For each token in policy-tokens, if token is a referrer policy and token is not the empty\n\t//    string, then set policy to token.\n\t// Note: This algorithm loops over multiple policy values to allow deployment of new policy\n\t// values with fallbacks for older user agents, as described in § 11.1 Unknown Policy Values.\n\tfor (const token of policyTokens) {\n\t\tif (token && ReferrerPolicy.has(token)) {\n\t\t\tpolicy = token;\n\t\t}\n\t}\n\n\t// 4. Return policy.\n\treturn policy;\n}\n","/**\n * Request.js\n *\n * Request class contains server only options\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\nimport {format as formatUrl} from 'node:url';\nimport {deprecate} from 'node:util';\nimport Headers from './headers.js';\nimport Body, {clone, extractContentType, getTotalBytes} from './body.js';\nimport {isAbortSignal} from './utils/is.js';\nimport {getSearch} from './utils/get-search.js';\nimport {\n\tvalidateReferrerPolicy, determineRequestsReferrer, DEFAULT_REFERRER_POLICY\n} from './utils/referrer.js';\n\nconst INTERNALS = Symbol('Request internals');\n\n/**\n * Check if `obj` is an instance of Request.\n *\n * @param  {*} object\n * @return {boolean}\n */\nconst isRequest = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object[INTERNALS] === 'object'\n\t);\n};\n\nconst doBadDataWarn = deprecate(() => {},\n\t'.data is not a valid RequestInit property, use .body instead',\n\t'https://github.com/node-fetch/node-fetch/issues/1000 (request)');\n\n/**\n * Request class\n *\n * Ref: https://fetch.spec.whatwg.org/#request-class\n *\n * @param   Mixed   input  Url or Request instance\n * @param   Object  init   Custom options\n * @return  Void\n */\nexport default class Request extends Body {\n\tconstructor(input, init = {}) {\n\t\tlet parsedURL;\n\n\t\t// Normalize input and force URL to be encoded as UTF-8 (https://github.com/node-fetch/node-fetch/issues/245)\n\t\tif (isRequest(input)) {\n\t\t\tparsedURL = new URL(input.url);\n\t\t} else {\n\t\t\tparsedURL = new URL(input);\n\t\t\tinput = {};\n\t\t}\n\n\t\tif (parsedURL.username !== '' || parsedURL.password !== '') {\n\t\t\tthrow new TypeError(`${parsedURL} is an url with embedded credentials.`);\n\t\t}\n\n\t\tlet method = init.method || input.method || 'GET';\n\t\tmethod = method.toUpperCase();\n\n\t\tif ('data' in init) {\n\t\t\tdoBadDataWarn();\n\t\t}\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif ((init.body != null || (isRequest(input) && input.body !== null)) &&\n\t\t\t(method === 'GET' || method === 'HEAD')) {\n\t\t\tthrow new TypeError('Request with GET/HEAD method cannot have body');\n\t\t}\n\n\t\tconst inputBody = init.body ?\n\t\t\tinit.body :\n\t\t\t(isRequest(input) && input.body !== null ?\n\t\t\t\tclone(input) :\n\t\t\t\tnull);\n\n\t\tsuper(inputBody, {\n\t\t\tsize: init.size || input.size || 0\n\t\t});\n\n\t\tconst headers = new Headers(init.headers || input.headers || {});\n\n\t\tif (inputBody !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(inputBody, this);\n\t\t\tif (contentType) {\n\t\t\t\theaders.set('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tlet signal = isRequest(input) ?\n\t\t\tinput.signal :\n\t\t\tnull;\n\t\tif ('signal' in init) {\n\t\t\tsignal = init.signal;\n\t\t}\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif (signal != null && !isAbortSignal(signal)) {\n\t\t\tthrow new TypeError('Expected signal to be an instanceof AbortSignal or EventTarget');\n\t\t}\n\n\t\t// §5.4, Request constructor steps, step 15.1\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tlet referrer = init.referrer == null ? input.referrer : init.referrer;\n\t\tif (referrer === '') {\n\t\t\t// §5.4, Request constructor steps, step 15.2\n\t\t\treferrer = 'no-referrer';\n\t\t} else if (referrer) {\n\t\t\t// §5.4, Request constructor steps, step 15.3.1, 15.3.2\n\t\t\tconst parsedReferrer = new URL(referrer);\n\t\t\t// §5.4, Request constructor steps, step 15.3.3, 15.3.4\n\t\t\treferrer = /^about:(\\/\\/)?client$/.test(parsedReferrer) ? 'client' : parsedReferrer;\n\t\t} else {\n\t\t\treferrer = undefined;\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\tmethod,\n\t\t\tredirect: init.redirect || input.redirect || 'follow',\n\t\t\theaders,\n\t\t\tparsedURL,\n\t\t\tsignal,\n\t\t\treferrer\n\t\t};\n\n\t\t// Node-fetch-only options\n\t\tthis.follow = init.follow === undefined ? (input.follow === undefined ? 20 : input.follow) : init.follow;\n\t\tthis.compress = init.compress === undefined ? (input.compress === undefined ? true : input.compress) : init.compress;\n\t\tthis.counter = init.counter || input.counter || 0;\n\t\tthis.agent = init.agent || input.agent;\n\t\tthis.highWaterMark = init.highWaterMark || input.highWaterMark || 16384;\n\t\tthis.insecureHTTPParser = init.insecureHTTPParser || input.insecureHTTPParser || false;\n\n\t\t// §5.4, Request constructor steps, step 16.\n\t\t// Default is empty string per https://fetch.spec.whatwg.org/#concept-request-referrer-policy\n\t\tthis.referrerPolicy = init.referrerPolicy || input.referrerPolicy || '';\n\t}\n\n\t/** @returns {string} */\n\tget method() {\n\t\treturn this[INTERNALS].method;\n\t}\n\n\t/** @returns {string} */\n\tget url() {\n\t\treturn formatUrl(this[INTERNALS].parsedURL);\n\t}\n\n\t/** @returns {Headers} */\n\tget headers() {\n\t\treturn this[INTERNALS].headers;\n\t}\n\n\tget redirect() {\n\t\treturn this[INTERNALS].redirect;\n\t}\n\n\t/** @returns {AbortSignal} */\n\tget signal() {\n\t\treturn this[INTERNALS].signal;\n\t}\n\n\t// https://fetch.spec.whatwg.org/#dom-request-referrer\n\tget referrer() {\n\t\tif (this[INTERNALS].referrer === 'no-referrer') {\n\t\t\treturn '';\n\t\t}\n\n\t\tif (this[INTERNALS].referrer === 'client') {\n\t\t\treturn 'about:client';\n\t\t}\n\n\t\tif (this[INTERNALS].referrer) {\n\t\t\treturn this[INTERNALS].referrer.toString();\n\t\t}\n\n\t\treturn undefined;\n\t}\n\n\tget referrerPolicy() {\n\t\treturn this[INTERNALS].referrerPolicy;\n\t}\n\n\tset referrerPolicy(referrerPolicy) {\n\t\tthis[INTERNALS].referrerPolicy = validateReferrerPolicy(referrerPolicy);\n\t}\n\n\t/**\n\t * Clone this request\n\t *\n\t * @return  Request\n\t */\n\tclone() {\n\t\treturn new Request(this);\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Request';\n\t}\n}\n\nObject.defineProperties(Request.prototype, {\n\tmethod: {enumerable: true},\n\turl: {enumerable: true},\n\theaders: {enumerable: true},\n\tredirect: {enumerable: true},\n\tclone: {enumerable: true},\n\tsignal: {enumerable: true},\n\treferrer: {enumerable: true},\n\treferrerPolicy: {enumerable: true}\n});\n\n/**\n * Convert a Request to Node.js http request options.\n *\n * @param {Request} request - A Request instance\n * @return The options object to be passed to http.request\n */\nexport const getNodeRequestOptions = request => {\n\tconst {parsedURL} = request[INTERNALS];\n\tconst headers = new Headers(request[INTERNALS].headers);\n\n\t// Fetch step 1.3\n\tif (!headers.has('Accept')) {\n\t\theaders.set('Accept', '*/*');\n\t}\n\n\t// HTTP-network-or-cache fetch steps 2.4-2.7\n\tlet contentLengthValue = null;\n\tif (request.body === null && /^(post|put)$/i.test(request.method)) {\n\t\tcontentLengthValue = '0';\n\t}\n\n\tif (request.body !== null) {\n\t\tconst totalBytes = getTotalBytes(request);\n\t\t// Set Content-Length if totalBytes is a number (that is not NaN)\n\t\tif (typeof totalBytes === 'number' && !Number.isNaN(totalBytes)) {\n\t\t\tcontentLengthValue = String(totalBytes);\n\t\t}\n\t}\n\n\tif (contentLengthValue) {\n\t\theaders.set('Content-Length', contentLengthValue);\n\t}\n\n\t// 4.1. Main fetch, step 2.6\n\t// > If request's referrer policy is the empty string, then set request's referrer policy to the\n\t// > default referrer policy.\n\tif (request.referrerPolicy === '') {\n\t\trequest.referrerPolicy = DEFAULT_REFERRER_POLICY;\n\t}\n\n\t// 4.1. Main fetch, step 2.7\n\t// > If request's referrer is not \"no-referrer\", set request's referrer to the result of invoking\n\t// > determine request's referrer.\n\tif (request.referrer && request.referrer !== 'no-referrer') {\n\t\trequest[INTERNALS].referrer = determineRequestsReferrer(request);\n\t} else {\n\t\trequest[INTERNALS].referrer = 'no-referrer';\n\t}\n\n\t// 4.5. HTTP-network-or-cache fetch, step 6.9\n\t// > If httpRequest's referrer is a URL, then append `Referer`/httpRequest's referrer, serialized\n\t// >  and isomorphic encoded, to httpRequest's header list.\n\tif (request[INTERNALS].referrer instanceof URL) {\n\t\theaders.set('Referer', request.referrer);\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.11\n\tif (!headers.has('User-Agent')) {\n\t\theaders.set('User-Agent', 'node-fetch');\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.15\n\tif (request.compress && !headers.has('Accept-Encoding')) {\n\t\theaders.set('Accept-Encoding', 'gzip,deflate,br');\n\t}\n\n\tlet {agent} = request;\n\tif (typeof agent === 'function') {\n\t\tagent = agent(parsedURL);\n\t}\n\n\tif (!headers.has('Connection') && !agent) {\n\t\theaders.set('Connection', 'close');\n\t}\n\n\t// HTTP-network fetch step 4.2\n\t// chunked encoding is handled by Node.js\n\n\tconst search = getSearch(parsedURL);\n\n\t// Pass the full URL directly to request(), but overwrite the following\n\t// options:\n\tconst options = {\n\t\t// Overwrite search to retain trailing ? (issue #776)\n\t\tpath: parsedURL.pathname + search,\n\t\t// The following options are not expressed in the URL\n\t\tmethod: request.method,\n\t\theaders: headers[Symbol.for('nodejs.util.inspect.custom')](),\n\t\tinsecureHTTPParser: request.insecureHTTPParser,\n\t\tagent\n\t};\n\n\treturn {\n\t\t/** @type {URL} */\n\t\tparsedURL,\n\t\toptions\n\t};\n};\n","import {FetchBaseError} from './base.js';\n\n/**\n * AbortError interface for cancelled requests\n */\nexport class AbortError extends FetchBaseError {\n\tconstructor(message, type = 'aborted') {\n\t\tsuper(message, type);\n\t}\n}\n","/**\n * Index.js\n *\n * a request API compatible with window.fetch\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\nimport http from 'node:http';\nimport https from 'node:https';\nimport zlib from 'node:zlib';\nimport Stream, {PassThrough, pipeline as pump} from 'node:stream';\nimport {Buffer} from 'node:buffer';\n\nimport dataUriToBuffer from 'data-uri-to-buffer';\n\nimport {writeToStream, clone} from './body.js';\nimport Response from './response.js';\nimport Headers, {fromRawHeaders} from './headers.js';\nimport Request, {getNodeRequestOptions} from './request.js';\nimport {FetchError} from './errors/fetch-error.js';\nimport {AbortError} from './errors/abort-error.js';\nimport {isRedirect} from './utils/is-redirect.js';\nimport {FormData} from 'formdata-polyfill/esm.min.js';\nimport {isDomainOrSubdomain} from './utils/is.js';\nimport {parseReferrerPolicyFromHeader} from './utils/referrer.js';\nimport {\n\tBlob,\n\tFile,\n\tfileFromSync,\n\tfileFrom,\n\tblobFromSync,\n\tblobFrom\n} from 'fetch-blob/from.js';\n\nexport {FormData, Headers, Request, Response, FetchError, AbortError, isRedirect};\nexport {Blob, File, fileFromSync, fileFrom, blobFromSync, blobFrom};\n\nconst supportedSchemas = new Set(['data:', 'http:', 'https:']);\n\n/**\n * Fetch function\n *\n * @param   {string | URL | import('./request').default} url - Absolute url or Request instance\n * @param   {*} [options_] - Fetch options\n * @return  {Promise<import('./response').default>}\n */\nexport default async function fetch(url, options_) {\n\treturn new Promise((resolve, reject) => {\n\t\t// Build request object\n\t\tconst request = new Request(url, options_);\n\t\tconst {parsedURL, options} = getNodeRequestOptions(request);\n\t\tif (!supportedSchemas.has(parsedURL.protocol)) {\n\t\t\tthrow new TypeError(`node-fetch cannot load ${url}. URL scheme \"${parsedURL.protocol.replace(/:$/, '')}\" is not supported.`);\n\t\t}\n\n\t\tif (parsedURL.protocol === 'data:') {\n\t\t\tconst data = dataUriToBuffer(request.url);\n\t\t\tconst response = new Response(data, {headers: {'Content-Type': data.typeFull}});\n\t\t\tresolve(response);\n\t\t\treturn;\n\t\t}\n\n\t\t// Wrap http.request into fetch\n\t\tconst send = (parsedURL.protocol === 'https:' ? https : http).request;\n\t\tconst {signal} = request;\n\t\tlet response = null;\n\n\t\tconst abort = () => {\n\t\t\tconst error = new AbortError('The operation was aborted.');\n\t\t\treject(error);\n\t\t\tif (request.body && request.body instanceof Stream.Readable) {\n\t\t\t\trequest.body.destroy(error);\n\t\t\t}\n\n\t\t\tif (!response || !response.body) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tresponse.body.emit('error', error);\n\t\t};\n\n\t\tif (signal && signal.aborted) {\n\t\t\tabort();\n\t\t\treturn;\n\t\t}\n\n\t\tconst abortAndFinalize = () => {\n\t\t\tabort();\n\t\t\tfinalize();\n\t\t};\n\n\t\t// Send request\n\t\tconst request_ = send(parsedURL.toString(), options);\n\n\t\tif (signal) {\n\t\t\tsignal.addEventListener('abort', abortAndFinalize);\n\t\t}\n\n\t\tconst finalize = () => {\n\t\t\trequest_.abort();\n\t\t\tif (signal) {\n\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t}\n\t\t};\n\n\t\trequest_.on('error', error => {\n\t\t\treject(new FetchError(`request to ${request.url} failed, reason: ${error.message}`, 'system', error));\n\t\t\tfinalize();\n\t\t});\n\n\t\tfixResponseChunkedTransferBadEnding(request_, error => {\n\t\t\tresponse.body.destroy(error);\n\t\t});\n\n\t\t/* c8 ignore next 18 */\n\t\tif (process.version < 'v14') {\n\t\t\t// Before Node.js 14, pipeline() does not fully support async iterators and does not always\n\t\t\t// properly handle when the socket close/end events are out of order.\n\t\t\trequest_.on('socket', s => {\n\t\t\t\tlet endedWithEventsCount;\n\t\t\t\ts.prependListener('end', () => {\n\t\t\t\t\tendedWithEventsCount = s._eventsCount;\n\t\t\t\t});\n\t\t\t\ts.prependListener('close', hadError => {\n\t\t\t\t\t// if end happened before close but the socket didn't emit an error, do it now\n\t\t\t\t\tif (response && endedWithEventsCount < s._eventsCount && !hadError) {\n\t\t\t\t\t\tconst error = new Error('Premature close');\n\t\t\t\t\t\terror.code = 'ERR_STREAM_PREMATURE_CLOSE';\n\t\t\t\t\t\tresponse.body.emit('error', error);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t});\n\t\t}\n\n\t\trequest_.on('response', response_ => {\n\t\t\trequest_.setTimeout(0);\n\t\t\tconst headers = fromRawHeaders(response_.rawHeaders);\n\n\t\t\t// HTTP fetch step 5\n\t\t\tif (isRedirect(response_.statusCode)) {\n\t\t\t\t// HTTP fetch step 5.2\n\t\t\t\tconst location = headers.get('Location');\n\n\t\t\t\t// HTTP fetch step 5.3\n\t\t\t\tlet locationURL = null;\n\t\t\t\ttry {\n\t\t\t\t\tlocationURL = location === null ? null : new URL(location, request.url);\n\t\t\t\t} catch {\n\t\t\t\t\t// error here can only be invalid URL in Location: header\n\t\t\t\t\t// do not throw when options.redirect == manual\n\t\t\t\t\t// let the user extract the errorneous redirect URL\n\t\t\t\t\tif (request.redirect !== 'manual') {\n\t\t\t\t\t\treject(new FetchError(`uri requested responds with an invalid redirect URL: ${location}`, 'invalid-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// HTTP fetch step 5.5\n\t\t\t\tswitch (request.redirect) {\n\t\t\t\t\tcase 'error':\n\t\t\t\t\t\treject(new FetchError(`uri requested responds with a redirect, redirect mode is set to error: ${request.url}`, 'no-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\tcase 'manual':\n\t\t\t\t\t\t// Nothing to do\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'follow': {\n\t\t\t\t\t\t// HTTP-redirect fetch step 2\n\t\t\t\t\t\tif (locationURL === null) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 5\n\t\t\t\t\t\tif (request.counter >= request.follow) {\n\t\t\t\t\t\t\treject(new FetchError(`maximum redirect reached at: ${request.url}`, 'max-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 6 (counter increment)\n\t\t\t\t\t\t// Create a new Request object.\n\t\t\t\t\t\tconst requestOptions = {\n\t\t\t\t\t\t\theaders: new Headers(request.headers),\n\t\t\t\t\t\t\tfollow: request.follow,\n\t\t\t\t\t\t\tcounter: request.counter + 1,\n\t\t\t\t\t\t\tagent: request.agent,\n\t\t\t\t\t\t\tcompress: request.compress,\n\t\t\t\t\t\t\tmethod: request.method,\n\t\t\t\t\t\t\tbody: clone(request),\n\t\t\t\t\t\t\tsignal: request.signal,\n\t\t\t\t\t\t\tsize: request.size,\n\t\t\t\t\t\t\treferrer: request.referrer,\n\t\t\t\t\t\t\treferrerPolicy: request.referrerPolicy\n\t\t\t\t\t\t};\n\n\t\t\t\t\t\t// when forwarding sensitive headers like \"Authorization\",\n\t\t\t\t\t\t// \"WWW-Authenticate\", and \"Cookie\" to untrusted targets,\n\t\t\t\t\t\t// headers will be ignored when following a redirect to a domain\n\t\t\t\t\t\t// that is not a subdomain match or exact match of the initial domain.\n\t\t\t\t\t\t// For example, a redirect from \"foo.com\" to either \"foo.com\" or \"sub.foo.com\"\n\t\t\t\t\t\t// will forward the sensitive headers, but a redirect to \"bar.com\" will not.\n\t\t\t\t\t\tif (!isDomainOrSubdomain(request.url, locationURL)) {\n\t\t\t\t\t\t\tfor (const name of ['authorization', 'www-authenticate', 'cookie', 'cookie2']) {\n\t\t\t\t\t\t\t\trequestOptions.headers.delete(name);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 9\n\t\t\t\t\t\tif (response_.statusCode !== 303 && request.body && options_.body instanceof Stream.Readable) {\n\t\t\t\t\t\t\treject(new FetchError('Cannot follow redirect with body being a readable stream', 'unsupported-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 11\n\t\t\t\t\t\tif (response_.statusCode === 303 || ((response_.statusCode === 301 || response_.statusCode === 302) && request.method === 'POST')) {\n\t\t\t\t\t\t\trequestOptions.method = 'GET';\n\t\t\t\t\t\t\trequestOptions.body = undefined;\n\t\t\t\t\t\t\trequestOptions.headers.delete('content-length');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 14\n\t\t\t\t\t\tconst responseReferrerPolicy = parseReferrerPolicyFromHeader(headers);\n\t\t\t\t\t\tif (responseReferrerPolicy) {\n\t\t\t\t\t\t\trequestOptions.referrerPolicy = responseReferrerPolicy;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 15\n\t\t\t\t\t\tresolve(fetch(new Request(locationURL, requestOptions)));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn reject(new TypeError(`Redirect option '${request.redirect}' is not a valid value of RequestRedirect`));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Prepare response\n\t\t\tif (signal) {\n\t\t\t\tresponse_.once('end', () => {\n\t\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tlet body = pump(response_, new PassThrough(), error => {\n\t\t\t\tif (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t}\n\t\t\t});\n\t\t\t// see https://github.com/nodejs/node/pull/29376\n\t\t\t/* c8 ignore next 3 */\n\t\t\tif (process.version < 'v12.10') {\n\t\t\t\tresponse_.on('aborted', abortAndFinalize);\n\t\t\t}\n\n\t\t\tconst responseOptions = {\n\t\t\t\turl: request.url,\n\t\t\t\tstatus: response_.statusCode,\n\t\t\t\tstatusText: response_.statusMessage,\n\t\t\t\theaders,\n\t\t\t\tsize: request.size,\n\t\t\t\tcounter: request.counter,\n\t\t\t\thighWaterMark: request.highWaterMark\n\t\t\t};\n\n\t\t\t// HTTP-network fetch step 12.1.1.3\n\t\t\tconst codings = headers.get('Content-Encoding');\n\n\t\t\t// HTTP-network fetch step 12.1.1.4: handle content codings\n\n\t\t\t// in following scenarios we ignore compression support\n\t\t\t// 1. compression support is disabled\n\t\t\t// 2. HEAD request\n\t\t\t// 3. no Content-Encoding header\n\t\t\t// 4. no content response (204)\n\t\t\t// 5. content not modified response (304)\n\t\t\tif (!request.compress || request.method === 'HEAD' || codings === null || response_.statusCode === 204 || response_.statusCode === 304) {\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For Node v6+\n\t\t\t// Be less strict when decoding compressed responses, since sometimes\n\t\t\t// servers send slightly invalid responses that are still accepted\n\t\t\t// by common browsers.\n\t\t\t// Always using Z_SYNC_FLUSH is what cURL does.\n\t\t\tconst zlibOptions = {\n\t\t\t\tflush: zlib.Z_SYNC_FLUSH,\n\t\t\t\tfinishFlush: zlib.Z_SYNC_FLUSH\n\t\t\t};\n\n\t\t\t// For gzip\n\t\t\tif (codings === 'gzip' || codings === 'x-gzip') {\n\t\t\t\tbody = pump(body, zlib.createGunzip(zlibOptions), error => {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\treject(error);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For deflate\n\t\t\tif (codings === 'deflate' || codings === 'x-deflate') {\n\t\t\t\t// Handle the infamous raw deflate response from old servers\n\t\t\t\t// a hack for old IIS and Apache servers\n\t\t\t\tconst raw = pump(response_, new PassThrough(), error => {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\treject(error);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\traw.once('data', chunk => {\n\t\t\t\t\t// See http://stackoverflow.com/questions/37519828\n\t\t\t\t\tif ((chunk[0] & 0x0F) === 0x08) {\n\t\t\t\t\t\tbody = pump(body, zlib.createInflate(), error => {\n\t\t\t\t\t\t\tif (error) {\n\t\t\t\t\t\t\t\treject(error);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbody = pump(body, zlib.createInflateRaw(), error => {\n\t\t\t\t\t\t\tif (error) {\n\t\t\t\t\t\t\t\treject(error);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\n\t\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\t\tresolve(response);\n\t\t\t\t});\n\t\t\t\traw.once('end', () => {\n\t\t\t\t\t// Some old IIS servers return zero-length OK deflate responses, so\n\t\t\t\t\t// 'data' is never emitted. See https://github.com/node-fetch/node-fetch/pull/903\n\t\t\t\t\tif (!response) {\n\t\t\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\t\t\tresolve(response);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For br\n\t\t\tif (codings === 'br') {\n\t\t\t\tbody = pump(body, zlib.createBrotliDecompress(), error => {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\treject(error);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Otherwise, use response as-is\n\t\t\tresponse = new Response(body, responseOptions);\n\t\t\tresolve(response);\n\t\t});\n\n\t\t// eslint-disable-next-line promise/prefer-await-to-then\n\t\twriteToStream(request_, request).catch(reject);\n\t});\n}\n\nfunction fixResponseChunkedTransferBadEnding(request, errorCallback) {\n\tconst LAST_CHUNK = Buffer.from('0\\r\\n\\r\\n');\n\n\tlet isChunkedTransfer = false;\n\tlet properLastChunkReceived = false;\n\tlet previousChunk;\n\n\trequest.on('response', response => {\n\t\tconst {headers} = response;\n\t\tisChunkedTransfer = headers['transfer-encoding'] === 'chunked' && !headers['content-length'];\n\t});\n\n\trequest.on('socket', socket => {\n\t\tconst onSocketClose = () => {\n\t\t\tif (isChunkedTransfer && !properLastChunkReceived) {\n\t\t\t\tconst error = new Error('Premature close');\n\t\t\t\terror.code = 'ERR_STREAM_PREMATURE_CLOSE';\n\t\t\t\terrorCallback(error);\n\t\t\t}\n\t\t};\n\n\t\tsocket.prependListener('close', onSocketClose);\n\n\t\trequest.on('abort', () => {\n\t\t\tsocket.removeListener('close', onSocketClose);\n\t\t});\n\n\t\tsocket.on('data', buf => {\n\t\t\tproperLastChunkReceived = Buffer.compare(buf.slice(-5), LAST_CHUNK) === 0;\n\n\t\t\t// Sometimes final 0-length chunk and end of message code are in separate packets\n\t\t\tif (!properLastChunkReceived && previousChunk) {\n\t\t\t\tproperLastChunkReceived = (\n\t\t\t\t\tBuffer.compare(previousChunk.slice(-3), LAST_CHUNK.slice(0, 3)) === 0 &&\n\t\t\t\t\tBuffer.compare(buf.slice(-2), LAST_CHUNK.slice(3)) === 0\n\t\t\t\t);\n\t\t\t}\n\n\t\t\tpreviousChunk = buf;\n\t\t});\n\t});\n}\n","'use strict'\n\n// high-level commands\nexports.c = exports.create = require('./lib/create.js')\nexports.r = exports.replace = require('./lib/replace.js')\nexports.t = exports.list = require('./lib/list.js')\nexports.u = exports.update = require('./lib/update.js')\nexports.x = exports.extract = require('./lib/extract.js')\n\n// classes\nexports.Pack = require('./lib/pack.js')\nexports.Unpack = require('./lib/unpack.js')\nexports.Parse = require('./lib/parse.js')\nexports.ReadEntry = require('./lib/read-entry.js')\nexports.WriteEntry = require('./lib/write-entry.js')\nexports.Header = require('./lib/header.js')\nexports.Pax = require('./lib/pax.js')\nexports.types = require('./lib/types.js')\n","'use strict'\n\n// tar -c\nconst hlo = require('./high-level-opt.js')\n\nconst Pack = require('./pack.js')\nconst fsm = require('fs-minipass')\nconst t = require('./list.js')\nconst path = require('path')\n\nmodule.exports = (opt_, files, cb) => {\n  if (typeof files === 'function')\n    cb = files\n\n  if (Array.isArray(opt_))\n    files = opt_, opt_ = {}\n\n  if (!files || !Array.isArray(files) || !files.length)\n    throw new TypeError('no files or directories specified')\n\n  files = Array.from(files)\n\n  const opt = hlo(opt_)\n\n  if (opt.sync && typeof cb === 'function')\n    throw new TypeError('callback not supported for sync tar functions')\n\n  if (!opt.file && typeof cb === 'function')\n    throw new TypeError('callback only supported with file option')\n\n  return opt.file && opt.sync ? createFileSync(opt, files)\n    : opt.file ? createFile(opt, files, cb)\n    : opt.sync ? createSync(opt, files)\n    : create(opt, files)\n}\n\nconst createFileSync = (opt, files) => {\n  const p = new Pack.Sync(opt)\n  const stream = new fsm.WriteStreamSync(opt.file, {\n    mode: opt.mode || 0o666,\n  })\n  p.pipe(stream)\n  addFilesSync(p, files)\n}\n\nconst createFile = (opt, files, cb) => {\n  const p = new Pack(opt)\n  const stream = new fsm.WriteStream(opt.file, {\n    mode: opt.mode || 0o666,\n  })\n  p.pipe(stream)\n\n  const promise = new Promise((res, rej) => {\n    stream.on('error', rej)\n    stream.on('close', res)\n    p.on('error', rej)\n  })\n\n  addFilesAsync(p, files)\n\n  return cb ? promise.then(cb, cb) : promise\n}\n\nconst addFilesSync = (p, files) => {\n  files.forEach(file => {\n    if (file.charAt(0) === '@') {\n      t({\n        file: path.resolve(p.cwd, file.substr(1)),\n        sync: true,\n        noResume: true,\n        onentry: entry => p.add(entry),\n      })\n    } else\n      p.add(file)\n  })\n  p.end()\n}\n\nconst addFilesAsync = (p, files) => {\n  while (files.length) {\n    const file = files.shift()\n    if (file.charAt(0) === '@') {\n      return t({\n        file: path.resolve(p.cwd, file.substr(1)),\n        noResume: true,\n        onentry: entry => p.add(entry),\n      }).then(_ => addFilesAsync(p, files))\n    } else\n      p.add(file)\n  }\n  p.end()\n}\n\nconst createSync = (opt, files) => {\n  const p = new Pack.Sync(opt)\n  addFilesSync(p, files)\n  return p\n}\n\nconst create = (opt, files) => {\n  const p = new Pack(opt)\n  addFilesAsync(p, files)\n  return p\n}\n","'use strict'\n\n// tar -x\nconst hlo = require('./high-level-opt.js')\nconst Unpack = require('./unpack.js')\nconst fs = require('fs')\nconst fsm = require('fs-minipass')\nconst path = require('path')\nconst stripSlash = require('./strip-trailing-slashes.js')\n\nmodule.exports = (opt_, files, cb) => {\n  if (typeof opt_ === 'function')\n    cb = opt_, files = null, opt_ = {}\n  else if (Array.isArray(opt_))\n    files = opt_, opt_ = {}\n\n  if (typeof files === 'function')\n    cb = files, files = null\n\n  if (!files)\n    files = []\n  else\n    files = Array.from(files)\n\n  const opt = hlo(opt_)\n\n  if (opt.sync && typeof cb === 'function')\n    throw new TypeError('callback not supported for sync tar functions')\n\n  if (!opt.file && typeof cb === 'function')\n    throw new TypeError('callback only supported with file option')\n\n  if (files.length)\n    filesFilter(opt, files)\n\n  return opt.file && opt.sync ? extractFileSync(opt)\n    : opt.file ? extractFile(opt, cb)\n    : opt.sync ? extractSync(opt)\n    : extract(opt)\n}\n\n// construct a filter that limits the file entries listed\n// include child entries if a dir is included\nconst filesFilter = (opt, files) => {\n  const map = new Map(files.map(f => [stripSlash(f), true]))\n  const filter = opt.filter\n\n  const mapHas = (file, r) => {\n    const root = r || path.parse(file).root || '.'\n    const ret = file === root ? false\n      : map.has(file) ? map.get(file)\n      : mapHas(path.dirname(file), root)\n\n    map.set(file, ret)\n    return ret\n  }\n\n  opt.filter = filter\n    ? (file, entry) => filter(file, entry) && mapHas(stripSlash(file))\n    : file => mapHas(stripSlash(file))\n}\n\nconst extractFileSync = opt => {\n  const u = new Unpack.Sync(opt)\n\n  const file = opt.file\n  const stat = fs.statSync(file)\n  // This trades a zero-byte read() syscall for a stat\n  // However, it will usually result in less memory allocation\n  const readSize = opt.maxReadSize || 16 * 1024 * 1024\n  const stream = new fsm.ReadStreamSync(file, {\n    readSize: readSize,\n    size: stat.size,\n  })\n  stream.pipe(u)\n}\n\nconst extractFile = (opt, cb) => {\n  const u = new Unpack(opt)\n  const readSize = opt.maxReadSize || 16 * 1024 * 1024\n\n  const file = opt.file\n  const p = new Promise((resolve, reject) => {\n    u.on('error', reject)\n    u.on('close', resolve)\n\n    // This trades a zero-byte read() syscall for a stat\n    // However, it will usually result in less memory allocation\n    fs.stat(file, (er, stat) => {\n      if (er)\n        reject(er)\n      else {\n        const stream = new fsm.ReadStream(file, {\n          readSize: readSize,\n          size: stat.size,\n        })\n        stream.on('error', reject)\n        stream.pipe(u)\n      }\n    })\n  })\n  return cb ? p.then(cb, cb) : p\n}\n\nconst extractSync = opt => new Unpack.Sync(opt)\n\nconst extract = opt => new Unpack(opt)\n","// Get the appropriate flag to use for creating files\n// We use fmap on Windows platforms for files less than\n// 512kb.  This is a fairly low limit, but avoids making\n// things slower in some cases.  Since most of what this\n// library is used for is extracting tarballs of many\n// relatively small files in npm packages and the like,\n// it can be a big boost on Windows platforms.\n// Only supported in Node v12.9.0 and above.\nconst platform = process.env.__FAKE_PLATFORM__ || process.platform\nconst isWindows = platform === 'win32'\nconst fs = global.__FAKE_TESTING_FS__ || require('fs')\n\n/* istanbul ignore next */\nconst { O_CREAT, O_TRUNC, O_WRONLY, UV_FS_O_FILEMAP = 0 } = fs.constants\n\nconst fMapEnabled = isWindows && !!UV_FS_O_FILEMAP\nconst fMapLimit = 512 * 1024\nconst fMapFlag = UV_FS_O_FILEMAP | O_TRUNC | O_CREAT | O_WRONLY\nmodule.exports = !fMapEnabled ? () => 'w'\n  : size => size < fMapLimit ? fMapFlag : 'w'\n","'use strict'\n// parse a 512-byte header block to a data object, or vice-versa\n// encode returns `true` if a pax extended header is needed, because\n// the data could not be faithfully encoded in a simple header.\n// (Also, check header.needPax to see if it needs a pax header.)\n\nconst types = require('./types.js')\nconst pathModule = require('path').posix\nconst large = require('./large-numbers.js')\n\nconst SLURP = Symbol('slurp')\nconst TYPE = Symbol('type')\n\nclass Header {\n  constructor (data, off, ex, gex) {\n    this.cksumValid = false\n    this.needPax = false\n    this.nullBlock = false\n\n    this.block = null\n    this.path = null\n    this.mode = null\n    this.uid = null\n    this.gid = null\n    this.size = null\n    this.mtime = null\n    this.cksum = null\n    this[TYPE] = '0'\n    this.linkpath = null\n    this.uname = null\n    this.gname = null\n    this.devmaj = 0\n    this.devmin = 0\n    this.atime = null\n    this.ctime = null\n\n    if (Buffer.isBuffer(data))\n      this.decode(data, off || 0, ex, gex)\n    else if (data)\n      this.set(data)\n  }\n\n  decode (buf, off, ex, gex) {\n    if (!off)\n      off = 0\n\n    if (!buf || !(buf.length >= off + 512))\n      throw new Error('need 512 bytes for header')\n\n    this.path = decString(buf, off, 100)\n    this.mode = decNumber(buf, off + 100, 8)\n    this.uid = decNumber(buf, off + 108, 8)\n    this.gid = decNumber(buf, off + 116, 8)\n    this.size = decNumber(buf, off + 124, 12)\n    this.mtime = decDate(buf, off + 136, 12)\n    this.cksum = decNumber(buf, off + 148, 12)\n\n    // if we have extended or global extended headers, apply them now\n    // See https://github.com/npm/node-tar/pull/187\n    this[SLURP](ex)\n    this[SLURP](gex, true)\n\n    // old tar versions marked dirs as a file with a trailing /\n    this[TYPE] = decString(buf, off + 156, 1)\n    if (this[TYPE] === '')\n      this[TYPE] = '0'\n    if (this[TYPE] === '0' && this.path.substr(-1) === '/')\n      this[TYPE] = '5'\n\n    // tar implementations sometimes incorrectly put the stat(dir).size\n    // as the size in the tarball, even though Directory entries are\n    // not able to have any body at all.  In the very rare chance that\n    // it actually DOES have a body, we weren't going to do anything with\n    // it anyway, and it'll just be a warning about an invalid header.\n    if (this[TYPE] === '5')\n      this.size = 0\n\n    this.linkpath = decString(buf, off + 157, 100)\n    if (buf.slice(off + 257, off + 265).toString() === 'ustar\\u000000') {\n      this.uname = decString(buf, off + 265, 32)\n      this.gname = decString(buf, off + 297, 32)\n      this.devmaj = decNumber(buf, off + 329, 8)\n      this.devmin = decNumber(buf, off + 337, 8)\n      if (buf[off + 475] !== 0) {\n        // definitely a prefix, definitely >130 chars.\n        const prefix = decString(buf, off + 345, 155)\n        this.path = prefix + '/' + this.path\n      } else {\n        const prefix = decString(buf, off + 345, 130)\n        if (prefix)\n          this.path = prefix + '/' + this.path\n        this.atime = decDate(buf, off + 476, 12)\n        this.ctime = decDate(buf, off + 488, 12)\n      }\n    }\n\n    let sum = 8 * 0x20\n    for (let i = off; i < off + 148; i++)\n      sum += buf[i]\n\n    for (let i = off + 156; i < off + 512; i++)\n      sum += buf[i]\n\n    this.cksumValid = sum === this.cksum\n    if (this.cksum === null && sum === 8 * 0x20)\n      this.nullBlock = true\n  }\n\n  [SLURP] (ex, global) {\n    for (const k in ex) {\n      // we slurp in everything except for the path attribute in\n      // a global extended header, because that's weird.\n      if (ex[k] !== null && ex[k] !== undefined &&\n          !(global && k === 'path'))\n        this[k] = ex[k]\n    }\n  }\n\n  encode (buf, off) {\n    if (!buf) {\n      buf = this.block = Buffer.alloc(512)\n      off = 0\n    }\n\n    if (!off)\n      off = 0\n\n    if (!(buf.length >= off + 512))\n      throw new Error('need 512 bytes for header')\n\n    const prefixSize = this.ctime || this.atime ? 130 : 155\n    const split = splitPrefix(this.path || '', prefixSize)\n    const path = split[0]\n    const prefix = split[1]\n    this.needPax = split[2]\n\n    this.needPax = encString(buf, off, 100, path) || this.needPax\n    this.needPax = encNumber(buf, off + 100, 8, this.mode) || this.needPax\n    this.needPax = encNumber(buf, off + 108, 8, this.uid) || this.needPax\n    this.needPax = encNumber(buf, off + 116, 8, this.gid) || this.needPax\n    this.needPax = encNumber(buf, off + 124, 12, this.size) || this.needPax\n    this.needPax = encDate(buf, off + 136, 12, this.mtime) || this.needPax\n    buf[off + 156] = this[TYPE].charCodeAt(0)\n    this.needPax = encString(buf, off + 157, 100, this.linkpath) || this.needPax\n    buf.write('ustar\\u000000', off + 257, 8)\n    this.needPax = encString(buf, off + 265, 32, this.uname) || this.needPax\n    this.needPax = encString(buf, off + 297, 32, this.gname) || this.needPax\n    this.needPax = encNumber(buf, off + 329, 8, this.devmaj) || this.needPax\n    this.needPax = encNumber(buf, off + 337, 8, this.devmin) || this.needPax\n    this.needPax = encString(buf, off + 345, prefixSize, prefix) || this.needPax\n    if (buf[off + 475] !== 0)\n      this.needPax = encString(buf, off + 345, 155, prefix) || this.needPax\n    else {\n      this.needPax = encString(buf, off + 345, 130, prefix) || this.needPax\n      this.needPax = encDate(buf, off + 476, 12, this.atime) || this.needPax\n      this.needPax = encDate(buf, off + 488, 12, this.ctime) || this.needPax\n    }\n\n    let sum = 8 * 0x20\n    for (let i = off; i < off + 148; i++)\n      sum += buf[i]\n\n    for (let i = off + 156; i < off + 512; i++)\n      sum += buf[i]\n\n    this.cksum = sum\n    encNumber(buf, off + 148, 8, this.cksum)\n    this.cksumValid = true\n\n    return this.needPax\n  }\n\n  set (data) {\n    for (const i in data) {\n      if (data[i] !== null && data[i] !== undefined)\n        this[i] = data[i]\n    }\n  }\n\n  get type () {\n    return types.name.get(this[TYPE]) || this[TYPE]\n  }\n\n  get typeKey () {\n    return this[TYPE]\n  }\n\n  set type (type) {\n    if (types.code.has(type))\n      this[TYPE] = types.code.get(type)\n    else\n      this[TYPE] = type\n  }\n}\n\nconst splitPrefix = (p, prefixSize) => {\n  const pathSize = 100\n  let pp = p\n  let prefix = ''\n  let ret\n  const root = pathModule.parse(p).root || '.'\n\n  if (Buffer.byteLength(pp) < pathSize)\n    ret = [pp, prefix, false]\n  else {\n    // first set prefix to the dir, and path to the base\n    prefix = pathModule.dirname(pp)\n    pp = pathModule.basename(pp)\n\n    do {\n      // both fit!\n      if (Buffer.byteLength(pp) <= pathSize &&\n          Buffer.byteLength(prefix) <= prefixSize)\n        ret = [pp, prefix, false]\n\n      // prefix fits in prefix, but path doesn't fit in path\n      else if (Buffer.byteLength(pp) > pathSize &&\n          Buffer.byteLength(prefix) <= prefixSize)\n        ret = [pp.substr(0, pathSize - 1), prefix, true]\n\n      else {\n        // make path take a bit from prefix\n        pp = pathModule.join(pathModule.basename(prefix), pp)\n        prefix = pathModule.dirname(prefix)\n      }\n    } while (prefix !== root && !ret)\n\n    // at this point, found no resolution, just truncate\n    if (!ret)\n      ret = [p.substr(0, pathSize - 1), '', true]\n  }\n  return ret\n}\n\nconst decString = (buf, off, size) =>\n  buf.slice(off, off + size).toString('utf8').replace(/\\0.*/, '')\n\nconst decDate = (buf, off, size) =>\n  numToDate(decNumber(buf, off, size))\n\nconst numToDate = num => num === null ? null : new Date(num * 1000)\n\nconst decNumber = (buf, off, size) =>\n  buf[off] & 0x80 ? large.parse(buf.slice(off, off + size))\n  : decSmallNumber(buf, off, size)\n\nconst nanNull = value => isNaN(value) ? null : value\n\nconst decSmallNumber = (buf, off, size) =>\n  nanNull(parseInt(\n    buf.slice(off, off + size)\n      .toString('utf8').replace(/\\0.*$/, '').trim(), 8))\n\n// the maximum encodable as a null-terminated octal, by field size\nconst MAXNUM = {\n  12: 0o77777777777,\n  8: 0o7777777,\n}\n\nconst encNumber = (buf, off, size, number) =>\n  number === null ? false :\n  number > MAXNUM[size] || number < 0\n    ? (large.encode(number, buf.slice(off, off + size)), true)\n    : (encSmallNumber(buf, off, size, number), false)\n\nconst encSmallNumber = (buf, off, size, number) =>\n  buf.write(octalString(number, size), off, size, 'ascii')\n\nconst octalString = (number, size) =>\n  padOctal(Math.floor(number).toString(8), size)\n\nconst padOctal = (string, size) =>\n  (string.length === size - 1 ? string\n  : new Array(size - string.length - 1).join('0') + string + ' ') + '\\0'\n\nconst encDate = (buf, off, size, date) =>\n  date === null ? false :\n  encNumber(buf, off, size, date.getTime() / 1000)\n\n// enough to fill the longest string we've got\nconst NULLS = new Array(156).join('\\0')\n// pad with nulls, return true if it's longer or non-ascii\nconst encString = (buf, off, size, string) =>\n  string === null ? false :\n  (buf.write(string + NULLS, off, size, 'utf8'),\n  string.length !== Buffer.byteLength(string) || string.length > size)\n\nmodule.exports = Header\n","'use strict'\n\n// turn tar(1) style args like `C` into the more verbose things like `cwd`\n\nconst argmap = new Map([\n  ['C', 'cwd'],\n  ['f', 'file'],\n  ['z', 'gzip'],\n  ['P', 'preservePaths'],\n  ['U', 'unlink'],\n  ['strip-components', 'strip'],\n  ['stripComponents', 'strip'],\n  ['keep-newer', 'newer'],\n  ['keepNewer', 'newer'],\n  ['keep-newer-files', 'newer'],\n  ['keepNewerFiles', 'newer'],\n  ['k', 'keep'],\n  ['keep-existing', 'keep'],\n  ['keepExisting', 'keep'],\n  ['m', 'noMtime'],\n  ['no-mtime', 'noMtime'],\n  ['p', 'preserveOwner'],\n  ['L', 'follow'],\n  ['h', 'follow'],\n])\n\nmodule.exports = opt => opt ? Object.keys(opt).map(k => [\n  argmap.has(k) ? argmap.get(k) : k, opt[k],\n]).reduce((set, kv) => (set[kv[0]] = kv[1], set), Object.create(null)) : {}\n","'use strict'\n// Tar can encode large and negative numbers using a leading byte of\n// 0xff for negative, and 0x80 for positive.\n\nconst encode = (num, buf) => {\n  if (!Number.isSafeInteger(num))\n    // The number is so large that javascript cannot represent it with integer\n    // precision.\n    throw Error('cannot encode number outside of javascript safe integer range')\n  else if (num < 0)\n    encodeNegative(num, buf)\n  else\n    encodePositive(num, buf)\n  return buf\n}\n\nconst encodePositive = (num, buf) => {\n  buf[0] = 0x80\n\n  for (var i = buf.length; i > 1; i--) {\n    buf[i - 1] = num & 0xff\n    num = Math.floor(num / 0x100)\n  }\n}\n\nconst encodeNegative = (num, buf) => {\n  buf[0] = 0xff\n  var flipped = false\n  num = num * -1\n  for (var i = buf.length; i > 1; i--) {\n    var byte = num & 0xff\n    num = Math.floor(num / 0x100)\n    if (flipped)\n      buf[i - 1] = onesComp(byte)\n    else if (byte === 0)\n      buf[i - 1] = 0\n    else {\n      flipped = true\n      buf[i - 1] = twosComp(byte)\n    }\n  }\n}\n\nconst parse = (buf) => {\n  const pre = buf[0]\n  const value = pre === 0x80 ? pos(buf.slice(1, buf.length))\n    : pre === 0xff ? twos(buf)\n    : null\n  if (value === null)\n    throw Error('invalid base256 encoding')\n\n  if (!Number.isSafeInteger(value))\n    // The number is so large that javascript cannot represent it with integer\n    // precision.\n    throw Error('parsed number outside of javascript safe integer range')\n\n  return value\n}\n\nconst twos = (buf) => {\n  var len = buf.length\n  var sum = 0\n  var flipped = false\n  for (var i = len - 1; i > -1; i--) {\n    var byte = buf[i]\n    var f\n    if (flipped)\n      f = onesComp(byte)\n    else if (byte === 0)\n      f = byte\n    else {\n      flipped = true\n      f = twosComp(byte)\n    }\n    if (f !== 0)\n      sum -= f * Math.pow(256, len - i - 1)\n  }\n  return sum\n}\n\nconst pos = (buf) => {\n  var len = buf.length\n  var sum = 0\n  for (var i = len - 1; i > -1; i--) {\n    var byte = buf[i]\n    if (byte !== 0)\n      sum += byte * Math.pow(256, len - i - 1)\n  }\n  return sum\n}\n\nconst onesComp = byte => (0xff ^ byte) & 0xff\n\nconst twosComp = byte => ((0xff ^ byte) + 1) & 0xff\n\nmodule.exports = {\n  encode,\n  parse,\n}\n","'use strict'\n\n// XXX: This shares a lot in common with extract.js\n// maybe some DRY opportunity here?\n\n// tar -t\nconst hlo = require('./high-level-opt.js')\nconst Parser = require('./parse.js')\nconst fs = require('fs')\nconst fsm = require('fs-minipass')\nconst path = require('path')\nconst stripSlash = require('./strip-trailing-slashes.js')\n\nmodule.exports = (opt_, files, cb) => {\n  if (typeof opt_ === 'function')\n    cb = opt_, files = null, opt_ = {}\n  else if (Array.isArray(opt_))\n    files = opt_, opt_ = {}\n\n  if (typeof files === 'function')\n    cb = files, files = null\n\n  if (!files)\n    files = []\n  else\n    files = Array.from(files)\n\n  const opt = hlo(opt_)\n\n  if (opt.sync && typeof cb === 'function')\n    throw new TypeError('callback not supported for sync tar functions')\n\n  if (!opt.file && typeof cb === 'function')\n    throw new TypeError('callback only supported with file option')\n\n  if (files.length)\n    filesFilter(opt, files)\n\n  if (!opt.noResume)\n    onentryFunction(opt)\n\n  return opt.file && opt.sync ? listFileSync(opt)\n    : opt.file ? listFile(opt, cb)\n    : list(opt)\n}\n\nconst onentryFunction = opt => {\n  const onentry = opt.onentry\n  opt.onentry = onentry ? e => {\n    onentry(e)\n    e.resume()\n  } : e => e.resume()\n}\n\n// construct a filter that limits the file entries listed\n// include child entries if a dir is included\nconst filesFilter = (opt, files) => {\n  const map = new Map(files.map(f => [stripSlash(f), true]))\n  const filter = opt.filter\n\n  const mapHas = (file, r) => {\n    const root = r || path.parse(file).root || '.'\n    const ret = file === root ? false\n      : map.has(file) ? map.get(file)\n      : mapHas(path.dirname(file), root)\n\n    map.set(file, ret)\n    return ret\n  }\n\n  opt.filter = filter\n    ? (file, entry) => filter(file, entry) && mapHas(stripSlash(file))\n    : file => mapHas(stripSlash(file))\n}\n\nconst listFileSync = opt => {\n  const p = list(opt)\n  const file = opt.file\n  let threw = true\n  let fd\n  try {\n    const stat = fs.statSync(file)\n    const readSize = opt.maxReadSize || 16 * 1024 * 1024\n    if (stat.size < readSize)\n      p.end(fs.readFileSync(file))\n    else {\n      let pos = 0\n      const buf = Buffer.allocUnsafe(readSize)\n      fd = fs.openSync(file, 'r')\n      while (pos < stat.size) {\n        const bytesRead = fs.readSync(fd, buf, 0, readSize, pos)\n        pos += bytesRead\n        p.write(buf.slice(0, bytesRead))\n      }\n      p.end()\n    }\n    threw = false\n  } finally {\n    if (threw && fd) {\n      try {\n        fs.closeSync(fd)\n      } catch (er) {}\n    }\n  }\n}\n\nconst listFile = (opt, cb) => {\n  const parse = new Parser(opt)\n  const readSize = opt.maxReadSize || 16 * 1024 * 1024\n\n  const file = opt.file\n  const p = new Promise((resolve, reject) => {\n    parse.on('error', reject)\n    parse.on('end', resolve)\n\n    fs.stat(file, (er, stat) => {\n      if (er)\n        reject(er)\n      else {\n        const stream = new fsm.ReadStream(file, {\n          readSize: readSize,\n          size: stat.size,\n        })\n        stream.on('error', reject)\n        stream.pipe(parse)\n      }\n    })\n  })\n  return cb ? p.then(cb, cb) : p\n}\n\nconst list = opt => new Parser(opt)\n","'use strict'\n// wrapper around mkdirp for tar's needs.\n\n// TODO: This should probably be a class, not functionally\n// passing around state in a gazillion args.\n\nconst mkdirp = require('mkdirp')\nconst fs = require('fs')\nconst path = require('path')\nconst chownr = require('chownr')\nconst normPath = require('./normalize-windows-path.js')\n\nclass SymlinkError extends Error {\n  constructor (symlink, path) {\n    super('Cannot extract through symbolic link')\n    this.path = path\n    this.symlink = symlink\n  }\n\n  get name () {\n    return 'SylinkError'\n  }\n}\n\nclass CwdError extends Error {\n  constructor (path, code) {\n    super(code + ': Cannot cd into \\'' + path + '\\'')\n    this.path = path\n    this.code = code\n  }\n\n  get name () {\n    return 'CwdError'\n  }\n}\n\nconst cGet = (cache, key) => cache.get(normPath(key))\nconst cSet = (cache, key, val) => cache.set(normPath(key), val)\n\nconst checkCwd = (dir, cb) => {\n  fs.stat(dir, (er, st) => {\n    if (er || !st.isDirectory())\n      er = new CwdError(dir, er && er.code || 'ENOTDIR')\n    cb(er)\n  })\n}\n\nmodule.exports = (dir, opt, cb) => {\n  dir = normPath(dir)\n\n  // if there's any overlap between mask and mode,\n  // then we'll need an explicit chmod\n  const umask = opt.umask\n  const mode = opt.mode | 0o0700\n  const needChmod = (mode & umask) !== 0\n\n  const uid = opt.uid\n  const gid = opt.gid\n  const doChown = typeof uid === 'number' &&\n    typeof gid === 'number' &&\n    (uid !== opt.processUid || gid !== opt.processGid)\n\n  const preserve = opt.preserve\n  const unlink = opt.unlink\n  const cache = opt.cache\n  const cwd = normPath(opt.cwd)\n\n  const done = (er, created) => {\n    if (er)\n      cb(er)\n    else {\n      cSet(cache, dir, true)\n      if (created && doChown)\n        chownr(created, uid, gid, er => done(er))\n      else if (needChmod)\n        fs.chmod(dir, mode, cb)\n      else\n        cb()\n    }\n  }\n\n  if (cache && cGet(cache, dir) === true)\n    return done()\n\n  if (dir === cwd)\n    return checkCwd(dir, done)\n\n  if (preserve)\n    return mkdirp(dir, {mode}).then(made => done(null, made), done)\n\n  const sub = normPath(path.relative(cwd, dir))\n  const parts = sub.split('/')\n  mkdir_(cwd, parts, mode, cache, unlink, cwd, null, done)\n}\n\nconst mkdir_ = (base, parts, mode, cache, unlink, cwd, created, cb) => {\n  if (!parts.length)\n    return cb(null, created)\n  const p = parts.shift()\n  const part = normPath(path.resolve(base + '/' + p))\n  if (cGet(cache, part))\n    return mkdir_(part, parts, mode, cache, unlink, cwd, created, cb)\n  fs.mkdir(part, mode, onmkdir(part, parts, mode, cache, unlink, cwd, created, cb))\n}\n\nconst onmkdir = (part, parts, mode, cache, unlink, cwd, created, cb) => er => {\n  if (er) {\n    fs.lstat(part, (statEr, st) => {\n      if (statEr) {\n        statEr.path = statEr.path && normPath(statEr.path)\n        cb(statEr)\n      } else if (st.isDirectory())\n        mkdir_(part, parts, mode, cache, unlink, cwd, created, cb)\n      else if (unlink) {\n        fs.unlink(part, er => {\n          if (er)\n            return cb(er)\n          fs.mkdir(part, mode, onmkdir(part, parts, mode, cache, unlink, cwd, created, cb))\n        })\n      } else if (st.isSymbolicLink())\n        return cb(new SymlinkError(part, part + '/' + parts.join('/')))\n      else\n        cb(er)\n    })\n  } else {\n    created = created || part\n    mkdir_(part, parts, mode, cache, unlink, cwd, created, cb)\n  }\n}\n\nconst checkCwdSync = dir => {\n  let ok = false\n  let code = 'ENOTDIR'\n  try {\n    ok = fs.statSync(dir).isDirectory()\n  } catch (er) {\n    code = er.code\n  } finally {\n    if (!ok)\n      throw new CwdError(dir, code)\n  }\n}\n\nmodule.exports.sync = (dir, opt) => {\n  dir = normPath(dir)\n  // if there's any overlap between mask and mode,\n  // then we'll need an explicit chmod\n  const umask = opt.umask\n  const mode = opt.mode | 0o0700\n  const needChmod = (mode & umask) !== 0\n\n  const uid = opt.uid\n  const gid = opt.gid\n  const doChown = typeof uid === 'number' &&\n    typeof gid === 'number' &&\n    (uid !== opt.processUid || gid !== opt.processGid)\n\n  const preserve = opt.preserve\n  const unlink = opt.unlink\n  const cache = opt.cache\n  const cwd = normPath(opt.cwd)\n\n  const done = (created) => {\n    cSet(cache, dir, true)\n    if (created && doChown)\n      chownr.sync(created, uid, gid)\n    if (needChmod)\n      fs.chmodSync(dir, mode)\n  }\n\n  if (cache && cGet(cache, dir) === true)\n    return done()\n\n  if (dir === cwd) {\n    checkCwdSync(cwd)\n    return done()\n  }\n\n  if (preserve)\n    return done(mkdirp.sync(dir, mode))\n\n  const sub = normPath(path.relative(cwd, dir))\n  const parts = sub.split('/')\n  let created = null\n  for (let p = parts.shift(), part = cwd;\n    p && (part += '/' + p);\n    p = parts.shift()) {\n    part = normPath(path.resolve(part))\n    if (cGet(cache, part))\n      continue\n\n    try {\n      fs.mkdirSync(part, mode)\n      created = created || part\n      cSet(cache, part, true)\n    } catch (er) {\n      const st = fs.lstatSync(part)\n      if (st.isDirectory()) {\n        cSet(cache, part, true)\n        continue\n      } else if (unlink) {\n        fs.unlinkSync(part)\n        fs.mkdirSync(part, mode)\n        created = created || part\n        cSet(cache, part, true)\n        continue\n      } else if (st.isSymbolicLink())\n        return new SymlinkError(part, part + '/' + parts.join('/'))\n    }\n  }\n\n  return done(created)\n}\n","'use strict'\nmodule.exports = (mode, isDir, portable) => {\n  mode &= 0o7777\n\n  // in portable mode, use the minimum reasonable umask\n  // if this system creates files with 0o664 by default\n  // (as some linux distros do), then we'll write the\n  // archive with 0o644 instead.  Also, don't ever create\n  // a file that is not readable/writable by the owner.\n  if (portable)\n    mode = (mode | 0o600) & ~0o22\n\n  // if dirs are readable, then they should be listable\n  if (isDir) {\n    if (mode & 0o400)\n      mode |= 0o100\n    if (mode & 0o40)\n      mode |= 0o10\n    if (mode & 0o4)\n      mode |= 0o1\n  }\n  return mode\n}\n","// warning: extremely hot code path.\n// This has been meticulously optimized for use\n// within npm install on large package trees.\n// Do not edit without careful benchmarking.\nconst normalizeCache = Object.create(null)\nconst {hasOwnProperty} = Object.prototype\nmodule.exports = s => {\n  if (!hasOwnProperty.call(normalizeCache, s))\n    normalizeCache[s] = s.normalize('NFKD')\n  return normalizeCache[s]\n}\n","// on windows, either \\ or / are valid directory separators.\n// on unix, \\ is a valid character in filenames.\n// so, on windows, and only on windows, we replace all \\ chars with /,\n// so that we can use / as our one and only directory separator char.\n\nconst platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platform\nmodule.exports = platform !== 'win32' ? p => p\n  : p => p && p.replace(/\\\\/g, '/')\n","'use strict'\n\n// A readable tar stream creator\n// Technically, this is a transform stream that you write paths into,\n// and tar format comes out of.\n// The `add()` method is like `write()` but returns this,\n// and end() return `this` as well, so you can\n// do `new Pack(opt).add('files').add('dir').end().pipe(output)\n// You could also do something like:\n// streamOfPaths().pipe(new Pack()).pipe(new fs.WriteStream('out.tar'))\n\nclass PackJob {\n  constructor (path, absolute) {\n    this.path = path || './'\n    this.absolute = absolute\n    this.entry = null\n    this.stat = null\n    this.readdir = null\n    this.pending = false\n    this.ignore = false\n    this.piped = false\n  }\n}\n\nconst MiniPass = require('minipass')\nconst zlib = require('minizlib')\nconst ReadEntry = require('./read-entry.js')\nconst WriteEntry = require('./write-entry.js')\nconst WriteEntrySync = WriteEntry.Sync\nconst WriteEntryTar = WriteEntry.Tar\nconst Yallist = require('yallist')\nconst EOF = Buffer.alloc(1024)\nconst ONSTAT = Symbol('onStat')\nconst ENDED = Symbol('ended')\nconst QUEUE = Symbol('queue')\nconst CURRENT = Symbol('current')\nconst PROCESS = Symbol('process')\nconst PROCESSING = Symbol('processing')\nconst PROCESSJOB = Symbol('processJob')\nconst JOBS = Symbol('jobs')\nconst JOBDONE = Symbol('jobDone')\nconst ADDFSENTRY = Symbol('addFSEntry')\nconst ADDTARENTRY = Symbol('addTarEntry')\nconst STAT = Symbol('stat')\nconst READDIR = Symbol('readdir')\nconst ONREADDIR = Symbol('onreaddir')\nconst PIPE = Symbol('pipe')\nconst ENTRY = Symbol('entry')\nconst ENTRYOPT = Symbol('entryOpt')\nconst WRITEENTRYCLASS = Symbol('writeEntryClass')\nconst WRITE = Symbol('write')\nconst ONDRAIN = Symbol('ondrain')\n\nconst fs = require('fs')\nconst path = require('path')\nconst warner = require('./warn-mixin.js')\nconst normPath = require('./normalize-windows-path.js')\n\nconst Pack = warner(class Pack extends MiniPass {\n  constructor (opt) {\n    super(opt)\n    opt = opt || Object.create(null)\n    this.opt = opt\n    this.file = opt.file || ''\n    this.cwd = opt.cwd || process.cwd()\n    this.maxReadSize = opt.maxReadSize\n    this.preservePaths = !!opt.preservePaths\n    this.strict = !!opt.strict\n    this.noPax = !!opt.noPax\n    this.prefix = normPath(opt.prefix || '')\n    this.linkCache = opt.linkCache || new Map()\n    this.statCache = opt.statCache || new Map()\n    this.readdirCache = opt.readdirCache || new Map()\n\n    this[WRITEENTRYCLASS] = WriteEntry\n    if (typeof opt.onwarn === 'function')\n      this.on('warn', opt.onwarn)\n\n    this.portable = !!opt.portable\n    this.zip = null\n    if (opt.gzip) {\n      if (typeof opt.gzip !== 'object')\n        opt.gzip = {}\n      if (this.portable)\n        opt.gzip.portable = true\n      this.zip = new zlib.Gzip(opt.gzip)\n      this.zip.on('data', chunk => super.write(chunk))\n      this.zip.on('end', _ => super.end())\n      this.zip.on('drain', _ => this[ONDRAIN]())\n      this.on('resume', _ => this.zip.resume())\n    } else\n      this.on('drain', this[ONDRAIN])\n\n    this.noDirRecurse = !!opt.noDirRecurse\n    this.follow = !!opt.follow\n    this.noMtime = !!opt.noMtime\n    this.mtime = opt.mtime || null\n\n    this.filter = typeof opt.filter === 'function' ? opt.filter : _ => true\n\n    this[QUEUE] = new Yallist()\n    this[JOBS] = 0\n    this.jobs = +opt.jobs || 4\n    this[PROCESSING] = false\n    this[ENDED] = false\n  }\n\n  [WRITE] (chunk) {\n    return super.write(chunk)\n  }\n\n  add (path) {\n    this.write(path)\n    return this\n  }\n\n  end (path) {\n    if (path)\n      this.write(path)\n    this[ENDED] = true\n    this[PROCESS]()\n    return this\n  }\n\n  write (path) {\n    if (this[ENDED])\n      throw new Error('write after end')\n\n    if (path instanceof ReadEntry)\n      this[ADDTARENTRY](path)\n    else\n      this[ADDFSENTRY](path)\n    return this.flowing\n  }\n\n  [ADDTARENTRY] (p) {\n    const absolute = normPath(path.resolve(this.cwd, p.path))\n    // in this case, we don't have to wait for the stat\n    if (!this.filter(p.path, p))\n      p.resume()\n    else {\n      const job = new PackJob(p.path, absolute, false)\n      job.entry = new WriteEntryTar(p, this[ENTRYOPT](job))\n      job.entry.on('end', _ => this[JOBDONE](job))\n      this[JOBS] += 1\n      this[QUEUE].push(job)\n    }\n\n    this[PROCESS]()\n  }\n\n  [ADDFSENTRY] (p) {\n    const absolute = normPath(path.resolve(this.cwd, p))\n    this[QUEUE].push(new PackJob(p, absolute))\n    this[PROCESS]()\n  }\n\n  [STAT] (job) {\n    job.pending = true\n    this[JOBS] += 1\n    const stat = this.follow ? 'stat' : 'lstat'\n    fs[stat](job.absolute, (er, stat) => {\n      job.pending = false\n      this[JOBS] -= 1\n      if (er)\n        this.emit('error', er)\n      else\n        this[ONSTAT](job, stat)\n    })\n  }\n\n  [ONSTAT] (job, stat) {\n    this.statCache.set(job.absolute, stat)\n    job.stat = stat\n\n    // now we have the stat, we can filter it.\n    if (!this.filter(job.path, stat))\n      job.ignore = true\n\n    this[PROCESS]()\n  }\n\n  [READDIR] (job) {\n    job.pending = true\n    this[JOBS] += 1\n    fs.readdir(job.absolute, (er, entries) => {\n      job.pending = false\n      this[JOBS] -= 1\n      if (er)\n        return this.emit('error', er)\n      this[ONREADDIR](job, entries)\n    })\n  }\n\n  [ONREADDIR] (job, entries) {\n    this.readdirCache.set(job.absolute, entries)\n    job.readdir = entries\n    this[PROCESS]()\n  }\n\n  [PROCESS] () {\n    if (this[PROCESSING])\n      return\n\n    this[PROCESSING] = true\n    for (let w = this[QUEUE].head;\n      w !== null && this[JOBS] < this.jobs;\n      w = w.next) {\n      this[PROCESSJOB](w.value)\n      if (w.value.ignore) {\n        const p = w.next\n        this[QUEUE].removeNode(w)\n        w.next = p\n      }\n    }\n\n    this[PROCESSING] = false\n\n    if (this[ENDED] && !this[QUEUE].length && this[JOBS] === 0) {\n      if (this.zip)\n        this.zip.end(EOF)\n      else {\n        super.write(EOF)\n        super.end()\n      }\n    }\n  }\n\n  get [CURRENT] () {\n    return this[QUEUE] && this[QUEUE].head && this[QUEUE].head.value\n  }\n\n  [JOBDONE] (job) {\n    this[QUEUE].shift()\n    this[JOBS] -= 1\n    this[PROCESS]()\n  }\n\n  [PROCESSJOB] (job) {\n    if (job.pending)\n      return\n\n    if (job.entry) {\n      if (job === this[CURRENT] && !job.piped)\n        this[PIPE](job)\n      return\n    }\n\n    if (!job.stat) {\n      if (this.statCache.has(job.absolute))\n        this[ONSTAT](job, this.statCache.get(job.absolute))\n      else\n        this[STAT](job)\n    }\n    if (!job.stat)\n      return\n\n    // filtered out!\n    if (job.ignore)\n      return\n\n    if (!this.noDirRecurse && job.stat.isDirectory() && !job.readdir) {\n      if (this.readdirCache.has(job.absolute))\n        this[ONREADDIR](job, this.readdirCache.get(job.absolute))\n      else\n        this[READDIR](job)\n      if (!job.readdir)\n        return\n    }\n\n    // we know it doesn't have an entry, because that got checked above\n    job.entry = this[ENTRY](job)\n    if (!job.entry) {\n      job.ignore = true\n      return\n    }\n\n    if (job === this[CURRENT] && !job.piped)\n      this[PIPE](job)\n  }\n\n  [ENTRYOPT] (job) {\n    return {\n      onwarn: (code, msg, data) => this.warn(code, msg, data),\n      noPax: this.noPax,\n      cwd: this.cwd,\n      absolute: job.absolute,\n      preservePaths: this.preservePaths,\n      maxReadSize: this.maxReadSize,\n      strict: this.strict,\n      portable: this.portable,\n      linkCache: this.linkCache,\n      statCache: this.statCache,\n      noMtime: this.noMtime,\n      mtime: this.mtime,\n      prefix: this.prefix,\n    }\n  }\n\n  [ENTRY] (job) {\n    this[JOBS] += 1\n    try {\n      return new this[WRITEENTRYCLASS](job.path, this[ENTRYOPT](job))\n        .on('end', () => this[JOBDONE](job))\n        .on('error', er => this.emit('error', er))\n    } catch (er) {\n      this.emit('error', er)\n    }\n  }\n\n  [ONDRAIN] () {\n    if (this[CURRENT] && this[CURRENT].entry)\n      this[CURRENT].entry.resume()\n  }\n\n  // like .pipe() but using super, because our write() is special\n  [PIPE] (job) {\n    job.piped = true\n\n    if (job.readdir) {\n      job.readdir.forEach(entry => {\n        const p = job.path\n        const base = p === './' ? '' : p.replace(/\\/*$/, '/')\n        this[ADDFSENTRY](base + entry)\n      })\n    }\n\n    const source = job.entry\n    const zip = this.zip\n\n    if (zip) {\n      source.on('data', chunk => {\n        if (!zip.write(chunk))\n          source.pause()\n      })\n    } else {\n      source.on('data', chunk => {\n        if (!super.write(chunk))\n          source.pause()\n      })\n    }\n  }\n\n  pause () {\n    if (this.zip)\n      this.zip.pause()\n    return super.pause()\n  }\n})\n\nclass PackSync extends Pack {\n  constructor (opt) {\n    super(opt)\n    this[WRITEENTRYCLASS] = WriteEntrySync\n  }\n\n  // pause/resume are no-ops in sync streams.\n  pause () {}\n  resume () {}\n\n  [STAT] (job) {\n    const stat = this.follow ? 'statSync' : 'lstatSync'\n    this[ONSTAT](job, fs[stat](job.absolute))\n  }\n\n  [READDIR] (job, stat) {\n    this[ONREADDIR](job, fs.readdirSync(job.absolute))\n  }\n\n  // gotta get it all in this tick\n  [PIPE] (job) {\n    const source = job.entry\n    const zip = this.zip\n\n    if (job.readdir) {\n      job.readdir.forEach(entry => {\n        const p = job.path\n        const base = p === './' ? '' : p.replace(/\\/*$/, '/')\n        this[ADDFSENTRY](base + entry)\n      })\n    }\n\n    if (zip) {\n      source.on('data', chunk => {\n        zip.write(chunk)\n      })\n    } else {\n      source.on('data', chunk => {\n        super[WRITE](chunk)\n      })\n    }\n  }\n}\n\nPack.Sync = PackSync\n\nmodule.exports = Pack\n","'use strict'\n\n// this[BUFFER] is the remainder of a chunk if we're waiting for\n// the full 512 bytes of a header to come in.  We will Buffer.concat()\n// it to the next write(), which is a mem copy, but a small one.\n//\n// this[QUEUE] is a Yallist of entries that haven't been emitted\n// yet this can only get filled up if the user keeps write()ing after\n// a write() returns false, or does a write() with more than one entry\n//\n// We don't buffer chunks, we always parse them and either create an\n// entry, or push it into the active entry.  The ReadEntry class knows\n// to throw data away if .ignore=true\n//\n// Shift entry off the buffer when it emits 'end', and emit 'entry' for\n// the next one in the list.\n//\n// At any time, we're pushing body chunks into the entry at WRITEENTRY,\n// and waiting for 'end' on the entry at READENTRY\n//\n// ignored entries get .resume() called on them straight away\n\nconst warner = require('./warn-mixin.js')\nconst Header = require('./header.js')\nconst EE = require('events')\nconst Yallist = require('yallist')\nconst maxMetaEntrySize = 1024 * 1024\nconst Entry = require('./read-entry.js')\nconst Pax = require('./pax.js')\nconst zlib = require('minizlib')\n\nconst gzipHeader = Buffer.from([0x1f, 0x8b])\nconst STATE = Symbol('state')\nconst WRITEENTRY = Symbol('writeEntry')\nconst READENTRY = Symbol('readEntry')\nconst NEXTENTRY = Symbol('nextEntry')\nconst PROCESSENTRY = Symbol('processEntry')\nconst EX = Symbol('extendedHeader')\nconst GEX = Symbol('globalExtendedHeader')\nconst META = Symbol('meta')\nconst EMITMETA = Symbol('emitMeta')\nconst BUFFER = Symbol('buffer')\nconst QUEUE = Symbol('queue')\nconst ENDED = Symbol('ended')\nconst EMITTEDEND = Symbol('emittedEnd')\nconst EMIT = Symbol('emit')\nconst UNZIP = Symbol('unzip')\nconst CONSUMECHUNK = Symbol('consumeChunk')\nconst CONSUMECHUNKSUB = Symbol('consumeChunkSub')\nconst CONSUMEBODY = Symbol('consumeBody')\nconst CONSUMEMETA = Symbol('consumeMeta')\nconst CONSUMEHEADER = Symbol('consumeHeader')\nconst CONSUMING = Symbol('consuming')\nconst BUFFERCONCAT = Symbol('bufferConcat')\nconst MAYBEEND = Symbol('maybeEnd')\nconst WRITING = Symbol('writing')\nconst ABORTED = Symbol('aborted')\nconst DONE = Symbol('onDone')\nconst SAW_VALID_ENTRY = Symbol('sawValidEntry')\nconst SAW_NULL_BLOCK = Symbol('sawNullBlock')\nconst SAW_EOF = Symbol('sawEOF')\n\nconst noop = _ => true\n\nmodule.exports = warner(class Parser extends EE {\n  constructor (opt) {\n    opt = opt || {}\n    super(opt)\n\n    this.file = opt.file || ''\n\n    // set to boolean false when an entry starts.  1024 bytes of \\0\n    // is technically a valid tarball, albeit a boring one.\n    this[SAW_VALID_ENTRY] = null\n\n    // these BADARCHIVE errors can't be detected early. listen on DONE.\n    this.on(DONE, _ => {\n      if (this[STATE] === 'begin' || this[SAW_VALID_ENTRY] === false) {\n        // either less than 1 block of data, or all entries were invalid.\n        // Either way, probably not even a tarball.\n        this.warn('TAR_BAD_ARCHIVE', 'Unrecognized archive format')\n      }\n    })\n\n    if (opt.ondone)\n      this.on(DONE, opt.ondone)\n    else {\n      this.on(DONE, _ => {\n        this.emit('prefinish')\n        this.emit('finish')\n        this.emit('end')\n        this.emit('close')\n      })\n    }\n\n    this.strict = !!opt.strict\n    this.maxMetaEntrySize = opt.maxMetaEntrySize || maxMetaEntrySize\n    this.filter = typeof opt.filter === 'function' ? opt.filter : noop\n\n    // have to set this so that streams are ok piping into it\n    this.writable = true\n    this.readable = false\n\n    this[QUEUE] = new Yallist()\n    this[BUFFER] = null\n    this[READENTRY] = null\n    this[WRITEENTRY] = null\n    this[STATE] = 'begin'\n    this[META] = ''\n    this[EX] = null\n    this[GEX] = null\n    this[ENDED] = false\n    this[UNZIP] = null\n    this[ABORTED] = false\n    this[SAW_NULL_BLOCK] = false\n    this[SAW_EOF] = false\n    if (typeof opt.onwarn === 'function')\n      this.on('warn', opt.onwarn)\n    if (typeof opt.onentry === 'function')\n      this.on('entry', opt.onentry)\n  }\n\n  [CONSUMEHEADER] (chunk, position) {\n    if (this[SAW_VALID_ENTRY] === null)\n      this[SAW_VALID_ENTRY] = false\n    let header\n    try {\n      header = new Header(chunk, position, this[EX], this[GEX])\n    } catch (er) {\n      return this.warn('TAR_ENTRY_INVALID', er)\n    }\n\n    if (header.nullBlock) {\n      if (this[SAW_NULL_BLOCK]) {\n        this[SAW_EOF] = true\n        // ending an archive with no entries.  pointless, but legal.\n        if (this[STATE] === 'begin')\n          this[STATE] = 'header'\n        this[EMIT]('eof')\n      } else {\n        this[SAW_NULL_BLOCK] = true\n        this[EMIT]('nullBlock')\n      }\n    } else {\n      this[SAW_NULL_BLOCK] = false\n      if (!header.cksumValid)\n        this.warn('TAR_ENTRY_INVALID', 'checksum failure', {header})\n      else if (!header.path)\n        this.warn('TAR_ENTRY_INVALID', 'path is required', {header})\n      else {\n        const type = header.type\n        if (/^(Symbolic)?Link$/.test(type) && !header.linkpath)\n          this.warn('TAR_ENTRY_INVALID', 'linkpath required', {header})\n        else if (!/^(Symbolic)?Link$/.test(type) && header.linkpath)\n          this.warn('TAR_ENTRY_INVALID', 'linkpath forbidden', {header})\n        else {\n          const entry = this[WRITEENTRY] = new Entry(header, this[EX], this[GEX])\n\n          // we do this for meta & ignored entries as well, because they\n          // are still valid tar, or else we wouldn't know to ignore them\n          if (!this[SAW_VALID_ENTRY]) {\n            if (entry.remain) {\n              // this might be the one!\n              const onend = () => {\n                if (!entry.invalid)\n                  this[SAW_VALID_ENTRY] = true\n              }\n              entry.on('end', onend)\n            } else\n              this[SAW_VALID_ENTRY] = true\n          }\n\n          if (entry.meta) {\n            if (entry.size > this.maxMetaEntrySize) {\n              entry.ignore = true\n              this[EMIT]('ignoredEntry', entry)\n              this[STATE] = 'ignore'\n              entry.resume()\n            } else if (entry.size > 0) {\n              this[META] = ''\n              entry.on('data', c => this[META] += c)\n              this[STATE] = 'meta'\n            }\n          } else {\n            this[EX] = null\n            entry.ignore = entry.ignore || !this.filter(entry.path, entry)\n\n            if (entry.ignore) {\n              // probably valid, just not something we care about\n              this[EMIT]('ignoredEntry', entry)\n              this[STATE] = entry.remain ? 'ignore' : 'header'\n              entry.resume()\n            } else {\n              if (entry.remain)\n                this[STATE] = 'body'\n              else {\n                this[STATE] = 'header'\n                entry.end()\n              }\n\n              if (!this[READENTRY]) {\n                this[QUEUE].push(entry)\n                this[NEXTENTRY]()\n              } else\n                this[QUEUE].push(entry)\n            }\n          }\n        }\n      }\n    }\n  }\n\n  [PROCESSENTRY] (entry) {\n    let go = true\n\n    if (!entry) {\n      this[READENTRY] = null\n      go = false\n    } else if (Array.isArray(entry))\n      this.emit.apply(this, entry)\n    else {\n      this[READENTRY] = entry\n      this.emit('entry', entry)\n      if (!entry.emittedEnd) {\n        entry.on('end', _ => this[NEXTENTRY]())\n        go = false\n      }\n    }\n\n    return go\n  }\n\n  [NEXTENTRY] () {\n    do {} while (this[PROCESSENTRY](this[QUEUE].shift()))\n\n    if (!this[QUEUE].length) {\n      // At this point, there's nothing in the queue, but we may have an\n      // entry which is being consumed (readEntry).\n      // If we don't, then we definitely can handle more data.\n      // If we do, and either it's flowing, or it has never had any data\n      // written to it, then it needs more.\n      // The only other possibility is that it has returned false from a\n      // write() call, so we wait for the next drain to continue.\n      const re = this[READENTRY]\n      const drainNow = !re || re.flowing || re.size === re.remain\n      if (drainNow) {\n        if (!this[WRITING])\n          this.emit('drain')\n      } else\n        re.once('drain', _ => this.emit('drain'))\n    }\n  }\n\n  [CONSUMEBODY] (chunk, position) {\n    // write up to but no  more than writeEntry.blockRemain\n    const entry = this[WRITEENTRY]\n    const br = entry.blockRemain\n    const c = (br >= chunk.length && position === 0) ? chunk\n      : chunk.slice(position, position + br)\n\n    entry.write(c)\n\n    if (!entry.blockRemain) {\n      this[STATE] = 'header'\n      this[WRITEENTRY] = null\n      entry.end()\n    }\n\n    return c.length\n  }\n\n  [CONSUMEMETA] (chunk, position) {\n    const entry = this[WRITEENTRY]\n    const ret = this[CONSUMEBODY](chunk, position)\n\n    // if we finished, then the entry is reset\n    if (!this[WRITEENTRY])\n      this[EMITMETA](entry)\n\n    return ret\n  }\n\n  [EMIT] (ev, data, extra) {\n    if (!this[QUEUE].length && !this[READENTRY])\n      this.emit(ev, data, extra)\n    else\n      this[QUEUE].push([ev, data, extra])\n  }\n\n  [EMITMETA] (entry) {\n    this[EMIT]('meta', this[META])\n    switch (entry.type) {\n      case 'ExtendedHeader':\n      case 'OldExtendedHeader':\n        this[EX] = Pax.parse(this[META], this[EX], false)\n        break\n\n      case 'GlobalExtendedHeader':\n        this[GEX] = Pax.parse(this[META], this[GEX], true)\n        break\n\n      case 'NextFileHasLongPath':\n      case 'OldGnuLongPath':\n        this[EX] = this[EX] || Object.create(null)\n        this[EX].path = this[META].replace(/\\0.*/, '')\n        break\n\n      case 'NextFileHasLongLinkpath':\n        this[EX] = this[EX] || Object.create(null)\n        this[EX].linkpath = this[META].replace(/\\0.*/, '')\n        break\n\n      /* istanbul ignore next */\n      default: throw new Error('unknown meta: ' + entry.type)\n    }\n  }\n\n  abort (error) {\n    this[ABORTED] = true\n    this.emit('abort', error)\n    // always throws, even in non-strict mode\n    this.warn('TAR_ABORT', error, { recoverable: false })\n  }\n\n  write (chunk) {\n    if (this[ABORTED])\n      return\n\n    // first write, might be gzipped\n    if (this[UNZIP] === null && chunk) {\n      if (this[BUFFER]) {\n        chunk = Buffer.concat([this[BUFFER], chunk])\n        this[BUFFER] = null\n      }\n      if (chunk.length < gzipHeader.length) {\n        this[BUFFER] = chunk\n        return true\n      }\n      for (let i = 0; this[UNZIP] === null && i < gzipHeader.length; i++) {\n        if (chunk[i] !== gzipHeader[i])\n          this[UNZIP] = false\n      }\n      if (this[UNZIP] === null) {\n        const ended = this[ENDED]\n        this[ENDED] = false\n        this[UNZIP] = new zlib.Unzip()\n        this[UNZIP].on('data', chunk => this[CONSUMECHUNK](chunk))\n        this[UNZIP].on('error', er => this.abort(er))\n        this[UNZIP].on('end', _ => {\n          this[ENDED] = true\n          this[CONSUMECHUNK]()\n        })\n        this[WRITING] = true\n        const ret = this[UNZIP][ended ? 'end' : 'write'](chunk)\n        this[WRITING] = false\n        return ret\n      }\n    }\n\n    this[WRITING] = true\n    if (this[UNZIP])\n      this[UNZIP].write(chunk)\n    else\n      this[CONSUMECHUNK](chunk)\n    this[WRITING] = false\n\n    // return false if there's a queue, or if the current entry isn't flowing\n    const ret =\n      this[QUEUE].length ? false :\n      this[READENTRY] ? this[READENTRY].flowing :\n      true\n\n    // if we have no queue, then that means a clogged READENTRY\n    if (!ret && !this[QUEUE].length)\n      this[READENTRY].once('drain', _ => this.emit('drain'))\n\n    return ret\n  }\n\n  [BUFFERCONCAT] (c) {\n    if (c && !this[ABORTED])\n      this[BUFFER] = this[BUFFER] ? Buffer.concat([this[BUFFER], c]) : c\n  }\n\n  [MAYBEEND] () {\n    if (this[ENDED] &&\n        !this[EMITTEDEND] &&\n        !this[ABORTED] &&\n        !this[CONSUMING]) {\n      this[EMITTEDEND] = true\n      const entry = this[WRITEENTRY]\n      if (entry && entry.blockRemain) {\n        // truncated, likely a damaged file\n        const have = this[BUFFER] ? this[BUFFER].length : 0\n        this.warn('TAR_BAD_ARCHIVE', `Truncated input (needed ${\n          entry.blockRemain} more bytes, only ${have} available)`, {entry})\n        if (this[BUFFER])\n          entry.write(this[BUFFER])\n        entry.end()\n      }\n      this[EMIT](DONE)\n    }\n  }\n\n  [CONSUMECHUNK] (chunk) {\n    if (this[CONSUMING])\n      this[BUFFERCONCAT](chunk)\n    else if (!chunk && !this[BUFFER])\n      this[MAYBEEND]()\n    else {\n      this[CONSUMING] = true\n      if (this[BUFFER]) {\n        this[BUFFERCONCAT](chunk)\n        const c = this[BUFFER]\n        this[BUFFER] = null\n        this[CONSUMECHUNKSUB](c)\n      } else\n        this[CONSUMECHUNKSUB](chunk)\n\n      while (this[BUFFER] &&\n          this[BUFFER].length >= 512 &&\n          !this[ABORTED] &&\n          !this[SAW_EOF]) {\n        const c = this[BUFFER]\n        this[BUFFER] = null\n        this[CONSUMECHUNKSUB](c)\n      }\n      this[CONSUMING] = false\n    }\n\n    if (!this[BUFFER] || this[ENDED])\n      this[MAYBEEND]()\n  }\n\n  [CONSUMECHUNKSUB] (chunk) {\n    // we know that we are in CONSUMING mode, so anything written goes into\n    // the buffer.  Advance the position and put any remainder in the buffer.\n    let position = 0\n    const length = chunk.length\n    while (position + 512 <= length && !this[ABORTED] && !this[SAW_EOF]) {\n      switch (this[STATE]) {\n        case 'begin':\n        case 'header':\n          this[CONSUMEHEADER](chunk, position)\n          position += 512\n          break\n\n        case 'ignore':\n        case 'body':\n          position += this[CONSUMEBODY](chunk, position)\n          break\n\n        case 'meta':\n          position += this[CONSUMEMETA](chunk, position)\n          break\n\n        /* istanbul ignore next */\n        default:\n          throw new Error('invalid state: ' + this[STATE])\n      }\n    }\n\n    if (position < length) {\n      if (this[BUFFER])\n        this[BUFFER] = Buffer.concat([chunk.slice(position), this[BUFFER]])\n      else\n        this[BUFFER] = chunk.slice(position)\n    }\n  }\n\n  end (chunk) {\n    if (!this[ABORTED]) {\n      if (this[UNZIP])\n        this[UNZIP].end(chunk)\n      else {\n        this[ENDED] = true\n        this.write(chunk)\n      }\n    }\n  }\n})\n","// A path exclusive reservation system\n// reserve([list, of, paths], fn)\n// When the fn is first in line for all its paths, it\n// is called with a cb that clears the reservation.\n//\n// Used by async unpack to avoid clobbering paths in use,\n// while still allowing maximal safe parallelization.\n\nconst assert = require('assert')\nconst normalize = require('./normalize-unicode.js')\nconst stripSlashes = require('./strip-trailing-slashes.js')\nconst { join } = require('path')\n\nconst platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platform\nconst isWindows = platform === 'win32'\n\nmodule.exports = () => {\n  // path => [function or Set]\n  // A Set object means a directory reservation\n  // A fn is a direct reservation on that path\n  const queues = new Map()\n\n  // fn => {paths:[path,...], dirs:[path, ...]}\n  const reservations = new Map()\n\n  // return a set of parent dirs for a given path\n  // '/a/b/c/d' -> ['/', '/a', '/a/b', '/a/b/c', '/a/b/c/d']\n  const getDirs = path => {\n    const dirs = path.split('/').slice(0, -1).reduce((set, path) => {\n      if (set.length)\n        path = join(set[set.length - 1], path)\n      set.push(path || '/')\n      return set\n    }, [])\n    return dirs\n  }\n\n  // functions currently running\n  const running = new Set()\n\n  // return the queues for each path the function cares about\n  // fn => {paths, dirs}\n  const getQueues = fn => {\n    const res = reservations.get(fn)\n    /* istanbul ignore if - unpossible */\n    if (!res)\n      throw new Error('function does not have any path reservations')\n    return {\n      paths: res.paths.map(path => queues.get(path)),\n      dirs: [...res.dirs].map(path => queues.get(path)),\n    }\n  }\n\n  // check if fn is first in line for all its paths, and is\n  // included in the first set for all its dir queues\n  const check = fn => {\n    const {paths, dirs} = getQueues(fn)\n    return paths.every(q => q[0] === fn) &&\n      dirs.every(q => q[0] instanceof Set && q[0].has(fn))\n  }\n\n  // run the function if it's first in line and not already running\n  const run = fn => {\n    if (running.has(fn) || !check(fn))\n      return false\n    running.add(fn)\n    fn(() => clear(fn))\n    return true\n  }\n\n  const clear = fn => {\n    if (!running.has(fn))\n      return false\n\n    const { paths, dirs } = reservations.get(fn)\n    const next = new Set()\n\n    paths.forEach(path => {\n      const q = queues.get(path)\n      assert.equal(q[0], fn)\n      if (q.length === 1)\n        queues.delete(path)\n      else {\n        q.shift()\n        if (typeof q[0] === 'function')\n          next.add(q[0])\n        else\n          q[0].forEach(fn => next.add(fn))\n      }\n    })\n\n    dirs.forEach(dir => {\n      const q = queues.get(dir)\n      assert(q[0] instanceof Set)\n      if (q[0].size === 1 && q.length === 1)\n        queues.delete(dir)\n      else if (q[0].size === 1) {\n        q.shift()\n\n        // must be a function or else the Set would've been reused\n        next.add(q[0])\n      } else\n        q[0].delete(fn)\n    })\n    running.delete(fn)\n\n    next.forEach(fn => run(fn))\n    return true\n  }\n\n  const reserve = (paths, fn) => {\n    // collide on matches across case and unicode normalization\n    // On windows, thanks to the magic of 8.3 shortnames, it is fundamentally\n    // impossible to determine whether two paths refer to the same thing on\n    // disk, without asking the kernel for a shortname.\n    // So, we just pretend that every path matches every other path here,\n    // effectively removing all parallelization on windows.\n    paths = isWindows ? ['win32 parallelization disabled'] : paths.map(p => {\n      // don't need normPath, because we skip this entirely for windows\n      return normalize(stripSlashes(join(p))).toLowerCase()\n    })\n\n    const dirs = new Set(\n      paths.map(path => getDirs(path)).reduce((a, b) => a.concat(b))\n    )\n    reservations.set(fn, {dirs, paths})\n    paths.forEach(path => {\n      const q = queues.get(path)\n      if (!q)\n        queues.set(path, [fn])\n      else\n        q.push(fn)\n    })\n    dirs.forEach(dir => {\n      const q = queues.get(dir)\n      if (!q)\n        queues.set(dir, [new Set([fn])])\n      else if (q[q.length - 1] instanceof Set)\n        q[q.length - 1].add(fn)\n      else\n        q.push(new Set([fn]))\n    })\n\n    return run(fn)\n  }\n\n  return { check, reserve }\n}\n","'use strict'\nconst Header = require('./header.js')\nconst path = require('path')\n\nclass Pax {\n  constructor (obj, global) {\n    this.atime = obj.atime || null\n    this.charset = obj.charset || null\n    this.comment = obj.comment || null\n    this.ctime = obj.ctime || null\n    this.gid = obj.gid || null\n    this.gname = obj.gname || null\n    this.linkpath = obj.linkpath || null\n    this.mtime = obj.mtime || null\n    this.path = obj.path || null\n    this.size = obj.size || null\n    this.uid = obj.uid || null\n    this.uname = obj.uname || null\n    this.dev = obj.dev || null\n    this.ino = obj.ino || null\n    this.nlink = obj.nlink || null\n    this.global = global || false\n  }\n\n  encode () {\n    const body = this.encodeBody()\n    if (body === '')\n      return null\n\n    const bodyLen = Buffer.byteLength(body)\n    // round up to 512 bytes\n    // add 512 for header\n    const bufLen = 512 * Math.ceil(1 + bodyLen / 512)\n    const buf = Buffer.allocUnsafe(bufLen)\n\n    // 0-fill the header section, it might not hit every field\n    for (let i = 0; i < 512; i++)\n      buf[i] = 0\n\n    new Header({\n      // XXX split the path\n      // then the path should be PaxHeader + basename, but less than 99,\n      // prepend with the dirname\n      path: ('PaxHeader/' + path.basename(this.path)).slice(0, 99),\n      mode: this.mode || 0o644,\n      uid: this.uid || null,\n      gid: this.gid || null,\n      size: bodyLen,\n      mtime: this.mtime || null,\n      type: this.global ? 'GlobalExtendedHeader' : 'ExtendedHeader',\n      linkpath: '',\n      uname: this.uname || '',\n      gname: this.gname || '',\n      devmaj: 0,\n      devmin: 0,\n      atime: this.atime || null,\n      ctime: this.ctime || null,\n    }).encode(buf)\n\n    buf.write(body, 512, bodyLen, 'utf8')\n\n    // null pad after the body\n    for (let i = bodyLen + 512; i < buf.length; i++)\n      buf[i] = 0\n\n    return buf\n  }\n\n  encodeBody () {\n    return (\n      this.encodeField('path') +\n      this.encodeField('ctime') +\n      this.encodeField('atime') +\n      this.encodeField('dev') +\n      this.encodeField('ino') +\n      this.encodeField('nlink') +\n      this.encodeField('charset') +\n      this.encodeField('comment') +\n      this.encodeField('gid') +\n      this.encodeField('gname') +\n      this.encodeField('linkpath') +\n      this.encodeField('mtime') +\n      this.encodeField('size') +\n      this.encodeField('uid') +\n      this.encodeField('uname')\n    )\n  }\n\n  encodeField (field) {\n    if (this[field] === null || this[field] === undefined)\n      return ''\n    const v = this[field] instanceof Date ? this[field].getTime() / 1000\n      : this[field]\n    const s = ' ' +\n      (field === 'dev' || field === 'ino' || field === 'nlink'\n        ? 'SCHILY.' : '') +\n      field + '=' + v + '\\n'\n    const byteLen = Buffer.byteLength(s)\n    // the digits includes the length of the digits in ascii base-10\n    // so if it's 9 characters, then adding 1 for the 9 makes it 10\n    // which makes it 11 chars.\n    let digits = Math.floor(Math.log(byteLen) / Math.log(10)) + 1\n    if (byteLen + digits >= Math.pow(10, digits))\n      digits += 1\n    const len = digits + byteLen\n    return len + s\n  }\n}\n\nPax.parse = (string, ex, g) => new Pax(merge(parseKV(string), ex), g)\n\nconst merge = (a, b) =>\n  b ? Object.keys(a).reduce((s, k) => (s[k] = a[k], s), b) : a\n\nconst parseKV = string =>\n  string\n    .replace(/\\n$/, '')\n    .split('\\n')\n    .reduce(parseKVLine, Object.create(null))\n\nconst parseKVLine = (set, line) => {\n  const n = parseInt(line, 10)\n\n  // XXX Values with \\n in them will fail this.\n  // Refactor to not be a naive line-by-line parse.\n  if (n !== Buffer.byteLength(line) + 1)\n    return set\n\n  line = line.substr((n + ' ').length)\n  const kv = line.split('=')\n  const k = kv.shift().replace(/^SCHILY\\.(dev|ino|nlink)/, '$1')\n  if (!k)\n    return set\n\n  const v = kv.join('=')\n  set[k] = /^([A-Z]+\\.)?([mac]|birth|creation)time$/.test(k)\n    ? new Date(v * 1000)\n    : /^[0-9]+$/.test(v) ? +v\n    : v\n  return set\n}\n\nmodule.exports = Pax\n","'use strict'\nconst MiniPass = require('minipass')\nconst normPath = require('./normalize-windows-path.js')\n\nconst SLURP = Symbol('slurp')\nmodule.exports = class ReadEntry extends MiniPass {\n  constructor (header, ex, gex) {\n    super()\n    // read entries always start life paused.  this is to avoid the\n    // situation where Minipass's auto-ending empty streams results\n    // in an entry ending before we're ready for it.\n    this.pause()\n    this.extended = ex\n    this.globalExtended = gex\n    this.header = header\n    this.startBlockSize = 512 * Math.ceil(header.size / 512)\n    this.blockRemain = this.startBlockSize\n    this.remain = header.size\n    this.type = header.type\n    this.meta = false\n    this.ignore = false\n    switch (this.type) {\n      case 'File':\n      case 'OldFile':\n      case 'Link':\n      case 'SymbolicLink':\n      case 'CharacterDevice':\n      case 'BlockDevice':\n      case 'Directory':\n      case 'FIFO':\n      case 'ContiguousFile':\n      case 'GNUDumpDir':\n        break\n\n      case 'NextFileHasLongLinkpath':\n      case 'NextFileHasLongPath':\n      case 'OldGnuLongPath':\n      case 'GlobalExtendedHeader':\n      case 'ExtendedHeader':\n      case 'OldExtendedHeader':\n        this.meta = true\n        break\n\n      // NOTE: gnutar and bsdtar treat unrecognized types as 'File'\n      // it may be worth doing the same, but with a warning.\n      default:\n        this.ignore = true\n    }\n\n    this.path = normPath(header.path)\n    this.mode = header.mode\n    if (this.mode)\n      this.mode = this.mode & 0o7777\n    this.uid = header.uid\n    this.gid = header.gid\n    this.uname = header.uname\n    this.gname = header.gname\n    this.size = header.size\n    this.mtime = header.mtime\n    this.atime = header.atime\n    this.ctime = header.ctime\n    this.linkpath = normPath(header.linkpath)\n    this.uname = header.uname\n    this.gname = header.gname\n\n    if (ex)\n      this[SLURP](ex)\n    if (gex)\n      this[SLURP](gex, true)\n  }\n\n  write (data) {\n    const writeLen = data.length\n    if (writeLen > this.blockRemain)\n      throw new Error('writing more to entry than is appropriate')\n\n    const r = this.remain\n    const br = this.blockRemain\n    this.remain = Math.max(0, r - writeLen)\n    this.blockRemain = Math.max(0, br - writeLen)\n    if (this.ignore)\n      return true\n\n    if (r >= writeLen)\n      return super.write(data)\n\n    // r < writeLen\n    return super.write(data.slice(0, r))\n  }\n\n  [SLURP] (ex, global) {\n    for (const k in ex) {\n      // we slurp in everything except for the path attribute in\n      // a global extended header, because that's weird.\n      if (ex[k] !== null && ex[k] !== undefined &&\n          !(global && k === 'path'))\n        this[k] = k === 'path' || k === 'linkpath' ? normPath(ex[k]) : ex[k]\n    }\n  }\n}\n","'use strict'\n\n// tar -r\nconst hlo = require('./high-level-opt.js')\nconst Pack = require('./pack.js')\nconst fs = require('fs')\nconst fsm = require('fs-minipass')\nconst t = require('./list.js')\nconst path = require('path')\n\n// starting at the head of the file, read a Header\n// If the checksum is invalid, that's our position to start writing\n// If it is, jump forward by the specified size (round up to 512)\n// and try again.\n// Write the new Pack stream starting there.\n\nconst Header = require('./header.js')\n\nmodule.exports = (opt_, files, cb) => {\n  const opt = hlo(opt_)\n\n  if (!opt.file)\n    throw new TypeError('file is required')\n\n  if (opt.gzip)\n    throw new TypeError('cannot append to compressed archives')\n\n  if (!files || !Array.isArray(files) || !files.length)\n    throw new TypeError('no files or directories specified')\n\n  files = Array.from(files)\n\n  return opt.sync ? replaceSync(opt, files)\n    : replace(opt, files, cb)\n}\n\nconst replaceSync = (opt, files) => {\n  const p = new Pack.Sync(opt)\n\n  let threw = true\n  let fd\n  let position\n\n  try {\n    try {\n      fd = fs.openSync(opt.file, 'r+')\n    } catch (er) {\n      if (er.code === 'ENOENT')\n        fd = fs.openSync(opt.file, 'w+')\n      else\n        throw er\n    }\n\n    const st = fs.fstatSync(fd)\n    const headBuf = Buffer.alloc(512)\n\n    POSITION: for (position = 0; position < st.size; position += 512) {\n      for (let bufPos = 0, bytes = 0; bufPos < 512; bufPos += bytes) {\n        bytes = fs.readSync(\n          fd, headBuf, bufPos, headBuf.length - bufPos, position + bufPos\n        )\n\n        if (position === 0 && headBuf[0] === 0x1f && headBuf[1] === 0x8b)\n          throw new Error('cannot append to compressed archives')\n\n        if (!bytes)\n          break POSITION\n      }\n\n      const h = new Header(headBuf)\n      if (!h.cksumValid)\n        break\n      const entryBlockSize = 512 * Math.ceil(h.size / 512)\n      if (position + entryBlockSize + 512 > st.size)\n        break\n      // the 512 for the header we just parsed will be added as well\n      // also jump ahead all the blocks for the body\n      position += entryBlockSize\n      if (opt.mtimeCache)\n        opt.mtimeCache.set(h.path, h.mtime)\n    }\n    threw = false\n\n    streamSync(opt, p, position, fd, files)\n  } finally {\n    if (threw) {\n      try {\n        fs.closeSync(fd)\n      } catch (er) {}\n    }\n  }\n}\n\nconst streamSync = (opt, p, position, fd, files) => {\n  const stream = new fsm.WriteStreamSync(opt.file, {\n    fd: fd,\n    start: position,\n  })\n  p.pipe(stream)\n  addFilesSync(p, files)\n}\n\nconst replace = (opt, files, cb) => {\n  files = Array.from(files)\n  const p = new Pack(opt)\n\n  const getPos = (fd, size, cb_) => {\n    const cb = (er, pos) => {\n      if (er)\n        fs.close(fd, _ => cb_(er))\n      else\n        cb_(null, pos)\n    }\n\n    let position = 0\n    if (size === 0)\n      return cb(null, 0)\n\n    let bufPos = 0\n    const headBuf = Buffer.alloc(512)\n    const onread = (er, bytes) => {\n      if (er)\n        return cb(er)\n      bufPos += bytes\n      if (bufPos < 512 && bytes) {\n        return fs.read(\n          fd, headBuf, bufPos, headBuf.length - bufPos,\n          position + bufPos, onread\n        )\n      }\n\n      if (position === 0 && headBuf[0] === 0x1f && headBuf[1] === 0x8b)\n        return cb(new Error('cannot append to compressed archives'))\n\n      // truncated header\n      if (bufPos < 512)\n        return cb(null, position)\n\n      const h = new Header(headBuf)\n      if (!h.cksumValid)\n        return cb(null, position)\n\n      const entryBlockSize = 512 * Math.ceil(h.size / 512)\n      if (position + entryBlockSize + 512 > size)\n        return cb(null, position)\n\n      position += entryBlockSize + 512\n      if (position >= size)\n        return cb(null, position)\n\n      if (opt.mtimeCache)\n        opt.mtimeCache.set(h.path, h.mtime)\n      bufPos = 0\n      fs.read(fd, headBuf, 0, 512, position, onread)\n    }\n    fs.read(fd, headBuf, 0, 512, position, onread)\n  }\n\n  const promise = new Promise((resolve, reject) => {\n    p.on('error', reject)\n    let flag = 'r+'\n    const onopen = (er, fd) => {\n      if (er && er.code === 'ENOENT' && flag === 'r+') {\n        flag = 'w+'\n        return fs.open(opt.file, flag, onopen)\n      }\n\n      if (er)\n        return reject(er)\n\n      fs.fstat(fd, (er, st) => {\n        if (er)\n          return fs.close(fd, () => reject(er))\n\n        getPos(fd, st.size, (er, position) => {\n          if (er)\n            return reject(er)\n          const stream = new fsm.WriteStream(opt.file, {\n            fd: fd,\n            start: position,\n          })\n          p.pipe(stream)\n          stream.on('error', reject)\n          stream.on('close', resolve)\n          addFilesAsync(p, files)\n        })\n      })\n    }\n    fs.open(opt.file, flag, onopen)\n  })\n\n  return cb ? promise.then(cb, cb) : promise\n}\n\nconst addFilesSync = (p, files) => {\n  files.forEach(file => {\n    if (file.charAt(0) === '@') {\n      t({\n        file: path.resolve(p.cwd, file.substr(1)),\n        sync: true,\n        noResume: true,\n        onentry: entry => p.add(entry),\n      })\n    } else\n      p.add(file)\n  })\n  p.end()\n}\n\nconst addFilesAsync = (p, files) => {\n  while (files.length) {\n    const file = files.shift()\n    if (file.charAt(0) === '@') {\n      return t({\n        file: path.resolve(p.cwd, file.substr(1)),\n        noResume: true,\n        onentry: entry => p.add(entry),\n      }).then(_ => addFilesAsync(p, files))\n    } else\n      p.add(file)\n  }\n  p.end()\n}\n","// unix absolute paths are also absolute on win32, so we use this for both\nconst { isAbsolute, parse } = require('path').win32\n\n// returns [root, stripped]\n// Note that windows will think that //x/y/z/a has a \"root\" of //x/y, and in\n// those cases, we want to sanitize it to x/y/z/a, not z/a, so we strip /\n// explicitly if it's the first character.\n// drive-specific relative paths on Windows get their root stripped off even\n// though they are not absolute, so `c:../foo` becomes ['c:', '../foo']\nmodule.exports = path => {\n  let r = ''\n\n  let parsed = parse(path)\n  while (isAbsolute(path) || parsed.root) {\n    // windows will think that //x/y/z has a \"root\" of //x/y/\n    // but strip the //?/C:/ off of //?/C:/path\n    const root = path.charAt(0) === '/' && path.slice(0, 4) !== '//?/' ? '/'\n      : parsed.root\n    path = path.substr(root.length)\n    r += root\n    parsed = parse(path)\n  }\n  return [r, path]\n}\n","// warning: extremely hot code path.\n// This has been meticulously optimized for use\n// within npm install on large package trees.\n// Do not edit without careful benchmarking.\nmodule.exports = str => {\n  let i = str.length - 1\n  let slashesStart = -1\n  while (i > -1 && str.charAt(i) === '/') {\n    slashesStart = i\n    i--\n  }\n  return slashesStart === -1 ? str : str.slice(0, slashesStart)\n}\n","'use strict'\n// map types from key to human-friendly name\nexports.name = new Map([\n  ['0', 'File'],\n  // same as File\n  ['', 'OldFile'],\n  ['1', 'Link'],\n  ['2', 'SymbolicLink'],\n  // Devices and FIFOs aren't fully supported\n  // they are parsed, but skipped when unpacking\n  ['3', 'CharacterDevice'],\n  ['4', 'BlockDevice'],\n  ['5', 'Directory'],\n  ['6', 'FIFO'],\n  // same as File\n  ['7', 'ContiguousFile'],\n  // pax headers\n  ['g', 'GlobalExtendedHeader'],\n  ['x', 'ExtendedHeader'],\n  // vendor-specific stuff\n  // skip\n  ['A', 'SolarisACL'],\n  // like 5, but with data, which should be skipped\n  ['D', 'GNUDumpDir'],\n  // metadata only, skip\n  ['I', 'Inode'],\n  // data = link path of next file\n  ['K', 'NextFileHasLongLinkpath'],\n  // data = path of next file\n  ['L', 'NextFileHasLongPath'],\n  // skip\n  ['M', 'ContinuationFile'],\n  // like L\n  ['N', 'OldGnuLongPath'],\n  // skip\n  ['S', 'SparseFile'],\n  // skip\n  ['V', 'TapeVolumeHeader'],\n  // like x\n  ['X', 'OldExtendedHeader'],\n])\n\n// map the other direction\nexports.code = new Map(Array.from(exports.name).map(kv => [kv[1], kv[0]]))\n","'use strict'\n\n// the PEND/UNPEND stuff tracks whether we're ready to emit end/close yet.\n// but the path reservations are required to avoid race conditions where\n// parallelized unpack ops may mess with one another, due to dependencies\n// (like a Link depending on its target) or destructive operations (like\n// clobbering an fs object to create one of a different type.)\n\nconst assert = require('assert')\nconst Parser = require('./parse.js')\nconst fs = require('fs')\nconst fsm = require('fs-minipass')\nconst path = require('path')\nconst mkdir = require('./mkdir.js')\nconst wc = require('./winchars.js')\nconst pathReservations = require('./path-reservations.js')\nconst stripAbsolutePath = require('./strip-absolute-path.js')\nconst normPath = require('./normalize-windows-path.js')\nconst stripSlash = require('./strip-trailing-slashes.js')\nconst normalize = require('./normalize-unicode.js')\n\nconst ONENTRY = Symbol('onEntry')\nconst CHECKFS = Symbol('checkFs')\nconst CHECKFS2 = Symbol('checkFs2')\nconst PRUNECACHE = Symbol('pruneCache')\nconst ISREUSABLE = Symbol('isReusable')\nconst MAKEFS = Symbol('makeFs')\nconst FILE = Symbol('file')\nconst DIRECTORY = Symbol('directory')\nconst LINK = Symbol('link')\nconst SYMLINK = Symbol('symlink')\nconst HARDLINK = Symbol('hardlink')\nconst UNSUPPORTED = Symbol('unsupported')\nconst CHECKPATH = Symbol('checkPath')\nconst MKDIR = Symbol('mkdir')\nconst ONERROR = Symbol('onError')\nconst PENDING = Symbol('pending')\nconst PEND = Symbol('pend')\nconst UNPEND = Symbol('unpend')\nconst ENDED = Symbol('ended')\nconst MAYBECLOSE = Symbol('maybeClose')\nconst SKIP = Symbol('skip')\nconst DOCHOWN = Symbol('doChown')\nconst UID = Symbol('uid')\nconst GID = Symbol('gid')\nconst CHECKED_CWD = Symbol('checkedCwd')\nconst crypto = require('crypto')\nconst getFlag = require('./get-write-flag.js')\nconst platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platform\nconst isWindows = platform === 'win32'\n\n// Unlinks on Windows are not atomic.\n//\n// This means that if you have a file entry, followed by another\n// file entry with an identical name, and you cannot re-use the file\n// (because it's a hardlink, or because unlink:true is set, or it's\n// Windows, which does not have useful nlink values), then the unlink\n// will be committed to the disk AFTER the new file has been written\n// over the old one, deleting the new file.\n//\n// To work around this, on Windows systems, we rename the file and then\n// delete the renamed file.  It's a sloppy kludge, but frankly, I do not\n// know of a better way to do this, given windows' non-atomic unlink\n// semantics.\n//\n// See: https://github.com/npm/node-tar/issues/183\n/* istanbul ignore next */\nconst unlinkFile = (path, cb) => {\n  if (!isWindows)\n    return fs.unlink(path, cb)\n\n  const name = path + '.DELETE.' + crypto.randomBytes(16).toString('hex')\n  fs.rename(path, name, er => {\n    if (er)\n      return cb(er)\n    fs.unlink(name, cb)\n  })\n}\n\n/* istanbul ignore next */\nconst unlinkFileSync = path => {\n  if (!isWindows)\n    return fs.unlinkSync(path)\n\n  const name = path + '.DELETE.' + crypto.randomBytes(16).toString('hex')\n  fs.renameSync(path, name)\n  fs.unlinkSync(name)\n}\n\n// this.gid, entry.gid, this.processUid\nconst uint32 = (a, b, c) =>\n  a === a >>> 0 ? a\n  : b === b >>> 0 ? b\n  : c\n\n// clear the cache if it's a case-insensitive unicode-squashing match.\n// we can't know if the current file system is case-sensitive or supports\n// unicode fully, so we check for similarity on the maximally compatible\n// representation.  Err on the side of pruning, since all it's doing is\n// preventing lstats, and it's not the end of the world if we get a false\n// positive.\n// Note that on windows, we always drop the entire cache whenever a\n// symbolic link is encountered, because 8.3 filenames are impossible\n// to reason about, and collisions are hazards rather than just failures.\nconst cacheKeyNormalize = path => normalize(stripSlash(normPath(path)))\n  .toLowerCase()\n\nconst pruneCache = (cache, abs) => {\n  abs = cacheKeyNormalize(abs)\n  for (const path of cache.keys()) {\n    const pnorm = cacheKeyNormalize(path)\n    if (pnorm === abs || pnorm.indexOf(abs + '/') === 0)\n      cache.delete(path)\n  }\n}\n\nconst dropCache = cache => {\n  for (const key of cache.keys())\n    cache.delete(key)\n}\n\nclass Unpack extends Parser {\n  constructor (opt) {\n    if (!opt)\n      opt = {}\n\n    opt.ondone = _ => {\n      this[ENDED] = true\n      this[MAYBECLOSE]()\n    }\n\n    super(opt)\n\n    this[CHECKED_CWD] = false\n\n    this.reservations = pathReservations()\n\n    this.transform = typeof opt.transform === 'function' ? opt.transform : null\n\n    this.writable = true\n    this.readable = false\n\n    this[PENDING] = 0\n    this[ENDED] = false\n\n    this.dirCache = opt.dirCache || new Map()\n\n    if (typeof opt.uid === 'number' || typeof opt.gid === 'number') {\n      // need both or neither\n      if (typeof opt.uid !== 'number' || typeof opt.gid !== 'number')\n        throw new TypeError('cannot set owner without number uid and gid')\n      if (opt.preserveOwner) {\n        throw new TypeError(\n          'cannot preserve owner in archive and also set owner explicitly')\n      }\n      this.uid = opt.uid\n      this.gid = opt.gid\n      this.setOwner = true\n    } else {\n      this.uid = null\n      this.gid = null\n      this.setOwner = false\n    }\n\n    // default true for root\n    if (opt.preserveOwner === undefined && typeof opt.uid !== 'number')\n      this.preserveOwner = process.getuid && process.getuid() === 0\n    else\n      this.preserveOwner = !!opt.preserveOwner\n\n    this.processUid = (this.preserveOwner || this.setOwner) && process.getuid ?\n      process.getuid() : null\n    this.processGid = (this.preserveOwner || this.setOwner) && process.getgid ?\n      process.getgid() : null\n\n    // mostly just for testing, but useful in some cases.\n    // Forcibly trigger a chown on every entry, no matter what\n    this.forceChown = opt.forceChown === true\n\n    // turn ><?| in filenames into 0xf000-higher encoded forms\n    this.win32 = !!opt.win32 || isWindows\n\n    // do not unpack over files that are newer than what's in the archive\n    this.newer = !!opt.newer\n\n    // do not unpack over ANY files\n    this.keep = !!opt.keep\n\n    // do not set mtime/atime of extracted entries\n    this.noMtime = !!opt.noMtime\n\n    // allow .., absolute path entries, and unpacking through symlinks\n    // without this, warn and skip .., relativize absolutes, and error\n    // on symlinks in extraction path\n    this.preservePaths = !!opt.preservePaths\n\n    // unlink files and links before writing. This breaks existing hard\n    // links, and removes symlink directories rather than erroring\n    this.unlink = !!opt.unlink\n\n    this.cwd = normPath(path.resolve(opt.cwd || process.cwd()))\n    this.strip = +opt.strip || 0\n    // if we're not chmodding, then we don't need the process umask\n    this.processUmask = opt.noChmod ? 0 : process.umask()\n    this.umask = typeof opt.umask === 'number' ? opt.umask : this.processUmask\n\n    // default mode for dirs created as parents\n    this.dmode = opt.dmode || (0o0777 & (~this.umask))\n    this.fmode = opt.fmode || (0o0666 & (~this.umask))\n\n    this.on('entry', entry => this[ONENTRY](entry))\n  }\n\n  // a bad or damaged archive is a warning for Parser, but an error\n  // when extracting.  Mark those errors as unrecoverable, because\n  // the Unpack contract cannot be met.\n  warn (code, msg, data = {}) {\n    if (code === 'TAR_BAD_ARCHIVE' || code === 'TAR_ABORT')\n      data.recoverable = false\n    return super.warn(code, msg, data)\n  }\n\n  [MAYBECLOSE] () {\n    if (this[ENDED] && this[PENDING] === 0) {\n      this.emit('prefinish')\n      this.emit('finish')\n      this.emit('end')\n      this.emit('close')\n    }\n  }\n\n  [CHECKPATH] (entry) {\n    if (this.strip) {\n      const parts = normPath(entry.path).split('/')\n      if (parts.length < this.strip)\n        return false\n      entry.path = parts.slice(this.strip).join('/')\n\n      if (entry.type === 'Link') {\n        const linkparts = normPath(entry.linkpath).split('/')\n        if (linkparts.length >= this.strip)\n          entry.linkpath = linkparts.slice(this.strip).join('/')\n        else\n          return false\n      }\n    }\n\n    if (!this.preservePaths) {\n      const p = normPath(entry.path)\n      const parts = p.split('/')\n      if (parts.includes('..') || isWindows && /^[a-z]:\\.\\.$/i.test(parts[0])) {\n        this.warn('TAR_ENTRY_ERROR', `path contains '..'`, {\n          entry,\n          path: p,\n        })\n        return false\n      }\n\n      // strip off the root\n      const [root, stripped] = stripAbsolutePath(p)\n      if (root) {\n        entry.path = stripped\n        this.warn('TAR_ENTRY_INFO', `stripping ${root} from absolute path`, {\n          entry,\n          path: p,\n        })\n      }\n    }\n\n    if (path.isAbsolute(entry.path))\n      entry.absolute = normPath(path.resolve(entry.path))\n    else\n      entry.absolute = normPath(path.resolve(this.cwd, entry.path))\n\n    // if we somehow ended up with a path that escapes the cwd, and we are\n    // not in preservePaths mode, then something is fishy!  This should have\n    // been prevented above, so ignore this for coverage.\n    /* istanbul ignore if - defense in depth */\n    if (!this.preservePaths &&\n        entry.absolute.indexOf(this.cwd + '/') !== 0 &&\n        entry.absolute !== this.cwd) {\n      this.warn('TAR_ENTRY_ERROR', 'path escaped extraction target', {\n        entry,\n        path: normPath(entry.path),\n        resolvedPath: entry.absolute,\n        cwd: this.cwd,\n      })\n      return false\n    }\n\n    // an archive can set properties on the extraction directory, but it\n    // may not replace the cwd with a different kind of thing entirely.\n    if (entry.absolute === this.cwd &&\n        entry.type !== 'Directory' &&\n        entry.type !== 'GNUDumpDir')\n      return false\n\n    // only encode : chars that aren't drive letter indicators\n    if (this.win32) {\n      const { root: aRoot } = path.win32.parse(entry.absolute)\n      entry.absolute = aRoot + wc.encode(entry.absolute.substr(aRoot.length))\n      const { root: pRoot } = path.win32.parse(entry.path)\n      entry.path = pRoot + wc.encode(entry.path.substr(pRoot.length))\n    }\n\n    return true\n  }\n\n  [ONENTRY] (entry) {\n    if (!this[CHECKPATH](entry))\n      return entry.resume()\n\n    assert.equal(typeof entry.absolute, 'string')\n\n    switch (entry.type) {\n      case 'Directory':\n      case 'GNUDumpDir':\n        if (entry.mode)\n          entry.mode = entry.mode | 0o700\n\n      case 'File':\n      case 'OldFile':\n      case 'ContiguousFile':\n      case 'Link':\n      case 'SymbolicLink':\n        return this[CHECKFS](entry)\n\n      case 'CharacterDevice':\n      case 'BlockDevice':\n      case 'FIFO':\n      default:\n        return this[UNSUPPORTED](entry)\n    }\n  }\n\n  [ONERROR] (er, entry) {\n    // Cwd has to exist, or else nothing works. That's serious.\n    // Other errors are warnings, which raise the error in strict\n    // mode, but otherwise continue on.\n    if (er.name === 'CwdError')\n      this.emit('error', er)\n    else {\n      this.warn('TAR_ENTRY_ERROR', er, {entry})\n      this[UNPEND]()\n      entry.resume()\n    }\n  }\n\n  [MKDIR] (dir, mode, cb) {\n    mkdir(normPath(dir), {\n      uid: this.uid,\n      gid: this.gid,\n      processUid: this.processUid,\n      processGid: this.processGid,\n      umask: this.processUmask,\n      preserve: this.preservePaths,\n      unlink: this.unlink,\n      cache: this.dirCache,\n      cwd: this.cwd,\n      mode: mode,\n      noChmod: this.noChmod,\n    }, cb)\n  }\n\n  [DOCHOWN] (entry) {\n    // in preserve owner mode, chown if the entry doesn't match process\n    // in set owner mode, chown if setting doesn't match process\n    return this.forceChown ||\n      this.preserveOwner &&\n      (typeof entry.uid === 'number' && entry.uid !== this.processUid ||\n        typeof entry.gid === 'number' && entry.gid !== this.processGid)\n      ||\n      (typeof this.uid === 'number' && this.uid !== this.processUid ||\n        typeof this.gid === 'number' && this.gid !== this.processGid)\n  }\n\n  [UID] (entry) {\n    return uint32(this.uid, entry.uid, this.processUid)\n  }\n\n  [GID] (entry) {\n    return uint32(this.gid, entry.gid, this.processGid)\n  }\n\n  [FILE] (entry, fullyDone) {\n    const mode = entry.mode & 0o7777 || this.fmode\n    const stream = new fsm.WriteStream(entry.absolute, {\n      flags: getFlag(entry.size),\n      mode: mode,\n      autoClose: false,\n    })\n    stream.on('error', er => {\n      if (stream.fd)\n        fs.close(stream.fd, () => {})\n\n      // flush all the data out so that we aren't left hanging\n      // if the error wasn't actually fatal.  otherwise the parse\n      // is blocked, and we never proceed.\n      stream.write = () => true\n      this[ONERROR](er, entry)\n      fullyDone()\n    })\n\n    let actions = 1\n    const done = er => {\n      if (er) {\n        /* istanbul ignore else - we should always have a fd by now */\n        if (stream.fd)\n          fs.close(stream.fd, () => {})\n\n        this[ONERROR](er, entry)\n        fullyDone()\n        return\n      }\n\n      if (--actions === 0) {\n        fs.close(stream.fd, er => {\n          if (er)\n            this[ONERROR](er, entry)\n          else\n            this[UNPEND]()\n          fullyDone()\n        })\n      }\n    }\n\n    stream.on('finish', _ => {\n      // if futimes fails, try utimes\n      // if utimes fails, fail with the original error\n      // same for fchown/chown\n      const abs = entry.absolute\n      const fd = stream.fd\n\n      if (entry.mtime && !this.noMtime) {\n        actions++\n        const atime = entry.atime || new Date()\n        const mtime = entry.mtime\n        fs.futimes(fd, atime, mtime, er =>\n          er ? fs.utimes(abs, atime, mtime, er2 => done(er2 && er))\n          : done())\n      }\n\n      if (this[DOCHOWN](entry)) {\n        actions++\n        const uid = this[UID](entry)\n        const gid = this[GID](entry)\n        fs.fchown(fd, uid, gid, er =>\n          er ? fs.chown(abs, uid, gid, er2 => done(er2 && er))\n          : done())\n      }\n\n      done()\n    })\n\n    const tx = this.transform ? this.transform(entry) || entry : entry\n    if (tx !== entry) {\n      tx.on('error', er => {\n        this[ONERROR](er, entry)\n        fullyDone()\n      })\n      entry.pipe(tx)\n    }\n    tx.pipe(stream)\n  }\n\n  [DIRECTORY] (entry, fullyDone) {\n    const mode = entry.mode & 0o7777 || this.dmode\n    this[MKDIR](entry.absolute, mode, er => {\n      if (er) {\n        this[ONERROR](er, entry)\n        fullyDone()\n        return\n      }\n\n      let actions = 1\n      const done = _ => {\n        if (--actions === 0) {\n          fullyDone()\n          this[UNPEND]()\n          entry.resume()\n        }\n      }\n\n      if (entry.mtime && !this.noMtime) {\n        actions++\n        fs.utimes(entry.absolute, entry.atime || new Date(), entry.mtime, done)\n      }\n\n      if (this[DOCHOWN](entry)) {\n        actions++\n        fs.chown(entry.absolute, this[UID](entry), this[GID](entry), done)\n      }\n\n      done()\n    })\n  }\n\n  [UNSUPPORTED] (entry) {\n    entry.unsupported = true\n    this.warn('TAR_ENTRY_UNSUPPORTED',\n      `unsupported entry type: ${entry.type}`, {entry})\n    entry.resume()\n  }\n\n  [SYMLINK] (entry, done) {\n    this[LINK](entry, entry.linkpath, 'symlink', done)\n  }\n\n  [HARDLINK] (entry, done) {\n    const linkpath = normPath(path.resolve(this.cwd, entry.linkpath))\n    this[LINK](entry, linkpath, 'link', done)\n  }\n\n  [PEND] () {\n    this[PENDING]++\n  }\n\n  [UNPEND] () {\n    this[PENDING]--\n    this[MAYBECLOSE]()\n  }\n\n  [SKIP] (entry) {\n    this[UNPEND]()\n    entry.resume()\n  }\n\n  // Check if we can reuse an existing filesystem entry safely and\n  // overwrite it, rather than unlinking and recreating\n  // Windows doesn't report a useful nlink, so we just never reuse entries\n  [ISREUSABLE] (entry, st) {\n    return entry.type === 'File' &&\n      !this.unlink &&\n      st.isFile() &&\n      st.nlink <= 1 &&\n      !isWindows\n  }\n\n  // check if a thing is there, and if so, try to clobber it\n  [CHECKFS] (entry) {\n    this[PEND]()\n    const paths = [entry.path]\n    if (entry.linkpath)\n      paths.push(entry.linkpath)\n    this.reservations.reserve(paths, done => this[CHECKFS2](entry, done))\n  }\n\n  [PRUNECACHE] (entry) {\n    // if we are not creating a directory, and the path is in the dirCache,\n    // then that means we are about to delete the directory we created\n    // previously, and it is no longer going to be a directory, and neither\n    // is any of its children.\n    // If a symbolic link is encountered, all bets are off.  There is no\n    // reasonable way to sanitize the cache in such a way we will be able to\n    // avoid having filesystem collisions.  If this happens with a non-symlink\n    // entry, it'll just fail to unpack, but a symlink to a directory, using an\n    // 8.3 shortname or certain unicode attacks, can evade detection and lead\n    // to arbitrary writes to anywhere on the system.\n    if (entry.type === 'SymbolicLink')\n      dropCache(this.dirCache)\n    else if (entry.type !== 'Directory')\n      pruneCache(this.dirCache, entry.absolute)\n  }\n\n  [CHECKFS2] (entry, fullyDone) {\n    this[PRUNECACHE](entry)\n\n    const done = er => {\n      this[PRUNECACHE](entry)\n      fullyDone(er)\n    }\n\n    const checkCwd = () => {\n      this[MKDIR](this.cwd, this.dmode, er => {\n        if (er) {\n          this[ONERROR](er, entry)\n          done()\n          return\n        }\n        this[CHECKED_CWD] = true\n        start()\n      })\n    }\n\n    const start = () => {\n      if (entry.absolute !== this.cwd) {\n        const parent = normPath(path.dirname(entry.absolute))\n        if (parent !== this.cwd) {\n          return this[MKDIR](parent, this.dmode, er => {\n            if (er) {\n              this[ONERROR](er, entry)\n              done()\n              return\n            }\n            afterMakeParent()\n          })\n        }\n      }\n      afterMakeParent()\n    }\n\n    const afterMakeParent = () => {\n      fs.lstat(entry.absolute, (lstatEr, st) => {\n        if (st && (this.keep || this.newer && st.mtime > entry.mtime)) {\n          this[SKIP](entry)\n          done()\n          return\n        }\n        if (lstatEr || this[ISREUSABLE](entry, st))\n          return this[MAKEFS](null, entry, done)\n\n        if (st.isDirectory()) {\n          if (entry.type === 'Directory') {\n            const needChmod = !this.noChmod &&\n              entry.mode &&\n              (st.mode & 0o7777) !== entry.mode\n            const afterChmod = er => this[MAKEFS](er, entry, done)\n            if (!needChmod)\n              return afterChmod()\n            return fs.chmod(entry.absolute, entry.mode, afterChmod)\n          }\n          // Not a dir entry, have to remove it.\n          // NB: the only way to end up with an entry that is the cwd\n          // itself, in such a way that == does not detect, is a\n          // tricky windows absolute path with UNC or 8.3 parts (and\n          // preservePaths:true, or else it will have been stripped).\n          // In that case, the user has opted out of path protections\n          // explicitly, so if they blow away the cwd, c'est la vie.\n          if (entry.absolute !== this.cwd) {\n            return fs.rmdir(entry.absolute, er =>\n              this[MAKEFS](er, entry, done))\n          }\n        }\n\n        // not a dir, and not reusable\n        // don't remove if the cwd, we want that error\n        if (entry.absolute === this.cwd)\n          return this[MAKEFS](null, entry, done)\n\n        unlinkFile(entry.absolute, er =>\n          this[MAKEFS](er, entry, done))\n      })\n    }\n\n    if (this[CHECKED_CWD])\n      start()\n    else\n      checkCwd()\n  }\n\n  [MAKEFS] (er, entry, done) {\n    if (er) {\n      this[ONERROR](er, entry)\n      done()\n      return\n    }\n\n    switch (entry.type) {\n      case 'File':\n      case 'OldFile':\n      case 'ContiguousFile':\n        return this[FILE](entry, done)\n\n      case 'Link':\n        return this[HARDLINK](entry, done)\n\n      case 'SymbolicLink':\n        return this[SYMLINK](entry, done)\n\n      case 'Directory':\n      case 'GNUDumpDir':\n        return this[DIRECTORY](entry, done)\n    }\n  }\n\n  [LINK] (entry, linkpath, link, done) {\n    // XXX: get the type ('symlink' or 'junction') for windows\n    fs[link](linkpath, entry.absolute, er => {\n      if (er)\n        this[ONERROR](er, entry)\n      else {\n        this[UNPEND]()\n        entry.resume()\n      }\n      done()\n    })\n  }\n}\n\nconst callSync = fn => {\n  try {\n    return [null, fn()]\n  } catch (er) {\n    return [er, null]\n  }\n}\nclass UnpackSync extends Unpack {\n  [MAKEFS] (er, entry) {\n    return super[MAKEFS](er, entry, () => {})\n  }\n\n  [CHECKFS] (entry) {\n    this[PRUNECACHE](entry)\n\n    if (!this[CHECKED_CWD]) {\n      const er = this[MKDIR](this.cwd, this.dmode)\n      if (er)\n        return this[ONERROR](er, entry)\n      this[CHECKED_CWD] = true\n    }\n\n    // don't bother to make the parent if the current entry is the cwd,\n    // we've already checked it.\n    if (entry.absolute !== this.cwd) {\n      const parent = normPath(path.dirname(entry.absolute))\n      if (parent !== this.cwd) {\n        const mkParent = this[MKDIR](parent, this.dmode)\n        if (mkParent)\n          return this[ONERROR](mkParent, entry)\n      }\n    }\n\n    const [lstatEr, st] = callSync(() => fs.lstatSync(entry.absolute))\n    if (st && (this.keep || this.newer && st.mtime > entry.mtime))\n      return this[SKIP](entry)\n\n    if (lstatEr || this[ISREUSABLE](entry, st))\n      return this[MAKEFS](null, entry)\n\n    if (st.isDirectory()) {\n      if (entry.type === 'Directory') {\n        const needChmod = !this.noChmod &&\n          entry.mode &&\n          (st.mode & 0o7777) !== entry.mode\n        const [er] = needChmod ? callSync(() => {\n          fs.chmodSync(entry.absolute, entry.mode)\n        }) : []\n        return this[MAKEFS](er, entry)\n      }\n      // not a dir entry, have to remove it\n      const [er] = callSync(() => fs.rmdirSync(entry.absolute))\n      this[MAKEFS](er, entry)\n    }\n\n    // not a dir, and not reusable.\n    // don't remove if it's the cwd, since we want that error.\n    const [er] = entry.absolute === this.cwd ? []\n      : callSync(() => unlinkFileSync(entry.absolute))\n    this[MAKEFS](er, entry)\n  }\n\n  [FILE] (entry, done) {\n    const mode = entry.mode & 0o7777 || this.fmode\n\n    const oner = er => {\n      let closeError\n      try {\n        fs.closeSync(fd)\n      } catch (e) {\n        closeError = e\n      }\n      if (er || closeError)\n        this[ONERROR](er || closeError, entry)\n      done()\n    }\n\n    let fd\n    try {\n      fd = fs.openSync(entry.absolute, getFlag(entry.size), mode)\n    } catch (er) {\n      return oner(er)\n    }\n    const tx = this.transform ? this.transform(entry) || entry : entry\n    if (tx !== entry) {\n      tx.on('error', er => this[ONERROR](er, entry))\n      entry.pipe(tx)\n    }\n\n    tx.on('data', chunk => {\n      try {\n        fs.writeSync(fd, chunk, 0, chunk.length)\n      } catch (er) {\n        oner(er)\n      }\n    })\n\n    tx.on('end', _ => {\n      let er = null\n      // try both, falling futimes back to utimes\n      // if either fails, handle the first error\n      if (entry.mtime && !this.noMtime) {\n        const atime = entry.atime || new Date()\n        const mtime = entry.mtime\n        try {\n          fs.futimesSync(fd, atime, mtime)\n        } catch (futimeser) {\n          try {\n            fs.utimesSync(entry.absolute, atime, mtime)\n          } catch (utimeser) {\n            er = futimeser\n          }\n        }\n      }\n\n      if (this[DOCHOWN](entry)) {\n        const uid = this[UID](entry)\n        const gid = this[GID](entry)\n\n        try {\n          fs.fchownSync(fd, uid, gid)\n        } catch (fchowner) {\n          try {\n            fs.chownSync(entry.absolute, uid, gid)\n          } catch (chowner) {\n            er = er || fchowner\n          }\n        }\n      }\n\n      oner(er)\n    })\n  }\n\n  [DIRECTORY] (entry, done) {\n    const mode = entry.mode & 0o7777 || this.dmode\n    const er = this[MKDIR](entry.absolute, mode)\n    if (er) {\n      this[ONERROR](er, entry)\n      done()\n      return\n    }\n    if (entry.mtime && !this.noMtime) {\n      try {\n        fs.utimesSync(entry.absolute, entry.atime || new Date(), entry.mtime)\n      } catch (er) {}\n    }\n    if (this[DOCHOWN](entry)) {\n      try {\n        fs.chownSync(entry.absolute, this[UID](entry), this[GID](entry))\n      } catch (er) {}\n    }\n    done()\n    entry.resume()\n  }\n\n  [MKDIR] (dir, mode) {\n    try {\n      return mkdir.sync(normPath(dir), {\n        uid: this.uid,\n        gid: this.gid,\n        processUid: this.processUid,\n        processGid: this.processGid,\n        umask: this.processUmask,\n        preserve: this.preservePaths,\n        unlink: this.unlink,\n        cache: this.dirCache,\n        cwd: this.cwd,\n        mode: mode,\n      })\n    } catch (er) {\n      return er\n    }\n  }\n\n  [LINK] (entry, linkpath, link, done) {\n    try {\n      fs[link + 'Sync'](linkpath, entry.absolute)\n      done()\n      entry.resume()\n    } catch (er) {\n      return this[ONERROR](er, entry)\n    }\n  }\n}\n\nUnpack.Sync = UnpackSync\nmodule.exports = Unpack\n","'use strict'\n\n// tar -u\n\nconst hlo = require('./high-level-opt.js')\nconst r = require('./replace.js')\n// just call tar.r with the filter and mtimeCache\n\nmodule.exports = (opt_, files, cb) => {\n  const opt = hlo(opt_)\n\n  if (!opt.file)\n    throw new TypeError('file is required')\n\n  if (opt.gzip)\n    throw new TypeError('cannot append to compressed archives')\n\n  if (!files || !Array.isArray(files) || !files.length)\n    throw new TypeError('no files or directories specified')\n\n  files = Array.from(files)\n\n  mtimeFilter(opt)\n  return r(opt, files, cb)\n}\n\nconst mtimeFilter = opt => {\n  const filter = opt.filter\n\n  if (!opt.mtimeCache)\n    opt.mtimeCache = new Map()\n\n  opt.filter = filter ? (path, stat) =>\n    filter(path, stat) && !(opt.mtimeCache.get(path) > stat.mtime)\n    : (path, stat) => !(opt.mtimeCache.get(path) > stat.mtime)\n}\n","'use strict'\nmodule.exports = Base => class extends Base {\n  warn (code, message, data = {}) {\n    if (this.file)\n      data.file = this.file\n    if (this.cwd)\n      data.cwd = this.cwd\n    data.code = message instanceof Error && message.code || code\n    data.tarCode = code\n    if (!this.strict && data.recoverable !== false) {\n      if (message instanceof Error) {\n        data = Object.assign(message, data)\n        message = message.message\n      }\n      this.emit('warn', data.tarCode, message, data)\n    } else if (message instanceof Error)\n      this.emit('error', Object.assign(message, data))\n    else\n      this.emit('error', Object.assign(new Error(`${code}: ${message}`), data))\n  }\n}\n","'use strict'\n\n// When writing files on Windows, translate the characters to their\n// 0xf000 higher-encoded versions.\n\nconst raw = [\n  '|',\n  '<',\n  '>',\n  '?',\n  ':',\n]\n\nconst win = raw.map(char =>\n  String.fromCharCode(0xf000 + char.charCodeAt(0)))\n\nconst toWin = new Map(raw.map((char, i) => [char, win[i]]))\nconst toRaw = new Map(win.map((char, i) => [char, raw[i]]))\n\nmodule.exports = {\n  encode: s => raw.reduce((s, c) => s.split(c).join(toWin.get(c)), s),\n  decode: s => win.reduce((s, c) => s.split(c).join(toRaw.get(c)), s),\n}\n","'use strict'\nconst MiniPass = require('minipass')\nconst Pax = require('./pax.js')\nconst Header = require('./header.js')\nconst fs = require('fs')\nconst path = require('path')\nconst normPath = require('./normalize-windows-path.js')\nconst stripSlash = require('./strip-trailing-slashes.js')\n\nconst prefixPath = (path, prefix) => {\n  if (!prefix)\n    return normPath(path)\n  path = normPath(path).replace(/^\\.(\\/|$)/, '')\n  return stripSlash(prefix) + '/' + path\n}\n\nconst maxReadSize = 16 * 1024 * 1024\nconst PROCESS = Symbol('process')\nconst FILE = Symbol('file')\nconst DIRECTORY = Symbol('directory')\nconst SYMLINK = Symbol('symlink')\nconst HARDLINK = Symbol('hardlink')\nconst HEADER = Symbol('header')\nconst READ = Symbol('read')\nconst LSTAT = Symbol('lstat')\nconst ONLSTAT = Symbol('onlstat')\nconst ONREAD = Symbol('onread')\nconst ONREADLINK = Symbol('onreadlink')\nconst OPENFILE = Symbol('openfile')\nconst ONOPENFILE = Symbol('onopenfile')\nconst CLOSE = Symbol('close')\nconst MODE = Symbol('mode')\nconst AWAITDRAIN = Symbol('awaitDrain')\nconst ONDRAIN = Symbol('ondrain')\nconst PREFIX = Symbol('prefix')\nconst HAD_ERROR = Symbol('hadError')\nconst warner = require('./warn-mixin.js')\nconst winchars = require('./winchars.js')\nconst stripAbsolutePath = require('./strip-absolute-path.js')\n\nconst modeFix = require('./mode-fix.js')\n\nconst WriteEntry = warner(class WriteEntry extends MiniPass {\n  constructor (p, opt) {\n    opt = opt || {}\n    super(opt)\n    if (typeof p !== 'string')\n      throw new TypeError('path is required')\n    this.path = normPath(p)\n    // suppress atime, ctime, uid, gid, uname, gname\n    this.portable = !!opt.portable\n    // until node has builtin pwnam functions, this'll have to do\n    this.myuid = process.getuid && process.getuid() || 0\n    this.myuser = process.env.USER || ''\n    this.maxReadSize = opt.maxReadSize || maxReadSize\n    this.linkCache = opt.linkCache || new Map()\n    this.statCache = opt.statCache || new Map()\n    this.preservePaths = !!opt.preservePaths\n    this.cwd = normPath(opt.cwd || process.cwd())\n    this.strict = !!opt.strict\n    this.noPax = !!opt.noPax\n    this.noMtime = !!opt.noMtime\n    this.mtime = opt.mtime || null\n    this.prefix = opt.prefix ? normPath(opt.prefix) : null\n\n    this.fd = null\n    this.blockLen = null\n    this.blockRemain = null\n    this.buf = null\n    this.offset = null\n    this.length = null\n    this.pos = null\n    this.remain = null\n\n    if (typeof opt.onwarn === 'function')\n      this.on('warn', opt.onwarn)\n\n    let pathWarn = false\n    if (!this.preservePaths) {\n      const [root, stripped] = stripAbsolutePath(this.path)\n      if (root) {\n        this.path = stripped\n        pathWarn = root\n      }\n    }\n\n    this.win32 = !!opt.win32 || process.platform === 'win32'\n    if (this.win32) {\n      // force the \\ to / normalization, since we might not *actually*\n      // be on windows, but want \\ to be considered a path separator.\n      this.path = winchars.decode(this.path.replace(/\\\\/g, '/'))\n      p = p.replace(/\\\\/g, '/')\n    }\n\n    this.absolute = normPath(opt.absolute || path.resolve(this.cwd, p))\n\n    if (this.path === '')\n      this.path = './'\n\n    if (pathWarn) {\n      this.warn('TAR_ENTRY_INFO', `stripping ${pathWarn} from absolute path`, {\n        entry: this,\n        path: pathWarn + this.path,\n      })\n    }\n\n    if (this.statCache.has(this.absolute))\n      this[ONLSTAT](this.statCache.get(this.absolute))\n    else\n      this[LSTAT]()\n  }\n\n  emit (ev, ...data) {\n    if (ev === 'error')\n      this[HAD_ERROR] = true\n    return super.emit(ev, ...data)\n  }\n\n  [LSTAT] () {\n    fs.lstat(this.absolute, (er, stat) => {\n      if (er)\n        return this.emit('error', er)\n      this[ONLSTAT](stat)\n    })\n  }\n\n  [ONLSTAT] (stat) {\n    this.statCache.set(this.absolute, stat)\n    this.stat = stat\n    if (!stat.isFile())\n      stat.size = 0\n    this.type = getType(stat)\n    this.emit('stat', stat)\n    this[PROCESS]()\n  }\n\n  [PROCESS] () {\n    switch (this.type) {\n      case 'File': return this[FILE]()\n      case 'Directory': return this[DIRECTORY]()\n      case 'SymbolicLink': return this[SYMLINK]()\n      // unsupported types are ignored.\n      default: return this.end()\n    }\n  }\n\n  [MODE] (mode) {\n    return modeFix(mode, this.type === 'Directory', this.portable)\n  }\n\n  [PREFIX] (path) {\n    return prefixPath(path, this.prefix)\n  }\n\n  [HEADER] () {\n    if (this.type === 'Directory' && this.portable)\n      this.noMtime = true\n\n    this.header = new Header({\n      path: this[PREFIX](this.path),\n      // only apply the prefix to hard links.\n      linkpath: this.type === 'Link' ? this[PREFIX](this.linkpath)\n      : this.linkpath,\n      // only the permissions and setuid/setgid/sticky bitflags\n      // not the higher-order bits that specify file type\n      mode: this[MODE](this.stat.mode),\n      uid: this.portable ? null : this.stat.uid,\n      gid: this.portable ? null : this.stat.gid,\n      size: this.stat.size,\n      mtime: this.noMtime ? null : this.mtime || this.stat.mtime,\n      type: this.type,\n      uname: this.portable ? null :\n      this.stat.uid === this.myuid ? this.myuser : '',\n      atime: this.portable ? null : this.stat.atime,\n      ctime: this.portable ? null : this.stat.ctime,\n    })\n\n    if (this.header.encode() && !this.noPax) {\n      super.write(new Pax({\n        atime: this.portable ? null : this.header.atime,\n        ctime: this.portable ? null : this.header.ctime,\n        gid: this.portable ? null : this.header.gid,\n        mtime: this.noMtime ? null : this.mtime || this.header.mtime,\n        path: this[PREFIX](this.path),\n        linkpath: this.type === 'Link' ? this[PREFIX](this.linkpath)\n        : this.linkpath,\n        size: this.header.size,\n        uid: this.portable ? null : this.header.uid,\n        uname: this.portable ? null : this.header.uname,\n        dev: this.portable ? null : this.stat.dev,\n        ino: this.portable ? null : this.stat.ino,\n        nlink: this.portable ? null : this.stat.nlink,\n      }).encode())\n    }\n    super.write(this.header.block)\n  }\n\n  [DIRECTORY] () {\n    if (this.path.substr(-1) !== '/')\n      this.path += '/'\n    this.stat.size = 0\n    this[HEADER]()\n    this.end()\n  }\n\n  [SYMLINK] () {\n    fs.readlink(this.absolute, (er, linkpath) => {\n      if (er)\n        return this.emit('error', er)\n      this[ONREADLINK](linkpath)\n    })\n  }\n\n  [ONREADLINK] (linkpath) {\n    this.linkpath = normPath(linkpath)\n    this[HEADER]()\n    this.end()\n  }\n\n  [HARDLINK] (linkpath) {\n    this.type = 'Link'\n    this.linkpath = normPath(path.relative(this.cwd, linkpath))\n    this.stat.size = 0\n    this[HEADER]()\n    this.end()\n  }\n\n  [FILE] () {\n    if (this.stat.nlink > 1) {\n      const linkKey = this.stat.dev + ':' + this.stat.ino\n      if (this.linkCache.has(linkKey)) {\n        const linkpath = this.linkCache.get(linkKey)\n        if (linkpath.indexOf(this.cwd) === 0)\n          return this[HARDLINK](linkpath)\n      }\n      this.linkCache.set(linkKey, this.absolute)\n    }\n\n    this[HEADER]()\n    if (this.stat.size === 0)\n      return this.end()\n\n    this[OPENFILE]()\n  }\n\n  [OPENFILE] () {\n    fs.open(this.absolute, 'r', (er, fd) => {\n      if (er)\n        return this.emit('error', er)\n      this[ONOPENFILE](fd)\n    })\n  }\n\n  [ONOPENFILE] (fd) {\n    this.fd = fd\n    if (this[HAD_ERROR])\n      return this[CLOSE]()\n\n    this.blockLen = 512 * Math.ceil(this.stat.size / 512)\n    this.blockRemain = this.blockLen\n    const bufLen = Math.min(this.blockLen, this.maxReadSize)\n    this.buf = Buffer.allocUnsafe(bufLen)\n    this.offset = 0\n    this.pos = 0\n    this.remain = this.stat.size\n    this.length = this.buf.length\n    this[READ]()\n  }\n\n  [READ] () {\n    const { fd, buf, offset, length, pos } = this\n    fs.read(fd, buf, offset, length, pos, (er, bytesRead) => {\n      if (er) {\n        // ignoring the error from close(2) is a bad practice, but at\n        // this point we already have an error, don't need another one\n        return this[CLOSE](() => this.emit('error', er))\n      }\n      this[ONREAD](bytesRead)\n    })\n  }\n\n  [CLOSE] (cb) {\n    fs.close(this.fd, cb)\n  }\n\n  [ONREAD] (bytesRead) {\n    if (bytesRead <= 0 && this.remain > 0) {\n      const er = new Error('encountered unexpected EOF')\n      er.path = this.absolute\n      er.syscall = 'read'\n      er.code = 'EOF'\n      return this[CLOSE](() => this.emit('error', er))\n    }\n\n    if (bytesRead > this.remain) {\n      const er = new Error('did not encounter expected EOF')\n      er.path = this.absolute\n      er.syscall = 'read'\n      er.code = 'EOF'\n      return this[CLOSE](() => this.emit('error', er))\n    }\n\n    // null out the rest of the buffer, if we could fit the block padding\n    // at the end of this loop, we've incremented bytesRead and this.remain\n    // to be incremented up to the blockRemain level, as if we had expected\n    // to get a null-padded file, and read it until the end.  then we will\n    // decrement both remain and blockRemain by bytesRead, and know that we\n    // reached the expected EOF, without any null buffer to append.\n    if (bytesRead === this.remain) {\n      for (let i = bytesRead; i < this.length && bytesRead < this.blockRemain; i++) {\n        this.buf[i + this.offset] = 0\n        bytesRead++\n        this.remain++\n      }\n    }\n\n    const writeBuf = this.offset === 0 && bytesRead === this.buf.length ?\n      this.buf : this.buf.slice(this.offset, this.offset + bytesRead)\n\n    const flushed = this.write(writeBuf)\n    if (!flushed)\n      this[AWAITDRAIN](() => this[ONDRAIN]())\n    else\n      this[ONDRAIN]()\n  }\n\n  [AWAITDRAIN] (cb) {\n    this.once('drain', cb)\n  }\n\n  write (writeBuf) {\n    if (this.blockRemain < writeBuf.length) {\n      const er = new Error('writing more data than expected')\n      er.path = this.absolute\n      return this.emit('error', er)\n    }\n    this.remain -= writeBuf.length\n    this.blockRemain -= writeBuf.length\n    this.pos += writeBuf.length\n    this.offset += writeBuf.length\n    return super.write(writeBuf)\n  }\n\n  [ONDRAIN] () {\n    if (!this.remain) {\n      if (this.blockRemain)\n        super.write(Buffer.alloc(this.blockRemain))\n      return this[CLOSE](er => er ? this.emit('error', er) : this.end())\n    }\n\n    if (this.offset >= this.length) {\n      // if we only have a smaller bit left to read, alloc a smaller buffer\n      // otherwise, keep it the same length it was before.\n      this.buf = Buffer.allocUnsafe(Math.min(this.blockRemain, this.buf.length))\n      this.offset = 0\n    }\n    this.length = this.buf.length - this.offset\n    this[READ]()\n  }\n})\n\nclass WriteEntrySync extends WriteEntry {\n  [LSTAT] () {\n    this[ONLSTAT](fs.lstatSync(this.absolute))\n  }\n\n  [SYMLINK] () {\n    this[ONREADLINK](fs.readlinkSync(this.absolute))\n  }\n\n  [OPENFILE] () {\n    this[ONOPENFILE](fs.openSync(this.absolute, 'r'))\n  }\n\n  [READ] () {\n    let threw = true\n    try {\n      const { fd, buf, offset, length, pos } = this\n      const bytesRead = fs.readSync(fd, buf, offset, length, pos)\n      this[ONREAD](bytesRead)\n      threw = false\n    } finally {\n      // ignoring the error from close(2) is a bad practice, but at\n      // this point we already have an error, don't need another one\n      if (threw) {\n        try {\n          this[CLOSE](() => {})\n        } catch (er) {}\n      }\n    }\n  }\n\n  [AWAITDRAIN] (cb) {\n    cb()\n  }\n\n  [CLOSE] (cb) {\n    fs.closeSync(this.fd)\n    cb()\n  }\n}\n\nconst WriteEntryTar = warner(class WriteEntryTar extends MiniPass {\n  constructor (readEntry, opt) {\n    opt = opt || {}\n    super(opt)\n    this.preservePaths = !!opt.preservePaths\n    this.portable = !!opt.portable\n    this.strict = !!opt.strict\n    this.noPax = !!opt.noPax\n    this.noMtime = !!opt.noMtime\n\n    this.readEntry = readEntry\n    this.type = readEntry.type\n    if (this.type === 'Directory' && this.portable)\n      this.noMtime = true\n\n    this.prefix = opt.prefix || null\n\n    this.path = normPath(readEntry.path)\n    this.mode = this[MODE](readEntry.mode)\n    this.uid = this.portable ? null : readEntry.uid\n    this.gid = this.portable ? null : readEntry.gid\n    this.uname = this.portable ? null : readEntry.uname\n    this.gname = this.portable ? null : readEntry.gname\n    this.size = readEntry.size\n    this.mtime = this.noMtime ? null : opt.mtime || readEntry.mtime\n    this.atime = this.portable ? null : readEntry.atime\n    this.ctime = this.portable ? null : readEntry.ctime\n    this.linkpath = normPath(readEntry.linkpath)\n\n    if (typeof opt.onwarn === 'function')\n      this.on('warn', opt.onwarn)\n\n    let pathWarn = false\n    if (!this.preservePaths) {\n      const [root, stripped] = stripAbsolutePath(this.path)\n      if (root) {\n        this.path = stripped\n        pathWarn = root\n      }\n    }\n\n    this.remain = readEntry.size\n    this.blockRemain = readEntry.startBlockSize\n\n    this.header = new Header({\n      path: this[PREFIX](this.path),\n      linkpath: this.type === 'Link' ? this[PREFIX](this.linkpath)\n      : this.linkpath,\n      // only the permissions and setuid/setgid/sticky bitflags\n      // not the higher-order bits that specify file type\n      mode: this.mode,\n      uid: this.portable ? null : this.uid,\n      gid: this.portable ? null : this.gid,\n      size: this.size,\n      mtime: this.noMtime ? null : this.mtime,\n      type: this.type,\n      uname: this.portable ? null : this.uname,\n      atime: this.portable ? null : this.atime,\n      ctime: this.portable ? null : this.ctime,\n    })\n\n    if (pathWarn) {\n      this.warn('TAR_ENTRY_INFO', `stripping ${pathWarn} from absolute path`, {\n        entry: this,\n        path: pathWarn + this.path,\n      })\n    }\n\n    if (this.header.encode() && !this.noPax) {\n      super.write(new Pax({\n        atime: this.portable ? null : this.atime,\n        ctime: this.portable ? null : this.ctime,\n        gid: this.portable ? null : this.gid,\n        mtime: this.noMtime ? null : this.mtime,\n        path: this[PREFIX](this.path),\n        linkpath: this.type === 'Link' ? this[PREFIX](this.linkpath)\n        : this.linkpath,\n        size: this.size,\n        uid: this.portable ? null : this.uid,\n        uname: this.portable ? null : this.uname,\n        dev: this.portable ? null : this.readEntry.dev,\n        ino: this.portable ? null : this.readEntry.ino,\n        nlink: this.portable ? null : this.readEntry.nlink,\n      }).encode())\n    }\n\n    super.write(this.header.block)\n    readEntry.pipe(this)\n  }\n\n  [PREFIX] (path) {\n    return prefixPath(path, this.prefix)\n  }\n\n  [MODE] (mode) {\n    return modeFix(mode, this.type === 'Directory', this.portable)\n  }\n\n  write (data) {\n    const writeLen = data.length\n    if (writeLen > this.blockRemain)\n      throw new Error('writing more to entry than is appropriate')\n    this.blockRemain -= writeLen\n    return super.write(data)\n  }\n\n  end () {\n    if (this.blockRemain)\n      super.write(Buffer.alloc(this.blockRemain))\n    return super.end()\n  }\n})\n\nWriteEntry.Sync = WriteEntrySync\nWriteEntry.Tar = WriteEntryTar\n\nconst getType = stat =>\n  stat.isFile() ? 'File'\n  : stat.isDirectory() ? 'Directory'\n  : stat.isSymbolicLink() ? 'SymbolicLink'\n  : 'Unsupported'\n\nmodule.exports = WriteEntry\n","module.exports = require('./lib/tunnel');\n","'use strict';\n\nvar net = require('net');\nvar tls = require('tls');\nvar http = require('http');\nvar https = require('https');\nvar events = require('events');\nvar assert = require('assert');\nvar util = require('util');\n\n\nexports.httpOverHttp = httpOverHttp;\nexports.httpsOverHttp = httpsOverHttp;\nexports.httpOverHttps = httpOverHttps;\nexports.httpsOverHttps = httpsOverHttps;\n\n\nfunction httpOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  return agent;\n}\n\nfunction httpsOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\nfunction httpOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  return agent;\n}\n\nfunction httpsOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\n\nfunction TunnelingAgent(options) {\n  var self = this;\n  self.options = options || {};\n  self.proxyOptions = self.options.proxy || {};\n  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets;\n  self.requests = [];\n  self.sockets = [];\n\n  self.on('free', function onFree(socket, host, port, localAddress) {\n    var options = toOptions(host, port, localAddress);\n    for (var i = 0, len = self.requests.length; i < len; ++i) {\n      var pending = self.requests[i];\n      if (pending.host === options.host && pending.port === options.port) {\n        // Detect the request to connect same origin server,\n        // reuse the connection.\n        self.requests.splice(i, 1);\n        pending.request.onSocket(socket);\n        return;\n      }\n    }\n    socket.destroy();\n    self.removeSocket(socket);\n  });\n}\nutil.inherits(TunnelingAgent, events.EventEmitter);\n\nTunnelingAgent.prototype.addRequest = function addRequest(req, host, port, localAddress) {\n  var self = this;\n  var options = mergeOptions({request: req}, self.options, toOptions(host, port, localAddress));\n\n  if (self.sockets.length >= this.maxSockets) {\n    // We are over limit so we'll add it to the queue.\n    self.requests.push(options);\n    return;\n  }\n\n  // If we are under maxSockets create a new one.\n  self.createSocket(options, function(socket) {\n    socket.on('free', onFree);\n    socket.on('close', onCloseOrRemove);\n    socket.on('agentRemove', onCloseOrRemove);\n    req.onSocket(socket);\n\n    function onFree() {\n      self.emit('free', socket, options);\n    }\n\n    function onCloseOrRemove(err) {\n      self.removeSocket(socket);\n      socket.removeListener('free', onFree);\n      socket.removeListener('close', onCloseOrRemove);\n      socket.removeListener('agentRemove', onCloseOrRemove);\n    }\n  });\n};\n\nTunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\n  var self = this;\n  var placeholder = {};\n  self.sockets.push(placeholder);\n\n  var connectOptions = mergeOptions({}, self.proxyOptions, {\n    method: 'CONNECT',\n    path: options.host + ':' + options.port,\n    agent: false,\n    headers: {\n      host: options.host + ':' + options.port\n    }\n  });\n  if (options.localAddress) {\n    connectOptions.localAddress = options.localAddress;\n  }\n  if (connectOptions.proxyAuth) {\n    connectOptions.headers = connectOptions.headers || {};\n    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\n        new Buffer(connectOptions.proxyAuth).toString('base64');\n  }\n\n  debug('making CONNECT request');\n  var connectReq = self.request(connectOptions);\n  connectReq.useChunkedEncodingByDefault = false; // for v0.6\n  connectReq.once('response', onResponse); // for v0.6\n  connectReq.once('upgrade', onUpgrade);   // for v0.6\n  connectReq.once('connect', onConnect);   // for v0.7 or later\n  connectReq.once('error', onError);\n  connectReq.end();\n\n  function onResponse(res) {\n    // Very hacky. This is necessary to avoid http-parser leaks.\n    res.upgrade = true;\n  }\n\n  function onUpgrade(res, socket, head) {\n    // Hacky.\n    process.nextTick(function() {\n      onConnect(res, socket, head);\n    });\n  }\n\n  function onConnect(res, socket, head) {\n    connectReq.removeAllListeners();\n    socket.removeAllListeners();\n\n    if (res.statusCode !== 200) {\n      debug('tunneling socket could not be established, statusCode=%d',\n        res.statusCode);\n      socket.destroy();\n      var error = new Error('tunneling socket could not be established, ' +\n        'statusCode=' + res.statusCode);\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    if (head.length > 0) {\n      debug('got illegal response body from proxy');\n      socket.destroy();\n      var error = new Error('got illegal response body from proxy');\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    debug('tunneling connection has established');\n    self.sockets[self.sockets.indexOf(placeholder)] = socket;\n    return cb(socket);\n  }\n\n  function onError(cause) {\n    connectReq.removeAllListeners();\n\n    debug('tunneling socket could not be established, cause=%s\\n',\n          cause.message, cause.stack);\n    var error = new Error('tunneling socket could not be established, ' +\n                          'cause=' + cause.message);\n    error.code = 'ECONNRESET';\n    options.request.emit('error', error);\n    self.removeSocket(placeholder);\n  }\n};\n\nTunnelingAgent.prototype.removeSocket = function removeSocket(socket) {\n  var pos = this.sockets.indexOf(socket)\n  if (pos === -1) {\n    return;\n  }\n  this.sockets.splice(pos, 1);\n\n  var pending = this.requests.shift();\n  if (pending) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(pending, function(socket) {\n      pending.request.onSocket(socket);\n    });\n  }\n};\n\nfunction createSecureSocket(options, cb) {\n  var self = this;\n  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {\n    var hostHeader = options.request.getHeader('host');\n    var tlsOptions = mergeOptions({}, self.options, {\n      socket: socket,\n      servername: hostHeader ? hostHeader.replace(/:.*$/, '') : options.host\n    });\n\n    // 0 is dummy port for v0.6\n    var secureSocket = tls.connect(0, tlsOptions);\n    self.sockets[self.sockets.indexOf(socket)] = secureSocket;\n    cb(secureSocket);\n  });\n}\n\n\nfunction toOptions(host, port, localAddress) {\n  if (typeof host === 'string') { // since v0.10\n    return {\n      host: host,\n      port: port,\n      localAddress: localAddress\n    };\n  }\n  return host; // for v0.11 or later\n}\n\nfunction mergeOptions(target) {\n  for (var i = 1, len = arguments.length; i < len; ++i) {\n    var overrides = arguments[i];\n    if (typeof overrides === 'object') {\n      var keys = Object.keys(overrides);\n      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {\n        var k = keys[j];\n        if (overrides[k] !== undefined) {\n          target[k] = overrides[k];\n        }\n      }\n    }\n  }\n  return target;\n}\n\n\nvar debug;\nif (process.env.NODE_DEBUG && /\\btunnel\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    var args = Array.prototype.slice.call(arguments);\n    if (typeof args[0] === 'string') {\n      args[0] = 'TUNNEL: ' + args[0];\n    } else {\n      args.unshift('TUNNEL:');\n    }\n    console.error.apply(console, args);\n  }\n} else {\n  debug = function() {};\n}\nexports.debug = debug; // for test\n","/**\n * web-streams-polyfill v3.2.0\n */\n(function (global, factory) {\n    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :\n    typeof define === 'function' && define.amd ? define(['exports'], factory) :\n    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, factory(global.WebStreamsPolyfill = {}));\n}(this, (function (exports) { 'use strict';\n\n    /// <reference lib=\"es2015.symbol\" />\n    const SymbolPolyfill = typeof Symbol === 'function' && typeof Symbol.iterator === 'symbol' ?\n        Symbol :\n        description => `Symbol(${description})`;\n\n    /// <reference lib=\"dom\" />\n    function noop() {\n        return undefined;\n    }\n    function getGlobals() {\n        if (typeof self !== 'undefined') {\n            return self;\n        }\n        else if (typeof window !== 'undefined') {\n            return window;\n        }\n        else if (typeof global !== 'undefined') {\n            return global;\n        }\n        return undefined;\n    }\n    const globals = getGlobals();\n\n    function typeIsObject(x) {\n        return (typeof x === 'object' && x !== null) || typeof x === 'function';\n    }\n    const rethrowAssertionErrorRejection = noop;\n\n    const originalPromise = Promise;\n    const originalPromiseThen = Promise.prototype.then;\n    const originalPromiseResolve = Promise.resolve.bind(originalPromise);\n    const originalPromiseReject = Promise.reject.bind(originalPromise);\n    function newPromise(executor) {\n        return new originalPromise(executor);\n    }\n    function promiseResolvedWith(value) {\n        return originalPromiseResolve(value);\n    }\n    function promiseRejectedWith(reason) {\n        return originalPromiseReject(reason);\n    }\n    function PerformPromiseThen(promise, onFulfilled, onRejected) {\n        // There doesn't appear to be any way to correctly emulate the behaviour from JavaScript, so this is just an\n        // approximation.\n        return originalPromiseThen.call(promise, onFulfilled, onRejected);\n    }\n    function uponPromise(promise, onFulfilled, onRejected) {\n        PerformPromiseThen(PerformPromiseThen(promise, onFulfilled, onRejected), undefined, rethrowAssertionErrorRejection);\n    }\n    function uponFulfillment(promise, onFulfilled) {\n        uponPromise(promise, onFulfilled);\n    }\n    function uponRejection(promise, onRejected) {\n        uponPromise(promise, undefined, onRejected);\n    }\n    function transformPromiseWith(promise, fulfillmentHandler, rejectionHandler) {\n        return PerformPromiseThen(promise, fulfillmentHandler, rejectionHandler);\n    }\n    function setPromiseIsHandledToTrue(promise) {\n        PerformPromiseThen(promise, undefined, rethrowAssertionErrorRejection);\n    }\n    const queueMicrotask = (() => {\n        const globalQueueMicrotask = globals && globals.queueMicrotask;\n        if (typeof globalQueueMicrotask === 'function') {\n            return globalQueueMicrotask;\n        }\n        const resolvedPromise = promiseResolvedWith(undefined);\n        return (fn) => PerformPromiseThen(resolvedPromise, fn);\n    })();\n    function reflectCall(F, V, args) {\n        if (typeof F !== 'function') {\n            throw new TypeError('Argument is not a function');\n        }\n        return Function.prototype.apply.call(F, V, args);\n    }\n    function promiseCall(F, V, args) {\n        try {\n            return promiseResolvedWith(reflectCall(F, V, args));\n        }\n        catch (value) {\n            return promiseRejectedWith(value);\n        }\n    }\n\n    // Original from Chromium\n    // https://chromium.googlesource.com/chromium/src/+/0aee4434a4dba42a42abaea9bfbc0cd196a63bc1/third_party/blink/renderer/core/streams/SimpleQueue.js\n    const QUEUE_MAX_ARRAY_SIZE = 16384;\n    /**\n     * Simple queue structure.\n     *\n     * Avoids scalability issues with using a packed array directly by using\n     * multiple arrays in a linked list and keeping the array size bounded.\n     */\n    class SimpleQueue {\n        constructor() {\n            this._cursor = 0;\n            this._size = 0;\n            // _front and _back are always defined.\n            this._front = {\n                _elements: [],\n                _next: undefined\n            };\n            this._back = this._front;\n            // The cursor is used to avoid calling Array.shift().\n            // It contains the index of the front element of the array inside the\n            // front-most node. It is always in the range [0, QUEUE_MAX_ARRAY_SIZE).\n            this._cursor = 0;\n            // When there is only one node, size === elements.length - cursor.\n            this._size = 0;\n        }\n        get length() {\n            return this._size;\n        }\n        // For exception safety, this method is structured in order:\n        // 1. Read state\n        // 2. Calculate required state mutations\n        // 3. Perform state mutations\n        push(element) {\n            const oldBack = this._back;\n            let newBack = oldBack;\n            if (oldBack._elements.length === QUEUE_MAX_ARRAY_SIZE - 1) {\n                newBack = {\n                    _elements: [],\n                    _next: undefined\n                };\n            }\n            // push() is the mutation most likely to throw an exception, so it\n            // goes first.\n            oldBack._elements.push(element);\n            if (newBack !== oldBack) {\n                this._back = newBack;\n                oldBack._next = newBack;\n            }\n            ++this._size;\n        }\n        // Like push(), shift() follows the read -> calculate -> mutate pattern for\n        // exception safety.\n        shift() { // must not be called on an empty queue\n            const oldFront = this._front;\n            let newFront = oldFront;\n            const oldCursor = this._cursor;\n            let newCursor = oldCursor + 1;\n            const elements = oldFront._elements;\n            const element = elements[oldCursor];\n            if (newCursor === QUEUE_MAX_ARRAY_SIZE) {\n                newFront = oldFront._next;\n                newCursor = 0;\n            }\n            // No mutations before this point.\n            --this._size;\n            this._cursor = newCursor;\n            if (oldFront !== newFront) {\n                this._front = newFront;\n            }\n            // Permit shifted element to be garbage collected.\n            elements[oldCursor] = undefined;\n            return element;\n        }\n        // The tricky thing about forEach() is that it can be called\n        // re-entrantly. The queue may be mutated inside the callback. It is easy to\n        // see that push() within the callback has no negative effects since the end\n        // of the queue is checked for on every iteration. If shift() is called\n        // repeatedly within the callback then the next iteration may return an\n        // element that has been removed. In this case the callback will be called\n        // with undefined values until we either \"catch up\" with elements that still\n        // exist or reach the back of the queue.\n        forEach(callback) {\n            let i = this._cursor;\n            let node = this._front;\n            let elements = node._elements;\n            while (i !== elements.length || node._next !== undefined) {\n                if (i === elements.length) {\n                    node = node._next;\n                    elements = node._elements;\n                    i = 0;\n                    if (elements.length === 0) {\n                        break;\n                    }\n                }\n                callback(elements[i]);\n                ++i;\n            }\n        }\n        // Return the element that would be returned if shift() was called now,\n        // without modifying the queue.\n        peek() { // must not be called on an empty queue\n            const front = this._front;\n            const cursor = this._cursor;\n            return front._elements[cursor];\n        }\n    }\n\n    function ReadableStreamReaderGenericInitialize(reader, stream) {\n        reader._ownerReadableStream = stream;\n        stream._reader = reader;\n        if (stream._state === 'readable') {\n            defaultReaderClosedPromiseInitialize(reader);\n        }\n        else if (stream._state === 'closed') {\n            defaultReaderClosedPromiseInitializeAsResolved(reader);\n        }\n        else {\n            defaultReaderClosedPromiseInitializeAsRejected(reader, stream._storedError);\n        }\n    }\n    // A client of ReadableStreamDefaultReader and ReadableStreamBYOBReader may use these functions directly to bypass state\n    // check.\n    function ReadableStreamReaderGenericCancel(reader, reason) {\n        const stream = reader._ownerReadableStream;\n        return ReadableStreamCancel(stream, reason);\n    }\n    function ReadableStreamReaderGenericRelease(reader) {\n        if (reader._ownerReadableStream._state === 'readable') {\n            defaultReaderClosedPromiseReject(reader, new TypeError(`Reader was released and can no longer be used to monitor the stream's closedness`));\n        }\n        else {\n            defaultReaderClosedPromiseResetToRejected(reader, new TypeError(`Reader was released and can no longer be used to monitor the stream's closedness`));\n        }\n        reader._ownerReadableStream._reader = undefined;\n        reader._ownerReadableStream = undefined;\n    }\n    // Helper functions for the readers.\n    function readerLockException(name) {\n        return new TypeError('Cannot ' + name + ' a stream using a released reader');\n    }\n    // Helper functions for the ReadableStreamDefaultReader.\n    function defaultReaderClosedPromiseInitialize(reader) {\n        reader._closedPromise = newPromise((resolve, reject) => {\n            reader._closedPromise_resolve = resolve;\n            reader._closedPromise_reject = reject;\n        });\n    }\n    function defaultReaderClosedPromiseInitializeAsRejected(reader, reason) {\n        defaultReaderClosedPromiseInitialize(reader);\n        defaultReaderClosedPromiseReject(reader, reason);\n    }\n    function defaultReaderClosedPromiseInitializeAsResolved(reader) {\n        defaultReaderClosedPromiseInitialize(reader);\n        defaultReaderClosedPromiseResolve(reader);\n    }\n    function defaultReaderClosedPromiseReject(reader, reason) {\n        if (reader._closedPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(reader._closedPromise);\n        reader._closedPromise_reject(reason);\n        reader._closedPromise_resolve = undefined;\n        reader._closedPromise_reject = undefined;\n    }\n    function defaultReaderClosedPromiseResetToRejected(reader, reason) {\n        defaultReaderClosedPromiseInitializeAsRejected(reader, reason);\n    }\n    function defaultReaderClosedPromiseResolve(reader) {\n        if (reader._closedPromise_resolve === undefined) {\n            return;\n        }\n        reader._closedPromise_resolve(undefined);\n        reader._closedPromise_resolve = undefined;\n        reader._closedPromise_reject = undefined;\n    }\n\n    const AbortSteps = SymbolPolyfill('[[AbortSteps]]');\n    const ErrorSteps = SymbolPolyfill('[[ErrorSteps]]');\n    const CancelSteps = SymbolPolyfill('[[CancelSteps]]');\n    const PullSteps = SymbolPolyfill('[[PullSteps]]');\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isFinite#Polyfill\n    const NumberIsFinite = Number.isFinite || function (x) {\n        return typeof x === 'number' && isFinite(x);\n    };\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/trunc#Polyfill\n    const MathTrunc = Math.trunc || function (v) {\n        return v < 0 ? Math.ceil(v) : Math.floor(v);\n    };\n\n    // https://heycam.github.io/webidl/#idl-dictionaries\n    function isDictionary(x) {\n        return typeof x === 'object' || typeof x === 'function';\n    }\n    function assertDictionary(obj, context) {\n        if (obj !== undefined && !isDictionary(obj)) {\n            throw new TypeError(`${context} is not an object.`);\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-callback-functions\n    function assertFunction(x, context) {\n        if (typeof x !== 'function') {\n            throw new TypeError(`${context} is not a function.`);\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-object\n    function isObject(x) {\n        return (typeof x === 'object' && x !== null) || typeof x === 'function';\n    }\n    function assertObject(x, context) {\n        if (!isObject(x)) {\n            throw new TypeError(`${context} is not an object.`);\n        }\n    }\n    function assertRequiredArgument(x, position, context) {\n        if (x === undefined) {\n            throw new TypeError(`Parameter ${position} is required in '${context}'.`);\n        }\n    }\n    function assertRequiredField(x, field, context) {\n        if (x === undefined) {\n            throw new TypeError(`${field} is required in '${context}'.`);\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-unrestricted-double\n    function convertUnrestrictedDouble(value) {\n        return Number(value);\n    }\n    function censorNegativeZero(x) {\n        return x === 0 ? 0 : x;\n    }\n    function integerPart(x) {\n        return censorNegativeZero(MathTrunc(x));\n    }\n    // https://heycam.github.io/webidl/#idl-unsigned-long-long\n    function convertUnsignedLongLongWithEnforceRange(value, context) {\n        const lowerBound = 0;\n        const upperBound = Number.MAX_SAFE_INTEGER;\n        let x = Number(value);\n        x = censorNegativeZero(x);\n        if (!NumberIsFinite(x)) {\n            throw new TypeError(`${context} is not a finite number`);\n        }\n        x = integerPart(x);\n        if (x < lowerBound || x > upperBound) {\n            throw new TypeError(`${context} is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`);\n        }\n        if (!NumberIsFinite(x) || x === 0) {\n            return 0;\n        }\n        // TODO Use BigInt if supported?\n        // let xBigInt = BigInt(integerPart(x));\n        // xBigInt = BigInt.asUintN(64, xBigInt);\n        // return Number(xBigInt);\n        return x;\n    }\n\n    function assertReadableStream(x, context) {\n        if (!IsReadableStream(x)) {\n            throw new TypeError(`${context} is not a ReadableStream.`);\n        }\n    }\n\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamDefaultReader(stream) {\n        return new ReadableStreamDefaultReader(stream);\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamAddReadRequest(stream, readRequest) {\n        stream._reader._readRequests.push(readRequest);\n    }\n    function ReadableStreamFulfillReadRequest(stream, chunk, done) {\n        const reader = stream._reader;\n        const readRequest = reader._readRequests.shift();\n        if (done) {\n            readRequest._closeSteps();\n        }\n        else {\n            readRequest._chunkSteps(chunk);\n        }\n    }\n    function ReadableStreamGetNumReadRequests(stream) {\n        return stream._reader._readRequests.length;\n    }\n    function ReadableStreamHasDefaultReader(stream) {\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return false;\n        }\n        if (!IsReadableStreamDefaultReader(reader)) {\n            return false;\n        }\n        return true;\n    }\n    /**\n     * A default reader vended by a {@link ReadableStream}.\n     *\n     * @public\n     */\n    class ReadableStreamDefaultReader {\n        constructor(stream) {\n            assertRequiredArgument(stream, 1, 'ReadableStreamDefaultReader');\n            assertReadableStream(stream, 'First parameter');\n            if (IsReadableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n            }\n            ReadableStreamReaderGenericInitialize(this, stream);\n            this._readRequests = new SimpleQueue();\n        }\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed,\n         * or rejected if the stream ever errors or the reader's lock is released before the stream finishes closing.\n         */\n        get closed() {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        }\n        /**\n         * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n         */\n        cancel(reason = undefined) {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('cancel'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('cancel'));\n            }\n            return ReadableStreamReaderGenericCancel(this, reason);\n        }\n        /**\n         * Returns a promise that allows access to the next chunk from the stream's internal queue, if available.\n         *\n         * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n         */\n        read() {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('read'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('read from'));\n            }\n            let resolvePromise;\n            let rejectPromise;\n            const promise = newPromise((resolve, reject) => {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            const readRequest = {\n                _chunkSteps: chunk => resolvePromise({ value: chunk, done: false }),\n                _closeSteps: () => resolvePromise({ value: undefined, done: true }),\n                _errorSteps: e => rejectPromise(e)\n            };\n            ReadableStreamDefaultReaderRead(this, readRequest);\n            return promise;\n        }\n        /**\n         * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n         * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n         * from now on; otherwise, the reader will appear closed.\n         *\n         * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n         * the reader's {@link ReadableStreamDefaultReader.read | read()} method has not yet been settled. Attempting to\n         * do so will throw a `TypeError` and leave the reader locked to the stream.\n         */\n        releaseLock() {\n            if (!IsReadableStreamDefaultReader(this)) {\n                throw defaultReaderBrandCheckException('releaseLock');\n            }\n            if (this._ownerReadableStream === undefined) {\n                return;\n            }\n            if (this._readRequests.length > 0) {\n                throw new TypeError('Tried to release a reader lock when that reader has pending read() calls un-settled');\n            }\n            ReadableStreamReaderGenericRelease(this);\n        }\n    }\n    Object.defineProperties(ReadableStreamDefaultReader.prototype, {\n        cancel: { enumerable: true },\n        read: { enumerable: true },\n        releaseLock: { enumerable: true },\n        closed: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamDefaultReader.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamDefaultReader',\n            configurable: true\n        });\n    }\n    // Abstract operations for the readers.\n    function IsReadableStreamDefaultReader(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readRequests')) {\n            return false;\n        }\n        return x instanceof ReadableStreamDefaultReader;\n    }\n    function ReadableStreamDefaultReaderRead(reader, readRequest) {\n        const stream = reader._ownerReadableStream;\n        stream._disturbed = true;\n        if (stream._state === 'closed') {\n            readRequest._closeSteps();\n        }\n        else if (stream._state === 'errored') {\n            readRequest._errorSteps(stream._storedError);\n        }\n        else {\n            stream._readableStreamController[PullSteps](readRequest);\n        }\n    }\n    // Helper functions for the ReadableStreamDefaultReader.\n    function defaultReaderBrandCheckException(name) {\n        return new TypeError(`ReadableStreamDefaultReader.prototype.${name} can only be used on a ReadableStreamDefaultReader`);\n    }\n\n    /// <reference lib=\"es2018.asynciterable\" />\n    /* eslint-disable @typescript-eslint/no-empty-function */\n    const AsyncIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf(async function* () { }).prototype);\n\n    /// <reference lib=\"es2018.asynciterable\" />\n    class ReadableStreamAsyncIteratorImpl {\n        constructor(reader, preventCancel) {\n            this._ongoingPromise = undefined;\n            this._isFinished = false;\n            this._reader = reader;\n            this._preventCancel = preventCancel;\n        }\n        next() {\n            const nextSteps = () => this._nextSteps();\n            this._ongoingPromise = this._ongoingPromise ?\n                transformPromiseWith(this._ongoingPromise, nextSteps, nextSteps) :\n                nextSteps();\n            return this._ongoingPromise;\n        }\n        return(value) {\n            const returnSteps = () => this._returnSteps(value);\n            return this._ongoingPromise ?\n                transformPromiseWith(this._ongoingPromise, returnSteps, returnSteps) :\n                returnSteps();\n        }\n        _nextSteps() {\n            if (this._isFinished) {\n                return Promise.resolve({ value: undefined, done: true });\n            }\n            const reader = this._reader;\n            if (reader._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('iterate'));\n            }\n            let resolvePromise;\n            let rejectPromise;\n            const promise = newPromise((resolve, reject) => {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            const readRequest = {\n                _chunkSteps: chunk => {\n                    this._ongoingPromise = undefined;\n                    // This needs to be delayed by one microtask, otherwise we stop pulling too early which breaks a test.\n                    // FIXME Is this a bug in the specification, or in the test?\n                    queueMicrotask(() => resolvePromise({ value: chunk, done: false }));\n                },\n                _closeSteps: () => {\n                    this._ongoingPromise = undefined;\n                    this._isFinished = true;\n                    ReadableStreamReaderGenericRelease(reader);\n                    resolvePromise({ value: undefined, done: true });\n                },\n                _errorSteps: reason => {\n                    this._ongoingPromise = undefined;\n                    this._isFinished = true;\n                    ReadableStreamReaderGenericRelease(reader);\n                    rejectPromise(reason);\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n            return promise;\n        }\n        _returnSteps(value) {\n            if (this._isFinished) {\n                return Promise.resolve({ value, done: true });\n            }\n            this._isFinished = true;\n            const reader = this._reader;\n            if (reader._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('finish iterating'));\n            }\n            if (!this._preventCancel) {\n                const result = ReadableStreamReaderGenericCancel(reader, value);\n                ReadableStreamReaderGenericRelease(reader);\n                return transformPromiseWith(result, () => ({ value, done: true }));\n            }\n            ReadableStreamReaderGenericRelease(reader);\n            return promiseResolvedWith({ value, done: true });\n        }\n    }\n    const ReadableStreamAsyncIteratorPrototype = {\n        next() {\n            if (!IsReadableStreamAsyncIterator(this)) {\n                return promiseRejectedWith(streamAsyncIteratorBrandCheckException('next'));\n            }\n            return this._asyncIteratorImpl.next();\n        },\n        return(value) {\n            if (!IsReadableStreamAsyncIterator(this)) {\n                return promiseRejectedWith(streamAsyncIteratorBrandCheckException('return'));\n            }\n            return this._asyncIteratorImpl.return(value);\n        }\n    };\n    if (AsyncIteratorPrototype !== undefined) {\n        Object.setPrototypeOf(ReadableStreamAsyncIteratorPrototype, AsyncIteratorPrototype);\n    }\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamAsyncIterator(stream, preventCancel) {\n        const reader = AcquireReadableStreamDefaultReader(stream);\n        const impl = new ReadableStreamAsyncIteratorImpl(reader, preventCancel);\n        const iterator = Object.create(ReadableStreamAsyncIteratorPrototype);\n        iterator._asyncIteratorImpl = impl;\n        return iterator;\n    }\n    function IsReadableStreamAsyncIterator(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_asyncIteratorImpl')) {\n            return false;\n        }\n        try {\n            // noinspection SuspiciousTypeOfGuard\n            return x._asyncIteratorImpl instanceof\n                ReadableStreamAsyncIteratorImpl;\n        }\n        catch (_a) {\n            return false;\n        }\n    }\n    // Helper functions for the ReadableStream.\n    function streamAsyncIteratorBrandCheckException(name) {\n        return new TypeError(`ReadableStreamAsyncIterator.${name} can only be used on a ReadableSteamAsyncIterator`);\n    }\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isNaN#Polyfill\n    const NumberIsNaN = Number.isNaN || function (x) {\n        // eslint-disable-next-line no-self-compare\n        return x !== x;\n    };\n\n    function CreateArrayFromList(elements) {\n        // We use arrays to represent lists, so this is basically a no-op.\n        // Do a slice though just in case we happen to depend on the unique-ness.\n        return elements.slice();\n    }\n    function CopyDataBlockBytes(dest, destOffset, src, srcOffset, n) {\n        new Uint8Array(dest).set(new Uint8Array(src, srcOffset, n), destOffset);\n    }\n    // Not implemented correctly\n    function TransferArrayBuffer(O) {\n        return O;\n    }\n    // Not implemented correctly\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    function IsDetachedBuffer(O) {\n        return false;\n    }\n    function ArrayBufferSlice(buffer, begin, end) {\n        // ArrayBuffer.prototype.slice is not available on IE10\n        // https://www.caniuse.com/mdn-javascript_builtins_arraybuffer_slice\n        if (buffer.slice) {\n            return buffer.slice(begin, end);\n        }\n        const length = end - begin;\n        const slice = new ArrayBuffer(length);\n        CopyDataBlockBytes(slice, 0, buffer, begin, length);\n        return slice;\n    }\n\n    function IsNonNegativeNumber(v) {\n        if (typeof v !== 'number') {\n            return false;\n        }\n        if (NumberIsNaN(v)) {\n            return false;\n        }\n        if (v < 0) {\n            return false;\n        }\n        return true;\n    }\n    function CloneAsUint8Array(O) {\n        const buffer = ArrayBufferSlice(O.buffer, O.byteOffset, O.byteOffset + O.byteLength);\n        return new Uint8Array(buffer);\n    }\n\n    function DequeueValue(container) {\n        const pair = container._queue.shift();\n        container._queueTotalSize -= pair.size;\n        if (container._queueTotalSize < 0) {\n            container._queueTotalSize = 0;\n        }\n        return pair.value;\n    }\n    function EnqueueValueWithSize(container, value, size) {\n        if (!IsNonNegativeNumber(size) || size === Infinity) {\n            throw new RangeError('Size must be a finite, non-NaN, non-negative number.');\n        }\n        container._queue.push({ value, size });\n        container._queueTotalSize += size;\n    }\n    function PeekQueueValue(container) {\n        const pair = container._queue.peek();\n        return pair.value;\n    }\n    function ResetQueue(container) {\n        container._queue = new SimpleQueue();\n        container._queueTotalSize = 0;\n    }\n\n    /**\n     * A pull-into request in a {@link ReadableByteStreamController}.\n     *\n     * @public\n     */\n    class ReadableStreamBYOBRequest {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the view for writing in to, or `null` if the BYOB request has already been responded to.\n         */\n        get view() {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('view');\n            }\n            return this._view;\n        }\n        respond(bytesWritten) {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('respond');\n            }\n            assertRequiredArgument(bytesWritten, 1, 'respond');\n            bytesWritten = convertUnsignedLongLongWithEnforceRange(bytesWritten, 'First parameter');\n            if (this._associatedReadableByteStreamController === undefined) {\n                throw new TypeError('This BYOB request has been invalidated');\n            }\n            if (IsDetachedBuffer(this._view.buffer)) ;\n            ReadableByteStreamControllerRespond(this._associatedReadableByteStreamController, bytesWritten);\n        }\n        respondWithNewView(view) {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('respondWithNewView');\n            }\n            assertRequiredArgument(view, 1, 'respondWithNewView');\n            if (!ArrayBuffer.isView(view)) {\n                throw new TypeError('You can only respond with array buffer views');\n            }\n            if (this._associatedReadableByteStreamController === undefined) {\n                throw new TypeError('This BYOB request has been invalidated');\n            }\n            if (IsDetachedBuffer(view.buffer)) ;\n            ReadableByteStreamControllerRespondWithNewView(this._associatedReadableByteStreamController, view);\n        }\n    }\n    Object.defineProperties(ReadableStreamBYOBRequest.prototype, {\n        respond: { enumerable: true },\n        respondWithNewView: { enumerable: true },\n        view: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamBYOBRequest.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamBYOBRequest',\n            configurable: true\n        });\n    }\n    /**\n     * Allows control of a {@link ReadableStream | readable byte stream}'s state and internal queue.\n     *\n     * @public\n     */\n    class ReadableByteStreamController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the current BYOB pull request, or `null` if there isn't one.\n         */\n        get byobRequest() {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('byobRequest');\n            }\n            return ReadableByteStreamControllerGetBYOBRequest(this);\n        }\n        /**\n         * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n         * over-full. An underlying byte source ought to use this information to determine when and how to apply backpressure.\n         */\n        get desiredSize() {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('desiredSize');\n            }\n            return ReadableByteStreamControllerGetDesiredSize(this);\n        }\n        /**\n         * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n         * the stream, but once those are read, the stream will become closed.\n         */\n        close() {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('close');\n            }\n            if (this._closeRequested) {\n                throw new TypeError('The stream has already been closed; do not close it again!');\n            }\n            const state = this._controlledReadableByteStream._state;\n            if (state !== 'readable') {\n                throw new TypeError(`The stream (in ${state} state) is not in the readable state and cannot be closed`);\n            }\n            ReadableByteStreamControllerClose(this);\n        }\n        enqueue(chunk) {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('enqueue');\n            }\n            assertRequiredArgument(chunk, 1, 'enqueue');\n            if (!ArrayBuffer.isView(chunk)) {\n                throw new TypeError('chunk must be an array buffer view');\n            }\n            if (chunk.byteLength === 0) {\n                throw new TypeError('chunk must have non-zero byteLength');\n            }\n            if (chunk.buffer.byteLength === 0) {\n                throw new TypeError(`chunk's buffer must have non-zero byteLength`);\n            }\n            if (this._closeRequested) {\n                throw new TypeError('stream is closed or draining');\n            }\n            const state = this._controlledReadableByteStream._state;\n            if (state !== 'readable') {\n                throw new TypeError(`The stream (in ${state} state) is not in the readable state and cannot be enqueued to`);\n            }\n            ReadableByteStreamControllerEnqueue(this, chunk);\n        }\n        /**\n         * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n         */\n        error(e = undefined) {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('error');\n            }\n            ReadableByteStreamControllerError(this, e);\n        }\n        /** @internal */\n        [CancelSteps](reason) {\n            ReadableByteStreamControllerClearPendingPullIntos(this);\n            ResetQueue(this);\n            const result = this._cancelAlgorithm(reason);\n            ReadableByteStreamControllerClearAlgorithms(this);\n            return result;\n        }\n        /** @internal */\n        [PullSteps](readRequest) {\n            const stream = this._controlledReadableByteStream;\n            if (this._queueTotalSize > 0) {\n                const entry = this._queue.shift();\n                this._queueTotalSize -= entry.byteLength;\n                ReadableByteStreamControllerHandleQueueDrain(this);\n                const view = new Uint8Array(entry.buffer, entry.byteOffset, entry.byteLength);\n                readRequest._chunkSteps(view);\n                return;\n            }\n            const autoAllocateChunkSize = this._autoAllocateChunkSize;\n            if (autoAllocateChunkSize !== undefined) {\n                let buffer;\n                try {\n                    buffer = new ArrayBuffer(autoAllocateChunkSize);\n                }\n                catch (bufferE) {\n                    readRequest._errorSteps(bufferE);\n                    return;\n                }\n                const pullIntoDescriptor = {\n                    buffer,\n                    bufferByteLength: autoAllocateChunkSize,\n                    byteOffset: 0,\n                    byteLength: autoAllocateChunkSize,\n                    bytesFilled: 0,\n                    elementSize: 1,\n                    viewConstructor: Uint8Array,\n                    readerType: 'default'\n                };\n                this._pendingPullIntos.push(pullIntoDescriptor);\n            }\n            ReadableStreamAddReadRequest(stream, readRequest);\n            ReadableByteStreamControllerCallPullIfNeeded(this);\n        }\n    }\n    Object.defineProperties(ReadableByteStreamController.prototype, {\n        close: { enumerable: true },\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        byobRequest: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableByteStreamController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableByteStreamController',\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableByteStreamController.\n    function IsReadableByteStreamController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableByteStream')) {\n            return false;\n        }\n        return x instanceof ReadableByteStreamController;\n    }\n    function IsReadableStreamBYOBRequest(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_associatedReadableByteStreamController')) {\n            return false;\n        }\n        return x instanceof ReadableStreamBYOBRequest;\n    }\n    function ReadableByteStreamControllerCallPullIfNeeded(controller) {\n        const shouldPull = ReadableByteStreamControllerShouldCallPull(controller);\n        if (!shouldPull) {\n            return;\n        }\n        if (controller._pulling) {\n            controller._pullAgain = true;\n            return;\n        }\n        controller._pulling = true;\n        // TODO: Test controller argument\n        const pullPromise = controller._pullAlgorithm();\n        uponPromise(pullPromise, () => {\n            controller._pulling = false;\n            if (controller._pullAgain) {\n                controller._pullAgain = false;\n                ReadableByteStreamControllerCallPullIfNeeded(controller);\n            }\n        }, e => {\n            ReadableByteStreamControllerError(controller, e);\n        });\n    }\n    function ReadableByteStreamControllerClearPendingPullIntos(controller) {\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        controller._pendingPullIntos = new SimpleQueue();\n    }\n    function ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor) {\n        let done = false;\n        if (stream._state === 'closed') {\n            done = true;\n        }\n        const filledView = ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor);\n        if (pullIntoDescriptor.readerType === 'default') {\n            ReadableStreamFulfillReadRequest(stream, filledView, done);\n        }\n        else {\n            ReadableStreamFulfillReadIntoRequest(stream, filledView, done);\n        }\n    }\n    function ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor) {\n        const bytesFilled = pullIntoDescriptor.bytesFilled;\n        const elementSize = pullIntoDescriptor.elementSize;\n        return new pullIntoDescriptor.viewConstructor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, bytesFilled / elementSize);\n    }\n    function ReadableByteStreamControllerEnqueueChunkToQueue(controller, buffer, byteOffset, byteLength) {\n        controller._queue.push({ buffer, byteOffset, byteLength });\n        controller._queueTotalSize += byteLength;\n    }\n    function ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor) {\n        const elementSize = pullIntoDescriptor.elementSize;\n        const currentAlignedBytes = pullIntoDescriptor.bytesFilled - pullIntoDescriptor.bytesFilled % elementSize;\n        const maxBytesToCopy = Math.min(controller._queueTotalSize, pullIntoDescriptor.byteLength - pullIntoDescriptor.bytesFilled);\n        const maxBytesFilled = pullIntoDescriptor.bytesFilled + maxBytesToCopy;\n        const maxAlignedBytes = maxBytesFilled - maxBytesFilled % elementSize;\n        let totalBytesToCopyRemaining = maxBytesToCopy;\n        let ready = false;\n        if (maxAlignedBytes > currentAlignedBytes) {\n            totalBytesToCopyRemaining = maxAlignedBytes - pullIntoDescriptor.bytesFilled;\n            ready = true;\n        }\n        const queue = controller._queue;\n        while (totalBytesToCopyRemaining > 0) {\n            const headOfQueue = queue.peek();\n            const bytesToCopy = Math.min(totalBytesToCopyRemaining, headOfQueue.byteLength);\n            const destStart = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n            CopyDataBlockBytes(pullIntoDescriptor.buffer, destStart, headOfQueue.buffer, headOfQueue.byteOffset, bytesToCopy);\n            if (headOfQueue.byteLength === bytesToCopy) {\n                queue.shift();\n            }\n            else {\n                headOfQueue.byteOffset += bytesToCopy;\n                headOfQueue.byteLength -= bytesToCopy;\n            }\n            controller._queueTotalSize -= bytesToCopy;\n            ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesToCopy, pullIntoDescriptor);\n            totalBytesToCopyRemaining -= bytesToCopy;\n        }\n        return ready;\n    }\n    function ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, size, pullIntoDescriptor) {\n        pullIntoDescriptor.bytesFilled += size;\n    }\n    function ReadableByteStreamControllerHandleQueueDrain(controller) {\n        if (controller._queueTotalSize === 0 && controller._closeRequested) {\n            ReadableByteStreamControllerClearAlgorithms(controller);\n            ReadableStreamClose(controller._controlledReadableByteStream);\n        }\n        else {\n            ReadableByteStreamControllerCallPullIfNeeded(controller);\n        }\n    }\n    function ReadableByteStreamControllerInvalidateBYOBRequest(controller) {\n        if (controller._byobRequest === null) {\n            return;\n        }\n        controller._byobRequest._associatedReadableByteStreamController = undefined;\n        controller._byobRequest._view = null;\n        controller._byobRequest = null;\n    }\n    function ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller) {\n        while (controller._pendingPullIntos.length > 0) {\n            if (controller._queueTotalSize === 0) {\n                return;\n            }\n            const pullIntoDescriptor = controller._pendingPullIntos.peek();\n            if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n                ReadableByteStreamControllerShiftPendingPullInto(controller);\n                ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n            }\n        }\n    }\n    function ReadableByteStreamControllerPullInto(controller, view, readIntoRequest) {\n        const stream = controller._controlledReadableByteStream;\n        let elementSize = 1;\n        if (view.constructor !== DataView) {\n            elementSize = view.constructor.BYTES_PER_ELEMENT;\n        }\n        const ctor = view.constructor;\n        // try {\n        const buffer = TransferArrayBuffer(view.buffer);\n        // } catch (e) {\n        //   readIntoRequest._errorSteps(e);\n        //   return;\n        // }\n        const pullIntoDescriptor = {\n            buffer,\n            bufferByteLength: buffer.byteLength,\n            byteOffset: view.byteOffset,\n            byteLength: view.byteLength,\n            bytesFilled: 0,\n            elementSize,\n            viewConstructor: ctor,\n            readerType: 'byob'\n        };\n        if (controller._pendingPullIntos.length > 0) {\n            controller._pendingPullIntos.push(pullIntoDescriptor);\n            // No ReadableByteStreamControllerCallPullIfNeeded() call since:\n            // - No change happens on desiredSize\n            // - The source has already been notified of that there's at least 1 pending read(view)\n            ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n            return;\n        }\n        if (stream._state === 'closed') {\n            const emptyView = new ctor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, 0);\n            readIntoRequest._closeSteps(emptyView);\n            return;\n        }\n        if (controller._queueTotalSize > 0) {\n            if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n                const filledView = ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor);\n                ReadableByteStreamControllerHandleQueueDrain(controller);\n                readIntoRequest._chunkSteps(filledView);\n                return;\n            }\n            if (controller._closeRequested) {\n                const e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n                ReadableByteStreamControllerError(controller, e);\n                readIntoRequest._errorSteps(e);\n                return;\n            }\n        }\n        controller._pendingPullIntos.push(pullIntoDescriptor);\n        ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerRespondInClosedState(controller, firstDescriptor) {\n        const stream = controller._controlledReadableByteStream;\n        if (ReadableStreamHasBYOBReader(stream)) {\n            while (ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n                const pullIntoDescriptor = ReadableByteStreamControllerShiftPendingPullInto(controller);\n                ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor);\n            }\n        }\n    }\n    function ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, pullIntoDescriptor) {\n        ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesWritten, pullIntoDescriptor);\n        if (pullIntoDescriptor.bytesFilled < pullIntoDescriptor.elementSize) {\n            return;\n        }\n        ReadableByteStreamControllerShiftPendingPullInto(controller);\n        const remainderSize = pullIntoDescriptor.bytesFilled % pullIntoDescriptor.elementSize;\n        if (remainderSize > 0) {\n            const end = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n            const remainder = ArrayBufferSlice(pullIntoDescriptor.buffer, end - remainderSize, end);\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, remainder, 0, remainder.byteLength);\n        }\n        pullIntoDescriptor.bytesFilled -= remainderSize;\n        ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n        ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n    }\n    function ReadableByteStreamControllerRespondInternal(controller, bytesWritten) {\n        const firstDescriptor = controller._pendingPullIntos.peek();\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'closed') {\n            ReadableByteStreamControllerRespondInClosedState(controller);\n        }\n        else {\n            ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, firstDescriptor);\n        }\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerShiftPendingPullInto(controller) {\n        const descriptor = controller._pendingPullIntos.shift();\n        return descriptor;\n    }\n    function ReadableByteStreamControllerShouldCallPull(controller) {\n        const stream = controller._controlledReadableByteStream;\n        if (stream._state !== 'readable') {\n            return false;\n        }\n        if (controller._closeRequested) {\n            return false;\n        }\n        if (!controller._started) {\n            return false;\n        }\n        if (ReadableStreamHasDefaultReader(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            return true;\n        }\n        if (ReadableStreamHasBYOBReader(stream) && ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n            return true;\n        }\n        const desiredSize = ReadableByteStreamControllerGetDesiredSize(controller);\n        if (desiredSize > 0) {\n            return true;\n        }\n        return false;\n    }\n    function ReadableByteStreamControllerClearAlgorithms(controller) {\n        controller._pullAlgorithm = undefined;\n        controller._cancelAlgorithm = undefined;\n    }\n    // A client of ReadableByteStreamController may use these functions directly to bypass state check.\n    function ReadableByteStreamControllerClose(controller) {\n        const stream = controller._controlledReadableByteStream;\n        if (controller._closeRequested || stream._state !== 'readable') {\n            return;\n        }\n        if (controller._queueTotalSize > 0) {\n            controller._closeRequested = true;\n            return;\n        }\n        if (controller._pendingPullIntos.length > 0) {\n            const firstPendingPullInto = controller._pendingPullIntos.peek();\n            if (firstPendingPullInto.bytesFilled > 0) {\n                const e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n                ReadableByteStreamControllerError(controller, e);\n                throw e;\n            }\n        }\n        ReadableByteStreamControllerClearAlgorithms(controller);\n        ReadableStreamClose(stream);\n    }\n    function ReadableByteStreamControllerEnqueue(controller, chunk) {\n        const stream = controller._controlledReadableByteStream;\n        if (controller._closeRequested || stream._state !== 'readable') {\n            return;\n        }\n        const buffer = chunk.buffer;\n        const byteOffset = chunk.byteOffset;\n        const byteLength = chunk.byteLength;\n        const transferredBuffer = TransferArrayBuffer(buffer);\n        if (controller._pendingPullIntos.length > 0) {\n            const firstPendingPullInto = controller._pendingPullIntos.peek();\n            if (IsDetachedBuffer(firstPendingPullInto.buffer)) ;\n            firstPendingPullInto.buffer = TransferArrayBuffer(firstPendingPullInto.buffer);\n        }\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        if (ReadableStreamHasDefaultReader(stream)) {\n            if (ReadableStreamGetNumReadRequests(stream) === 0) {\n                ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n            }\n            else {\n                if (controller._pendingPullIntos.length > 0) {\n                    ReadableByteStreamControllerShiftPendingPullInto(controller);\n                }\n                const transferredView = new Uint8Array(transferredBuffer, byteOffset, byteLength);\n                ReadableStreamFulfillReadRequest(stream, transferredView, false);\n            }\n        }\n        else if (ReadableStreamHasBYOBReader(stream)) {\n            // TODO: Ideally in this branch detaching should happen only if the buffer is not consumed fully.\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n            ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n        }\n        else {\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n        }\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerError(controller, e) {\n        const stream = controller._controlledReadableByteStream;\n        if (stream._state !== 'readable') {\n            return;\n        }\n        ReadableByteStreamControllerClearPendingPullIntos(controller);\n        ResetQueue(controller);\n        ReadableByteStreamControllerClearAlgorithms(controller);\n        ReadableStreamError(stream, e);\n    }\n    function ReadableByteStreamControllerGetBYOBRequest(controller) {\n        if (controller._byobRequest === null && controller._pendingPullIntos.length > 0) {\n            const firstDescriptor = controller._pendingPullIntos.peek();\n            const view = new Uint8Array(firstDescriptor.buffer, firstDescriptor.byteOffset + firstDescriptor.bytesFilled, firstDescriptor.byteLength - firstDescriptor.bytesFilled);\n            const byobRequest = Object.create(ReadableStreamBYOBRequest.prototype);\n            SetUpReadableStreamBYOBRequest(byobRequest, controller, view);\n            controller._byobRequest = byobRequest;\n        }\n        return controller._byobRequest;\n    }\n    function ReadableByteStreamControllerGetDesiredSize(controller) {\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'errored') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    function ReadableByteStreamControllerRespond(controller, bytesWritten) {\n        const firstDescriptor = controller._pendingPullIntos.peek();\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'closed') {\n            if (bytesWritten !== 0) {\n                throw new TypeError('bytesWritten must be 0 when calling respond() on a closed stream');\n            }\n        }\n        else {\n            if (bytesWritten === 0) {\n                throw new TypeError('bytesWritten must be greater than 0 when calling respond() on a readable stream');\n            }\n            if (firstDescriptor.bytesFilled + bytesWritten > firstDescriptor.byteLength) {\n                throw new RangeError('bytesWritten out of range');\n            }\n        }\n        firstDescriptor.buffer = TransferArrayBuffer(firstDescriptor.buffer);\n        ReadableByteStreamControllerRespondInternal(controller, bytesWritten);\n    }\n    function ReadableByteStreamControllerRespondWithNewView(controller, view) {\n        const firstDescriptor = controller._pendingPullIntos.peek();\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'closed') {\n            if (view.byteLength !== 0) {\n                throw new TypeError('The view\\'s length must be 0 when calling respondWithNewView() on a closed stream');\n            }\n        }\n        else {\n            if (view.byteLength === 0) {\n                throw new TypeError('The view\\'s length must be greater than 0 when calling respondWithNewView() on a readable stream');\n            }\n        }\n        if (firstDescriptor.byteOffset + firstDescriptor.bytesFilled !== view.byteOffset) {\n            throw new RangeError('The region specified by view does not match byobRequest');\n        }\n        if (firstDescriptor.bufferByteLength !== view.buffer.byteLength) {\n            throw new RangeError('The buffer of view has different capacity than byobRequest');\n        }\n        if (firstDescriptor.bytesFilled + view.byteLength > firstDescriptor.byteLength) {\n            throw new RangeError('The region specified by view is larger than byobRequest');\n        }\n        const viewByteLength = view.byteLength;\n        firstDescriptor.buffer = TransferArrayBuffer(view.buffer);\n        ReadableByteStreamControllerRespondInternal(controller, viewByteLength);\n    }\n    function SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize) {\n        controller._controlledReadableByteStream = stream;\n        controller._pullAgain = false;\n        controller._pulling = false;\n        controller._byobRequest = null;\n        // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n        controller._queue = controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._closeRequested = false;\n        controller._started = false;\n        controller._strategyHWM = highWaterMark;\n        controller._pullAlgorithm = pullAlgorithm;\n        controller._cancelAlgorithm = cancelAlgorithm;\n        controller._autoAllocateChunkSize = autoAllocateChunkSize;\n        controller._pendingPullIntos = new SimpleQueue();\n        stream._readableStreamController = controller;\n        const startResult = startAlgorithm();\n        uponPromise(promiseResolvedWith(startResult), () => {\n            controller._started = true;\n            ReadableByteStreamControllerCallPullIfNeeded(controller);\n        }, r => {\n            ReadableByteStreamControllerError(controller, r);\n        });\n    }\n    function SetUpReadableByteStreamControllerFromUnderlyingSource(stream, underlyingByteSource, highWaterMark) {\n        const controller = Object.create(ReadableByteStreamController.prototype);\n        let startAlgorithm = () => undefined;\n        let pullAlgorithm = () => promiseResolvedWith(undefined);\n        let cancelAlgorithm = () => promiseResolvedWith(undefined);\n        if (underlyingByteSource.start !== undefined) {\n            startAlgorithm = () => underlyingByteSource.start(controller);\n        }\n        if (underlyingByteSource.pull !== undefined) {\n            pullAlgorithm = () => underlyingByteSource.pull(controller);\n        }\n        if (underlyingByteSource.cancel !== undefined) {\n            cancelAlgorithm = reason => underlyingByteSource.cancel(reason);\n        }\n        const autoAllocateChunkSize = underlyingByteSource.autoAllocateChunkSize;\n        if (autoAllocateChunkSize === 0) {\n            throw new TypeError('autoAllocateChunkSize must be greater than 0');\n        }\n        SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize);\n    }\n    function SetUpReadableStreamBYOBRequest(request, controller, view) {\n        request._associatedReadableByteStreamController = controller;\n        request._view = view;\n    }\n    // Helper functions for the ReadableStreamBYOBRequest.\n    function byobRequestBrandCheckException(name) {\n        return new TypeError(`ReadableStreamBYOBRequest.prototype.${name} can only be used on a ReadableStreamBYOBRequest`);\n    }\n    // Helper functions for the ReadableByteStreamController.\n    function byteStreamControllerBrandCheckException(name) {\n        return new TypeError(`ReadableByteStreamController.prototype.${name} can only be used on a ReadableByteStreamController`);\n    }\n\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamBYOBReader(stream) {\n        return new ReadableStreamBYOBReader(stream);\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamAddReadIntoRequest(stream, readIntoRequest) {\n        stream._reader._readIntoRequests.push(readIntoRequest);\n    }\n    function ReadableStreamFulfillReadIntoRequest(stream, chunk, done) {\n        const reader = stream._reader;\n        const readIntoRequest = reader._readIntoRequests.shift();\n        if (done) {\n            readIntoRequest._closeSteps(chunk);\n        }\n        else {\n            readIntoRequest._chunkSteps(chunk);\n        }\n    }\n    function ReadableStreamGetNumReadIntoRequests(stream) {\n        return stream._reader._readIntoRequests.length;\n    }\n    function ReadableStreamHasBYOBReader(stream) {\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return false;\n        }\n        if (!IsReadableStreamBYOBReader(reader)) {\n            return false;\n        }\n        return true;\n    }\n    /**\n     * A BYOB reader vended by a {@link ReadableStream}.\n     *\n     * @public\n     */\n    class ReadableStreamBYOBReader {\n        constructor(stream) {\n            assertRequiredArgument(stream, 1, 'ReadableStreamBYOBReader');\n            assertReadableStream(stream, 'First parameter');\n            if (IsReadableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n            }\n            if (!IsReadableByteStreamController(stream._readableStreamController)) {\n                throw new TypeError('Cannot construct a ReadableStreamBYOBReader for a stream not constructed with a byte ' +\n                    'source');\n            }\n            ReadableStreamReaderGenericInitialize(this, stream);\n            this._readIntoRequests = new SimpleQueue();\n        }\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n         * the reader's lock is released before the stream finishes closing.\n         */\n        get closed() {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        }\n        /**\n         * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n         */\n        cancel(reason = undefined) {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('cancel'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('cancel'));\n            }\n            return ReadableStreamReaderGenericCancel(this, reason);\n        }\n        /**\n         * Attempts to reads bytes into view, and returns a promise resolved with the result.\n         *\n         * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n         */\n        read(view) {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('read'));\n            }\n            if (!ArrayBuffer.isView(view)) {\n                return promiseRejectedWith(new TypeError('view must be an array buffer view'));\n            }\n            if (view.byteLength === 0) {\n                return promiseRejectedWith(new TypeError('view must have non-zero byteLength'));\n            }\n            if (view.buffer.byteLength === 0) {\n                return promiseRejectedWith(new TypeError(`view's buffer must have non-zero byteLength`));\n            }\n            if (IsDetachedBuffer(view.buffer)) ;\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('read from'));\n            }\n            let resolvePromise;\n            let rejectPromise;\n            const promise = newPromise((resolve, reject) => {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            const readIntoRequest = {\n                _chunkSteps: chunk => resolvePromise({ value: chunk, done: false }),\n                _closeSteps: chunk => resolvePromise({ value: chunk, done: true }),\n                _errorSteps: e => rejectPromise(e)\n            };\n            ReadableStreamBYOBReaderRead(this, view, readIntoRequest);\n            return promise;\n        }\n        /**\n         * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n         * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n         * from now on; otherwise, the reader will appear closed.\n         *\n         * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n         * the reader's {@link ReadableStreamBYOBReader.read | read()} method has not yet been settled. Attempting to\n         * do so will throw a `TypeError` and leave the reader locked to the stream.\n         */\n        releaseLock() {\n            if (!IsReadableStreamBYOBReader(this)) {\n                throw byobReaderBrandCheckException('releaseLock');\n            }\n            if (this._ownerReadableStream === undefined) {\n                return;\n            }\n            if (this._readIntoRequests.length > 0) {\n                throw new TypeError('Tried to release a reader lock when that reader has pending read() calls un-settled');\n            }\n            ReadableStreamReaderGenericRelease(this);\n        }\n    }\n    Object.defineProperties(ReadableStreamBYOBReader.prototype, {\n        cancel: { enumerable: true },\n        read: { enumerable: true },\n        releaseLock: { enumerable: true },\n        closed: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamBYOBReader.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamBYOBReader',\n            configurable: true\n        });\n    }\n    // Abstract operations for the readers.\n    function IsReadableStreamBYOBReader(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readIntoRequests')) {\n            return false;\n        }\n        return x instanceof ReadableStreamBYOBReader;\n    }\n    function ReadableStreamBYOBReaderRead(reader, view, readIntoRequest) {\n        const stream = reader._ownerReadableStream;\n        stream._disturbed = true;\n        if (stream._state === 'errored') {\n            readIntoRequest._errorSteps(stream._storedError);\n        }\n        else {\n            ReadableByteStreamControllerPullInto(stream._readableStreamController, view, readIntoRequest);\n        }\n    }\n    // Helper functions for the ReadableStreamBYOBReader.\n    function byobReaderBrandCheckException(name) {\n        return new TypeError(`ReadableStreamBYOBReader.prototype.${name} can only be used on a ReadableStreamBYOBReader`);\n    }\n\n    function ExtractHighWaterMark(strategy, defaultHWM) {\n        const { highWaterMark } = strategy;\n        if (highWaterMark === undefined) {\n            return defaultHWM;\n        }\n        if (NumberIsNaN(highWaterMark) || highWaterMark < 0) {\n            throw new RangeError('Invalid highWaterMark');\n        }\n        return highWaterMark;\n    }\n    function ExtractSizeAlgorithm(strategy) {\n        const { size } = strategy;\n        if (!size) {\n            return () => 1;\n        }\n        return size;\n    }\n\n    function convertQueuingStrategy(init, context) {\n        assertDictionary(init, context);\n        const highWaterMark = init === null || init === void 0 ? void 0 : init.highWaterMark;\n        const size = init === null || init === void 0 ? void 0 : init.size;\n        return {\n            highWaterMark: highWaterMark === undefined ? undefined : convertUnrestrictedDouble(highWaterMark),\n            size: size === undefined ? undefined : convertQueuingStrategySize(size, `${context} has member 'size' that`)\n        };\n    }\n    function convertQueuingStrategySize(fn, context) {\n        assertFunction(fn, context);\n        return chunk => convertUnrestrictedDouble(fn(chunk));\n    }\n\n    function convertUnderlyingSink(original, context) {\n        assertDictionary(original, context);\n        const abort = original === null || original === void 0 ? void 0 : original.abort;\n        const close = original === null || original === void 0 ? void 0 : original.close;\n        const start = original === null || original === void 0 ? void 0 : original.start;\n        const type = original === null || original === void 0 ? void 0 : original.type;\n        const write = original === null || original === void 0 ? void 0 : original.write;\n        return {\n            abort: abort === undefined ?\n                undefined :\n                convertUnderlyingSinkAbortCallback(abort, original, `${context} has member 'abort' that`),\n            close: close === undefined ?\n                undefined :\n                convertUnderlyingSinkCloseCallback(close, original, `${context} has member 'close' that`),\n            start: start === undefined ?\n                undefined :\n                convertUnderlyingSinkStartCallback(start, original, `${context} has member 'start' that`),\n            write: write === undefined ?\n                undefined :\n                convertUnderlyingSinkWriteCallback(write, original, `${context} has member 'write' that`),\n            type\n        };\n    }\n    function convertUnderlyingSinkAbortCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (reason) => promiseCall(fn, original, [reason]);\n    }\n    function convertUnderlyingSinkCloseCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return () => promiseCall(fn, original, []);\n    }\n    function convertUnderlyingSinkStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => reflectCall(fn, original, [controller]);\n    }\n    function convertUnderlyingSinkWriteCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (chunk, controller) => promiseCall(fn, original, [chunk, controller]);\n    }\n\n    function assertWritableStream(x, context) {\n        if (!IsWritableStream(x)) {\n            throw new TypeError(`${context} is not a WritableStream.`);\n        }\n    }\n\n    function isAbortSignal(value) {\n        if (typeof value !== 'object' || value === null) {\n            return false;\n        }\n        try {\n            return typeof value.aborted === 'boolean';\n        }\n        catch (_a) {\n            // AbortSignal.prototype.aborted throws if its brand check fails\n            return false;\n        }\n    }\n    const supportsAbortController = typeof AbortController === 'function';\n    /**\n     * Construct a new AbortController, if supported by the platform.\n     *\n     * @internal\n     */\n    function createAbortController() {\n        if (supportsAbortController) {\n            return new AbortController();\n        }\n        return undefined;\n    }\n\n    /**\n     * A writable stream represents a destination for data, into which you can write.\n     *\n     * @public\n     */\n    class WritableStream {\n        constructor(rawUnderlyingSink = {}, rawStrategy = {}) {\n            if (rawUnderlyingSink === undefined) {\n                rawUnderlyingSink = null;\n            }\n            else {\n                assertObject(rawUnderlyingSink, 'First parameter');\n            }\n            const strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n            const underlyingSink = convertUnderlyingSink(rawUnderlyingSink, 'First parameter');\n            InitializeWritableStream(this);\n            const type = underlyingSink.type;\n            if (type !== undefined) {\n                throw new RangeError('Invalid type is specified');\n            }\n            const sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n            const highWaterMark = ExtractHighWaterMark(strategy, 1);\n            SetUpWritableStreamDefaultControllerFromUnderlyingSink(this, underlyingSink, highWaterMark, sizeAlgorithm);\n        }\n        /**\n         * Returns whether or not the writable stream is locked to a writer.\n         */\n        get locked() {\n            if (!IsWritableStream(this)) {\n                throw streamBrandCheckException$2('locked');\n            }\n            return IsWritableStreamLocked(this);\n        }\n        /**\n         * Aborts the stream, signaling that the producer can no longer successfully write to the stream and it is to be\n         * immediately moved to an errored state, with any queued-up writes discarded. This will also execute any abort\n         * mechanism of the underlying sink.\n         *\n         * The returned promise will fulfill if the stream shuts down successfully, or reject if the underlying sink signaled\n         * that there was an error doing so. Additionally, it will reject with a `TypeError` (without attempting to cancel\n         * the stream) if the stream is currently locked.\n         */\n        abort(reason = undefined) {\n            if (!IsWritableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$2('abort'));\n            }\n            if (IsWritableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot abort a stream that already has a writer'));\n            }\n            return WritableStreamAbort(this, reason);\n        }\n        /**\n         * Closes the stream. The underlying sink will finish processing any previously-written chunks, before invoking its\n         * close behavior. During this time any further attempts to write will fail (without erroring the stream).\n         *\n         * The method returns a promise that will fulfill if all remaining chunks are successfully written and the stream\n         * successfully closes, or rejects if an error is encountered during this process. Additionally, it will reject with\n         * a `TypeError` (without attempting to cancel the stream) if the stream is currently locked.\n         */\n        close() {\n            if (!IsWritableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$2('close'));\n            }\n            if (IsWritableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot close a stream that already has a writer'));\n            }\n            if (WritableStreamCloseQueuedOrInFlight(this)) {\n                return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n            }\n            return WritableStreamClose(this);\n        }\n        /**\n         * Creates a {@link WritableStreamDefaultWriter | writer} and locks the stream to the new writer. While the stream\n         * is locked, no other writer can be acquired until this one is released.\n         *\n         * This functionality is especially useful for creating abstractions that desire the ability to write to a stream\n         * without interruption or interleaving. By getting a writer for the stream, you can ensure nobody else can write at\n         * the same time, which would cause the resulting written data to be unpredictable and probably useless.\n         */\n        getWriter() {\n            if (!IsWritableStream(this)) {\n                throw streamBrandCheckException$2('getWriter');\n            }\n            return AcquireWritableStreamDefaultWriter(this);\n        }\n    }\n    Object.defineProperties(WritableStream.prototype, {\n        abort: { enumerable: true },\n        close: { enumerable: true },\n        getWriter: { enumerable: true },\n        locked: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStream',\n            configurable: true\n        });\n    }\n    // Abstract operations for the WritableStream.\n    function AcquireWritableStreamDefaultWriter(stream) {\n        return new WritableStreamDefaultWriter(stream);\n    }\n    // Throws if and only if startAlgorithm throws.\n    function CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark = 1, sizeAlgorithm = () => 1) {\n        const stream = Object.create(WritableStream.prototype);\n        InitializeWritableStream(stream);\n        const controller = Object.create(WritableStreamDefaultController.prototype);\n        SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm);\n        return stream;\n    }\n    function InitializeWritableStream(stream) {\n        stream._state = 'writable';\n        // The error that will be reported by new method calls once the state becomes errored. Only set when [[state]] is\n        // 'erroring' or 'errored'. May be set to an undefined value.\n        stream._storedError = undefined;\n        stream._writer = undefined;\n        // Initialize to undefined first because the constructor of the controller checks this\n        // variable to validate the caller.\n        stream._writableStreamController = undefined;\n        // This queue is placed here instead of the writer class in order to allow for passing a writer to the next data\n        // producer without waiting for the queued writes to finish.\n        stream._writeRequests = new SimpleQueue();\n        // Write requests are removed from _writeRequests when write() is called on the underlying sink. This prevents\n        // them from being erroneously rejected on error. If a write() call is in-flight, the request is stored here.\n        stream._inFlightWriteRequest = undefined;\n        // The promise that was returned from writer.close(). Stored here because it may be fulfilled after the writer\n        // has been detached.\n        stream._closeRequest = undefined;\n        // Close request is removed from _closeRequest when close() is called on the underlying sink. This prevents it\n        // from being erroneously rejected on error. If a close() call is in-flight, the request is stored here.\n        stream._inFlightCloseRequest = undefined;\n        // The promise that was returned from writer.abort(). This may also be fulfilled after the writer has detached.\n        stream._pendingAbortRequest = undefined;\n        // The backpressure signal set by the controller.\n        stream._backpressure = false;\n    }\n    function IsWritableStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_writableStreamController')) {\n            return false;\n        }\n        return x instanceof WritableStream;\n    }\n    function IsWritableStreamLocked(stream) {\n        if (stream._writer === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamAbort(stream, reason) {\n        var _a;\n        if (stream._state === 'closed' || stream._state === 'errored') {\n            return promiseResolvedWith(undefined);\n        }\n        stream._writableStreamController._abortReason = reason;\n        (_a = stream._writableStreamController._abortController) === null || _a === void 0 ? void 0 : _a.abort();\n        // TypeScript narrows the type of `stream._state` down to 'writable' | 'erroring',\n        // but it doesn't know that signaling abort runs author code that might have changed the state.\n        // Widen the type again by casting to WritableStreamState.\n        const state = stream._state;\n        if (state === 'closed' || state === 'errored') {\n            return promiseResolvedWith(undefined);\n        }\n        if (stream._pendingAbortRequest !== undefined) {\n            return stream._pendingAbortRequest._promise;\n        }\n        let wasAlreadyErroring = false;\n        if (state === 'erroring') {\n            wasAlreadyErroring = true;\n            // reason will not be used, so don't keep a reference to it.\n            reason = undefined;\n        }\n        const promise = newPromise((resolve, reject) => {\n            stream._pendingAbortRequest = {\n                _promise: undefined,\n                _resolve: resolve,\n                _reject: reject,\n                _reason: reason,\n                _wasAlreadyErroring: wasAlreadyErroring\n            };\n        });\n        stream._pendingAbortRequest._promise = promise;\n        if (!wasAlreadyErroring) {\n            WritableStreamStartErroring(stream, reason);\n        }\n        return promise;\n    }\n    function WritableStreamClose(stream) {\n        const state = stream._state;\n        if (state === 'closed' || state === 'errored') {\n            return promiseRejectedWith(new TypeError(`The stream (in ${state} state) is not in the writable state and cannot be closed`));\n        }\n        const promise = newPromise((resolve, reject) => {\n            const closeRequest = {\n                _resolve: resolve,\n                _reject: reject\n            };\n            stream._closeRequest = closeRequest;\n        });\n        const writer = stream._writer;\n        if (writer !== undefined && stream._backpressure && state === 'writable') {\n            defaultWriterReadyPromiseResolve(writer);\n        }\n        WritableStreamDefaultControllerClose(stream._writableStreamController);\n        return promise;\n    }\n    // WritableStream API exposed for controllers.\n    function WritableStreamAddWriteRequest(stream) {\n        const promise = newPromise((resolve, reject) => {\n            const writeRequest = {\n                _resolve: resolve,\n                _reject: reject\n            };\n            stream._writeRequests.push(writeRequest);\n        });\n        return promise;\n    }\n    function WritableStreamDealWithRejection(stream, error) {\n        const state = stream._state;\n        if (state === 'writable') {\n            WritableStreamStartErroring(stream, error);\n            return;\n        }\n        WritableStreamFinishErroring(stream);\n    }\n    function WritableStreamStartErroring(stream, reason) {\n        const controller = stream._writableStreamController;\n        stream._state = 'erroring';\n        stream._storedError = reason;\n        const writer = stream._writer;\n        if (writer !== undefined) {\n            WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, reason);\n        }\n        if (!WritableStreamHasOperationMarkedInFlight(stream) && controller._started) {\n            WritableStreamFinishErroring(stream);\n        }\n    }\n    function WritableStreamFinishErroring(stream) {\n        stream._state = 'errored';\n        stream._writableStreamController[ErrorSteps]();\n        const storedError = stream._storedError;\n        stream._writeRequests.forEach(writeRequest => {\n            writeRequest._reject(storedError);\n        });\n        stream._writeRequests = new SimpleQueue();\n        if (stream._pendingAbortRequest === undefined) {\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n            return;\n        }\n        const abortRequest = stream._pendingAbortRequest;\n        stream._pendingAbortRequest = undefined;\n        if (abortRequest._wasAlreadyErroring) {\n            abortRequest._reject(storedError);\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n            return;\n        }\n        const promise = stream._writableStreamController[AbortSteps](abortRequest._reason);\n        uponPromise(promise, () => {\n            abortRequest._resolve();\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n        }, (reason) => {\n            abortRequest._reject(reason);\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n        });\n    }\n    function WritableStreamFinishInFlightWrite(stream) {\n        stream._inFlightWriteRequest._resolve(undefined);\n        stream._inFlightWriteRequest = undefined;\n    }\n    function WritableStreamFinishInFlightWriteWithError(stream, error) {\n        stream._inFlightWriteRequest._reject(error);\n        stream._inFlightWriteRequest = undefined;\n        WritableStreamDealWithRejection(stream, error);\n    }\n    function WritableStreamFinishInFlightClose(stream) {\n        stream._inFlightCloseRequest._resolve(undefined);\n        stream._inFlightCloseRequest = undefined;\n        const state = stream._state;\n        if (state === 'erroring') {\n            // The error was too late to do anything, so it is ignored.\n            stream._storedError = undefined;\n            if (stream._pendingAbortRequest !== undefined) {\n                stream._pendingAbortRequest._resolve();\n                stream._pendingAbortRequest = undefined;\n            }\n        }\n        stream._state = 'closed';\n        const writer = stream._writer;\n        if (writer !== undefined) {\n            defaultWriterClosedPromiseResolve(writer);\n        }\n    }\n    function WritableStreamFinishInFlightCloseWithError(stream, error) {\n        stream._inFlightCloseRequest._reject(error);\n        stream._inFlightCloseRequest = undefined;\n        // Never execute sink abort() after sink close().\n        if (stream._pendingAbortRequest !== undefined) {\n            stream._pendingAbortRequest._reject(error);\n            stream._pendingAbortRequest = undefined;\n        }\n        WritableStreamDealWithRejection(stream, error);\n    }\n    // TODO(ricea): Fix alphabetical order.\n    function WritableStreamCloseQueuedOrInFlight(stream) {\n        if (stream._closeRequest === undefined && stream._inFlightCloseRequest === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamHasOperationMarkedInFlight(stream) {\n        if (stream._inFlightWriteRequest === undefined && stream._inFlightCloseRequest === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamMarkCloseRequestInFlight(stream) {\n        stream._inFlightCloseRequest = stream._closeRequest;\n        stream._closeRequest = undefined;\n    }\n    function WritableStreamMarkFirstWriteRequestInFlight(stream) {\n        stream._inFlightWriteRequest = stream._writeRequests.shift();\n    }\n    function WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream) {\n        if (stream._closeRequest !== undefined) {\n            stream._closeRequest._reject(stream._storedError);\n            stream._closeRequest = undefined;\n        }\n        const writer = stream._writer;\n        if (writer !== undefined) {\n            defaultWriterClosedPromiseReject(writer, stream._storedError);\n        }\n    }\n    function WritableStreamUpdateBackpressure(stream, backpressure) {\n        const writer = stream._writer;\n        if (writer !== undefined && backpressure !== stream._backpressure) {\n            if (backpressure) {\n                defaultWriterReadyPromiseReset(writer);\n            }\n            else {\n                defaultWriterReadyPromiseResolve(writer);\n            }\n        }\n        stream._backpressure = backpressure;\n    }\n    /**\n     * A default writer vended by a {@link WritableStream}.\n     *\n     * @public\n     */\n    class WritableStreamDefaultWriter {\n        constructor(stream) {\n            assertRequiredArgument(stream, 1, 'WritableStreamDefaultWriter');\n            assertWritableStream(stream, 'First parameter');\n            if (IsWritableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive writing by another writer');\n            }\n            this._ownerWritableStream = stream;\n            stream._writer = this;\n            const state = stream._state;\n            if (state === 'writable') {\n                if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._backpressure) {\n                    defaultWriterReadyPromiseInitialize(this);\n                }\n                else {\n                    defaultWriterReadyPromiseInitializeAsResolved(this);\n                }\n                defaultWriterClosedPromiseInitialize(this);\n            }\n            else if (state === 'erroring') {\n                defaultWriterReadyPromiseInitializeAsRejected(this, stream._storedError);\n                defaultWriterClosedPromiseInitialize(this);\n            }\n            else if (state === 'closed') {\n                defaultWriterReadyPromiseInitializeAsResolved(this);\n                defaultWriterClosedPromiseInitializeAsResolved(this);\n            }\n            else {\n                const storedError = stream._storedError;\n                defaultWriterReadyPromiseInitializeAsRejected(this, storedError);\n                defaultWriterClosedPromiseInitializeAsRejected(this, storedError);\n            }\n        }\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n         * the writer’s lock is released before the stream finishes closing.\n         */\n        get closed() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        }\n        /**\n         * Returns the desired size to fill the stream’s internal queue. It can be negative, if the queue is over-full.\n         * A producer can use this information to determine the right amount of data to write.\n         *\n         * It will be `null` if the stream cannot be successfully written to (due to either being errored, or having an abort\n         * queued up). It will return zero if the stream is closed. And the getter will throw an exception if invoked when\n         * the writer’s lock is released.\n         */\n        get desiredSize() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                throw defaultWriterBrandCheckException('desiredSize');\n            }\n            if (this._ownerWritableStream === undefined) {\n                throw defaultWriterLockException('desiredSize');\n            }\n            return WritableStreamDefaultWriterGetDesiredSize(this);\n        }\n        /**\n         * Returns a promise that will be fulfilled when the desired size to fill the stream’s internal queue transitions\n         * from non-positive to positive, signaling that it is no longer applying backpressure. Once the desired size dips\n         * back to zero or below, the getter will return a new promise that stays pending until the next transition.\n         *\n         * If the stream becomes errored or aborted, or the writer’s lock is released, the returned promise will become\n         * rejected.\n         */\n        get ready() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('ready'));\n            }\n            return this._readyPromise;\n        }\n        /**\n         * If the reader is active, behaves the same as {@link WritableStream.abort | stream.abort(reason)}.\n         */\n        abort(reason = undefined) {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('abort'));\n            }\n            if (this._ownerWritableStream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('abort'));\n            }\n            return WritableStreamDefaultWriterAbort(this, reason);\n        }\n        /**\n         * If the reader is active, behaves the same as {@link WritableStream.close | stream.close()}.\n         */\n        close() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('close'));\n            }\n            const stream = this._ownerWritableStream;\n            if (stream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('close'));\n            }\n            if (WritableStreamCloseQueuedOrInFlight(stream)) {\n                return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n            }\n            return WritableStreamDefaultWriterClose(this);\n        }\n        /**\n         * Releases the writer’s lock on the corresponding stream. After the lock is released, the writer is no longer active.\n         * If the associated stream is errored when the lock is released, the writer will appear errored in the same way from\n         * now on; otherwise, the writer will appear closed.\n         *\n         * Note that the lock can still be released even if some ongoing writes have not yet finished (i.e. even if the\n         * promises returned from previous calls to {@link WritableStreamDefaultWriter.write | write()} have not yet settled).\n         * It’s not necessary to hold the lock on the writer for the duration of the write; the lock instead simply prevents\n         * other producers from writing in an interleaved manner.\n         */\n        releaseLock() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                throw defaultWriterBrandCheckException('releaseLock');\n            }\n            const stream = this._ownerWritableStream;\n            if (stream === undefined) {\n                return;\n            }\n            WritableStreamDefaultWriterRelease(this);\n        }\n        write(chunk = undefined) {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('write'));\n            }\n            if (this._ownerWritableStream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('write to'));\n            }\n            return WritableStreamDefaultWriterWrite(this, chunk);\n        }\n    }\n    Object.defineProperties(WritableStreamDefaultWriter.prototype, {\n        abort: { enumerable: true },\n        close: { enumerable: true },\n        releaseLock: { enumerable: true },\n        write: { enumerable: true },\n        closed: { enumerable: true },\n        desiredSize: { enumerable: true },\n        ready: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStreamDefaultWriter.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStreamDefaultWriter',\n            configurable: true\n        });\n    }\n    // Abstract operations for the WritableStreamDefaultWriter.\n    function IsWritableStreamDefaultWriter(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_ownerWritableStream')) {\n            return false;\n        }\n        return x instanceof WritableStreamDefaultWriter;\n    }\n    // A client of WritableStreamDefaultWriter may use these functions directly to bypass state check.\n    function WritableStreamDefaultWriterAbort(writer, reason) {\n        const stream = writer._ownerWritableStream;\n        return WritableStreamAbort(stream, reason);\n    }\n    function WritableStreamDefaultWriterClose(writer) {\n        const stream = writer._ownerWritableStream;\n        return WritableStreamClose(stream);\n    }\n    function WritableStreamDefaultWriterCloseWithErrorPropagation(writer) {\n        const stream = writer._ownerWritableStream;\n        const state = stream._state;\n        if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n            return promiseResolvedWith(undefined);\n        }\n        if (state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        return WritableStreamDefaultWriterClose(writer);\n    }\n    function WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, error) {\n        if (writer._closedPromiseState === 'pending') {\n            defaultWriterClosedPromiseReject(writer, error);\n        }\n        else {\n            defaultWriterClosedPromiseResetToRejected(writer, error);\n        }\n    }\n    function WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, error) {\n        if (writer._readyPromiseState === 'pending') {\n            defaultWriterReadyPromiseReject(writer, error);\n        }\n        else {\n            defaultWriterReadyPromiseResetToRejected(writer, error);\n        }\n    }\n    function WritableStreamDefaultWriterGetDesiredSize(writer) {\n        const stream = writer._ownerWritableStream;\n        const state = stream._state;\n        if (state === 'errored' || state === 'erroring') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return WritableStreamDefaultControllerGetDesiredSize(stream._writableStreamController);\n    }\n    function WritableStreamDefaultWriterRelease(writer) {\n        const stream = writer._ownerWritableStream;\n        const releasedError = new TypeError(`Writer was released and can no longer be used to monitor the stream's closedness`);\n        WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, releasedError);\n        // The state transitions to \"errored\" before the sink abort() method runs, but the writer.closed promise is not\n        // rejected until afterwards. This means that simply testing state will not work.\n        WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, releasedError);\n        stream._writer = undefined;\n        writer._ownerWritableStream = undefined;\n    }\n    function WritableStreamDefaultWriterWrite(writer, chunk) {\n        const stream = writer._ownerWritableStream;\n        const controller = stream._writableStreamController;\n        const chunkSize = WritableStreamDefaultControllerGetChunkSize(controller, chunk);\n        if (stream !== writer._ownerWritableStream) {\n            return promiseRejectedWith(defaultWriterLockException('write to'));\n        }\n        const state = stream._state;\n        if (state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n            return promiseRejectedWith(new TypeError('The stream is closing or closed and cannot be written to'));\n        }\n        if (state === 'erroring') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        const promise = WritableStreamAddWriteRequest(stream);\n        WritableStreamDefaultControllerWrite(controller, chunk, chunkSize);\n        return promise;\n    }\n    const closeSentinel = {};\n    /**\n     * Allows control of a {@link WritableStream | writable stream}'s state and internal queue.\n     *\n     * @public\n     */\n    class WritableStreamDefaultController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * The reason which was passed to `WritableStream.abort(reason)` when the stream was aborted.\n         *\n         * @deprecated\n         *  This property has been removed from the specification, see https://github.com/whatwg/streams/pull/1177.\n         *  Use {@link WritableStreamDefaultController.signal}'s `reason` instead.\n         */\n        get abortReason() {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('abortReason');\n            }\n            return this._abortReason;\n        }\n        /**\n         * An `AbortSignal` that can be used to abort the pending write or close operation when the stream is aborted.\n         */\n        get signal() {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('signal');\n            }\n            if (this._abortController === undefined) {\n                // Older browsers or older Node versions may not support `AbortController` or `AbortSignal`.\n                // We don't want to bundle and ship an `AbortController` polyfill together with our polyfill,\n                // so instead we only implement support for `signal` if we find a global `AbortController` constructor.\n                throw new TypeError('WritableStreamDefaultController.prototype.signal is not supported');\n            }\n            return this._abortController.signal;\n        }\n        /**\n         * Closes the controlled writable stream, making all future interactions with it fail with the given error `e`.\n         *\n         * This method is rarely used, since usually it suffices to return a rejected promise from one of the underlying\n         * sink's methods. However, it can be useful for suddenly shutting down a stream in response to an event outside the\n         * normal lifecycle of interactions with the underlying sink.\n         */\n        error(e = undefined) {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('error');\n            }\n            const state = this._controlledWritableStream._state;\n            if (state !== 'writable') {\n                // The stream is closed, errored or will be soon. The sink can't do anything useful if it gets an error here, so\n                // just treat it as a no-op.\n                return;\n            }\n            WritableStreamDefaultControllerError(this, e);\n        }\n        /** @internal */\n        [AbortSteps](reason) {\n            const result = this._abortAlgorithm(reason);\n            WritableStreamDefaultControllerClearAlgorithms(this);\n            return result;\n        }\n        /** @internal */\n        [ErrorSteps]() {\n            ResetQueue(this);\n        }\n    }\n    Object.defineProperties(WritableStreamDefaultController.prototype, {\n        abortReason: { enumerable: true },\n        signal: { enumerable: true },\n        error: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Abstract operations implementing interface required by the WritableStream.\n    function IsWritableStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledWritableStream')) {\n            return false;\n        }\n        return x instanceof WritableStreamDefaultController;\n    }\n    function SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm) {\n        controller._controlledWritableStream = stream;\n        stream._writableStreamController = controller;\n        // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n        controller._queue = undefined;\n        controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._abortReason = undefined;\n        controller._abortController = createAbortController();\n        controller._started = false;\n        controller._strategySizeAlgorithm = sizeAlgorithm;\n        controller._strategyHWM = highWaterMark;\n        controller._writeAlgorithm = writeAlgorithm;\n        controller._closeAlgorithm = closeAlgorithm;\n        controller._abortAlgorithm = abortAlgorithm;\n        const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n        WritableStreamUpdateBackpressure(stream, backpressure);\n        const startResult = startAlgorithm();\n        const startPromise = promiseResolvedWith(startResult);\n        uponPromise(startPromise, () => {\n            controller._started = true;\n            WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n        }, r => {\n            controller._started = true;\n            WritableStreamDealWithRejection(stream, r);\n        });\n    }\n    function SetUpWritableStreamDefaultControllerFromUnderlyingSink(stream, underlyingSink, highWaterMark, sizeAlgorithm) {\n        const controller = Object.create(WritableStreamDefaultController.prototype);\n        let startAlgorithm = () => undefined;\n        let writeAlgorithm = () => promiseResolvedWith(undefined);\n        let closeAlgorithm = () => promiseResolvedWith(undefined);\n        let abortAlgorithm = () => promiseResolvedWith(undefined);\n        if (underlyingSink.start !== undefined) {\n            startAlgorithm = () => underlyingSink.start(controller);\n        }\n        if (underlyingSink.write !== undefined) {\n            writeAlgorithm = chunk => underlyingSink.write(chunk, controller);\n        }\n        if (underlyingSink.close !== undefined) {\n            closeAlgorithm = () => underlyingSink.close();\n        }\n        if (underlyingSink.abort !== undefined) {\n            abortAlgorithm = reason => underlyingSink.abort(reason);\n        }\n        SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm);\n    }\n    // ClearAlgorithms may be called twice. Erroring the same stream in multiple ways will often result in redundant calls.\n    function WritableStreamDefaultControllerClearAlgorithms(controller) {\n        controller._writeAlgorithm = undefined;\n        controller._closeAlgorithm = undefined;\n        controller._abortAlgorithm = undefined;\n        controller._strategySizeAlgorithm = undefined;\n    }\n    function WritableStreamDefaultControllerClose(controller) {\n        EnqueueValueWithSize(controller, closeSentinel, 0);\n        WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n    }\n    function WritableStreamDefaultControllerGetChunkSize(controller, chunk) {\n        try {\n            return controller._strategySizeAlgorithm(chunk);\n        }\n        catch (chunkSizeE) {\n            WritableStreamDefaultControllerErrorIfNeeded(controller, chunkSizeE);\n            return 1;\n        }\n    }\n    function WritableStreamDefaultControllerGetDesiredSize(controller) {\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    function WritableStreamDefaultControllerWrite(controller, chunk, chunkSize) {\n        try {\n            EnqueueValueWithSize(controller, chunk, chunkSize);\n        }\n        catch (enqueueE) {\n            WritableStreamDefaultControllerErrorIfNeeded(controller, enqueueE);\n            return;\n        }\n        const stream = controller._controlledWritableStream;\n        if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._state === 'writable') {\n            const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n            WritableStreamUpdateBackpressure(stream, backpressure);\n        }\n        WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n    }\n    // Abstract operations for the WritableStreamDefaultController.\n    function WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller) {\n        const stream = controller._controlledWritableStream;\n        if (!controller._started) {\n            return;\n        }\n        if (stream._inFlightWriteRequest !== undefined) {\n            return;\n        }\n        const state = stream._state;\n        if (state === 'erroring') {\n            WritableStreamFinishErroring(stream);\n            return;\n        }\n        if (controller._queue.length === 0) {\n            return;\n        }\n        const value = PeekQueueValue(controller);\n        if (value === closeSentinel) {\n            WritableStreamDefaultControllerProcessClose(controller);\n        }\n        else {\n            WritableStreamDefaultControllerProcessWrite(controller, value);\n        }\n    }\n    function WritableStreamDefaultControllerErrorIfNeeded(controller, error) {\n        if (controller._controlledWritableStream._state === 'writable') {\n            WritableStreamDefaultControllerError(controller, error);\n        }\n    }\n    function WritableStreamDefaultControllerProcessClose(controller) {\n        const stream = controller._controlledWritableStream;\n        WritableStreamMarkCloseRequestInFlight(stream);\n        DequeueValue(controller);\n        const sinkClosePromise = controller._closeAlgorithm();\n        WritableStreamDefaultControllerClearAlgorithms(controller);\n        uponPromise(sinkClosePromise, () => {\n            WritableStreamFinishInFlightClose(stream);\n        }, reason => {\n            WritableStreamFinishInFlightCloseWithError(stream, reason);\n        });\n    }\n    function WritableStreamDefaultControllerProcessWrite(controller, chunk) {\n        const stream = controller._controlledWritableStream;\n        WritableStreamMarkFirstWriteRequestInFlight(stream);\n        const sinkWritePromise = controller._writeAlgorithm(chunk);\n        uponPromise(sinkWritePromise, () => {\n            WritableStreamFinishInFlightWrite(stream);\n            const state = stream._state;\n            DequeueValue(controller);\n            if (!WritableStreamCloseQueuedOrInFlight(stream) && state === 'writable') {\n                const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n                WritableStreamUpdateBackpressure(stream, backpressure);\n            }\n            WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n        }, reason => {\n            if (stream._state === 'writable') {\n                WritableStreamDefaultControllerClearAlgorithms(controller);\n            }\n            WritableStreamFinishInFlightWriteWithError(stream, reason);\n        });\n    }\n    function WritableStreamDefaultControllerGetBackpressure(controller) {\n        const desiredSize = WritableStreamDefaultControllerGetDesiredSize(controller);\n        return desiredSize <= 0;\n    }\n    // A client of WritableStreamDefaultController may use these functions directly to bypass state check.\n    function WritableStreamDefaultControllerError(controller, error) {\n        const stream = controller._controlledWritableStream;\n        WritableStreamDefaultControllerClearAlgorithms(controller);\n        WritableStreamStartErroring(stream, error);\n    }\n    // Helper functions for the WritableStream.\n    function streamBrandCheckException$2(name) {\n        return new TypeError(`WritableStream.prototype.${name} can only be used on a WritableStream`);\n    }\n    // Helper functions for the WritableStreamDefaultController.\n    function defaultControllerBrandCheckException$2(name) {\n        return new TypeError(`WritableStreamDefaultController.prototype.${name} can only be used on a WritableStreamDefaultController`);\n    }\n    // Helper functions for the WritableStreamDefaultWriter.\n    function defaultWriterBrandCheckException(name) {\n        return new TypeError(`WritableStreamDefaultWriter.prototype.${name} can only be used on a WritableStreamDefaultWriter`);\n    }\n    function defaultWriterLockException(name) {\n        return new TypeError('Cannot ' + name + ' a stream using a released writer');\n    }\n    function defaultWriterClosedPromiseInitialize(writer) {\n        writer._closedPromise = newPromise((resolve, reject) => {\n            writer._closedPromise_resolve = resolve;\n            writer._closedPromise_reject = reject;\n            writer._closedPromiseState = 'pending';\n        });\n    }\n    function defaultWriterClosedPromiseInitializeAsRejected(writer, reason) {\n        defaultWriterClosedPromiseInitialize(writer);\n        defaultWriterClosedPromiseReject(writer, reason);\n    }\n    function defaultWriterClosedPromiseInitializeAsResolved(writer) {\n        defaultWriterClosedPromiseInitialize(writer);\n        defaultWriterClosedPromiseResolve(writer);\n    }\n    function defaultWriterClosedPromiseReject(writer, reason) {\n        if (writer._closedPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(writer._closedPromise);\n        writer._closedPromise_reject(reason);\n        writer._closedPromise_resolve = undefined;\n        writer._closedPromise_reject = undefined;\n        writer._closedPromiseState = 'rejected';\n    }\n    function defaultWriterClosedPromiseResetToRejected(writer, reason) {\n        defaultWriterClosedPromiseInitializeAsRejected(writer, reason);\n    }\n    function defaultWriterClosedPromiseResolve(writer) {\n        if (writer._closedPromise_resolve === undefined) {\n            return;\n        }\n        writer._closedPromise_resolve(undefined);\n        writer._closedPromise_resolve = undefined;\n        writer._closedPromise_reject = undefined;\n        writer._closedPromiseState = 'resolved';\n    }\n    function defaultWriterReadyPromiseInitialize(writer) {\n        writer._readyPromise = newPromise((resolve, reject) => {\n            writer._readyPromise_resolve = resolve;\n            writer._readyPromise_reject = reject;\n        });\n        writer._readyPromiseState = 'pending';\n    }\n    function defaultWriterReadyPromiseInitializeAsRejected(writer, reason) {\n        defaultWriterReadyPromiseInitialize(writer);\n        defaultWriterReadyPromiseReject(writer, reason);\n    }\n    function defaultWriterReadyPromiseInitializeAsResolved(writer) {\n        defaultWriterReadyPromiseInitialize(writer);\n        defaultWriterReadyPromiseResolve(writer);\n    }\n    function defaultWriterReadyPromiseReject(writer, reason) {\n        if (writer._readyPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(writer._readyPromise);\n        writer._readyPromise_reject(reason);\n        writer._readyPromise_resolve = undefined;\n        writer._readyPromise_reject = undefined;\n        writer._readyPromiseState = 'rejected';\n    }\n    function defaultWriterReadyPromiseReset(writer) {\n        defaultWriterReadyPromiseInitialize(writer);\n    }\n    function defaultWriterReadyPromiseResetToRejected(writer, reason) {\n        defaultWriterReadyPromiseInitializeAsRejected(writer, reason);\n    }\n    function defaultWriterReadyPromiseResolve(writer) {\n        if (writer._readyPromise_resolve === undefined) {\n            return;\n        }\n        writer._readyPromise_resolve(undefined);\n        writer._readyPromise_resolve = undefined;\n        writer._readyPromise_reject = undefined;\n        writer._readyPromiseState = 'fulfilled';\n    }\n\n    /// <reference lib=\"dom\" />\n    const NativeDOMException = typeof DOMException !== 'undefined' ? DOMException : undefined;\n\n    /// <reference types=\"node\" />\n    function isDOMExceptionConstructor(ctor) {\n        if (!(typeof ctor === 'function' || typeof ctor === 'object')) {\n            return false;\n        }\n        try {\n            new ctor();\n            return true;\n        }\n        catch (_a) {\n            return false;\n        }\n    }\n    function createDOMExceptionPolyfill() {\n        // eslint-disable-next-line no-shadow\n        const ctor = function DOMException(message, name) {\n            this.message = message || '';\n            this.name = name || 'Error';\n            if (Error.captureStackTrace) {\n                Error.captureStackTrace(this, this.constructor);\n            }\n        };\n        ctor.prototype = Object.create(Error.prototype);\n        Object.defineProperty(ctor.prototype, 'constructor', { value: ctor, writable: true, configurable: true });\n        return ctor;\n    }\n    // eslint-disable-next-line no-redeclare\n    const DOMException$1 = isDOMExceptionConstructor(NativeDOMException) ? NativeDOMException : createDOMExceptionPolyfill();\n\n    function ReadableStreamPipeTo(source, dest, preventClose, preventAbort, preventCancel, signal) {\n        const reader = AcquireReadableStreamDefaultReader(source);\n        const writer = AcquireWritableStreamDefaultWriter(dest);\n        source._disturbed = true;\n        let shuttingDown = false;\n        // This is used to keep track of the spec's requirement that we wait for ongoing writes during shutdown.\n        let currentWrite = promiseResolvedWith(undefined);\n        return newPromise((resolve, reject) => {\n            let abortAlgorithm;\n            if (signal !== undefined) {\n                abortAlgorithm = () => {\n                    const error = new DOMException$1('Aborted', 'AbortError');\n                    const actions = [];\n                    if (!preventAbort) {\n                        actions.push(() => {\n                            if (dest._state === 'writable') {\n                                return WritableStreamAbort(dest, error);\n                            }\n                            return promiseResolvedWith(undefined);\n                        });\n                    }\n                    if (!preventCancel) {\n                        actions.push(() => {\n                            if (source._state === 'readable') {\n                                return ReadableStreamCancel(source, error);\n                            }\n                            return promiseResolvedWith(undefined);\n                        });\n                    }\n                    shutdownWithAction(() => Promise.all(actions.map(action => action())), true, error);\n                };\n                if (signal.aborted) {\n                    abortAlgorithm();\n                    return;\n                }\n                signal.addEventListener('abort', abortAlgorithm);\n            }\n            // Using reader and writer, read all chunks from this and write them to dest\n            // - Backpressure must be enforced\n            // - Shutdown must stop all activity\n            function pipeLoop() {\n                return newPromise((resolveLoop, rejectLoop) => {\n                    function next(done) {\n                        if (done) {\n                            resolveLoop();\n                        }\n                        else {\n                            // Use `PerformPromiseThen` instead of `uponPromise` to avoid\n                            // adding unnecessary `.catch(rethrowAssertionErrorRejection)` handlers\n                            PerformPromiseThen(pipeStep(), next, rejectLoop);\n                        }\n                    }\n                    next(false);\n                });\n            }\n            function pipeStep() {\n                if (shuttingDown) {\n                    return promiseResolvedWith(true);\n                }\n                return PerformPromiseThen(writer._readyPromise, () => {\n                    return newPromise((resolveRead, rejectRead) => {\n                        ReadableStreamDefaultReaderRead(reader, {\n                            _chunkSteps: chunk => {\n                                currentWrite = PerformPromiseThen(WritableStreamDefaultWriterWrite(writer, chunk), undefined, noop);\n                                resolveRead(false);\n                            },\n                            _closeSteps: () => resolveRead(true),\n                            _errorSteps: rejectRead\n                        });\n                    });\n                });\n            }\n            // Errors must be propagated forward\n            isOrBecomesErrored(source, reader._closedPromise, storedError => {\n                if (!preventAbort) {\n                    shutdownWithAction(() => WritableStreamAbort(dest, storedError), true, storedError);\n                }\n                else {\n                    shutdown(true, storedError);\n                }\n            });\n            // Errors must be propagated backward\n            isOrBecomesErrored(dest, writer._closedPromise, storedError => {\n                if (!preventCancel) {\n                    shutdownWithAction(() => ReadableStreamCancel(source, storedError), true, storedError);\n                }\n                else {\n                    shutdown(true, storedError);\n                }\n            });\n            // Closing must be propagated forward\n            isOrBecomesClosed(source, reader._closedPromise, () => {\n                if (!preventClose) {\n                    shutdownWithAction(() => WritableStreamDefaultWriterCloseWithErrorPropagation(writer));\n                }\n                else {\n                    shutdown();\n                }\n            });\n            // Closing must be propagated backward\n            if (WritableStreamCloseQueuedOrInFlight(dest) || dest._state === 'closed') {\n                const destClosed = new TypeError('the destination writable stream closed before all data could be piped to it');\n                if (!preventCancel) {\n                    shutdownWithAction(() => ReadableStreamCancel(source, destClosed), true, destClosed);\n                }\n                else {\n                    shutdown(true, destClosed);\n                }\n            }\n            setPromiseIsHandledToTrue(pipeLoop());\n            function waitForWritesToFinish() {\n                // Another write may have started while we were waiting on this currentWrite, so we have to be sure to wait\n                // for that too.\n                const oldCurrentWrite = currentWrite;\n                return PerformPromiseThen(currentWrite, () => oldCurrentWrite !== currentWrite ? waitForWritesToFinish() : undefined);\n            }\n            function isOrBecomesErrored(stream, promise, action) {\n                if (stream._state === 'errored') {\n                    action(stream._storedError);\n                }\n                else {\n                    uponRejection(promise, action);\n                }\n            }\n            function isOrBecomesClosed(stream, promise, action) {\n                if (stream._state === 'closed') {\n                    action();\n                }\n                else {\n                    uponFulfillment(promise, action);\n                }\n            }\n            function shutdownWithAction(action, originalIsError, originalError) {\n                if (shuttingDown) {\n                    return;\n                }\n                shuttingDown = true;\n                if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n                    uponFulfillment(waitForWritesToFinish(), doTheRest);\n                }\n                else {\n                    doTheRest();\n                }\n                function doTheRest() {\n                    uponPromise(action(), () => finalize(originalIsError, originalError), newError => finalize(true, newError));\n                }\n            }\n            function shutdown(isError, error) {\n                if (shuttingDown) {\n                    return;\n                }\n                shuttingDown = true;\n                if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n                    uponFulfillment(waitForWritesToFinish(), () => finalize(isError, error));\n                }\n                else {\n                    finalize(isError, error);\n                }\n            }\n            function finalize(isError, error) {\n                WritableStreamDefaultWriterRelease(writer);\n                ReadableStreamReaderGenericRelease(reader);\n                if (signal !== undefined) {\n                    signal.removeEventListener('abort', abortAlgorithm);\n                }\n                if (isError) {\n                    reject(error);\n                }\n                else {\n                    resolve(undefined);\n                }\n            }\n        });\n    }\n\n    /**\n     * Allows control of a {@link ReadableStream | readable stream}'s state and internal queue.\n     *\n     * @public\n     */\n    class ReadableStreamDefaultController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n         * over-full. An underlying source ought to use this information to determine when and how to apply backpressure.\n         */\n        get desiredSize() {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('desiredSize');\n            }\n            return ReadableStreamDefaultControllerGetDesiredSize(this);\n        }\n        /**\n         * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n         * the stream, but once those are read, the stream will become closed.\n         */\n        close() {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('close');\n            }\n            if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n                throw new TypeError('The stream is not in a state that permits close');\n            }\n            ReadableStreamDefaultControllerClose(this);\n        }\n        enqueue(chunk = undefined) {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('enqueue');\n            }\n            if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n                throw new TypeError('The stream is not in a state that permits enqueue');\n            }\n            return ReadableStreamDefaultControllerEnqueue(this, chunk);\n        }\n        /**\n         * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n         */\n        error(e = undefined) {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('error');\n            }\n            ReadableStreamDefaultControllerError(this, e);\n        }\n        /** @internal */\n        [CancelSteps](reason) {\n            ResetQueue(this);\n            const result = this._cancelAlgorithm(reason);\n            ReadableStreamDefaultControllerClearAlgorithms(this);\n            return result;\n        }\n        /** @internal */\n        [PullSteps](readRequest) {\n            const stream = this._controlledReadableStream;\n            if (this._queue.length > 0) {\n                const chunk = DequeueValue(this);\n                if (this._closeRequested && this._queue.length === 0) {\n                    ReadableStreamDefaultControllerClearAlgorithms(this);\n                    ReadableStreamClose(stream);\n                }\n                else {\n                    ReadableStreamDefaultControllerCallPullIfNeeded(this);\n                }\n                readRequest._chunkSteps(chunk);\n            }\n            else {\n                ReadableStreamAddReadRequest(stream, readRequest);\n                ReadableStreamDefaultControllerCallPullIfNeeded(this);\n            }\n        }\n    }\n    Object.defineProperties(ReadableStreamDefaultController.prototype, {\n        close: { enumerable: true },\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableStreamDefaultController.\n    function IsReadableStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableStream')) {\n            return false;\n        }\n        return x instanceof ReadableStreamDefaultController;\n    }\n    function ReadableStreamDefaultControllerCallPullIfNeeded(controller) {\n        const shouldPull = ReadableStreamDefaultControllerShouldCallPull(controller);\n        if (!shouldPull) {\n            return;\n        }\n        if (controller._pulling) {\n            controller._pullAgain = true;\n            return;\n        }\n        controller._pulling = true;\n        const pullPromise = controller._pullAlgorithm();\n        uponPromise(pullPromise, () => {\n            controller._pulling = false;\n            if (controller._pullAgain) {\n                controller._pullAgain = false;\n                ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n            }\n        }, e => {\n            ReadableStreamDefaultControllerError(controller, e);\n        });\n    }\n    function ReadableStreamDefaultControllerShouldCallPull(controller) {\n        const stream = controller._controlledReadableStream;\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return false;\n        }\n        if (!controller._started) {\n            return false;\n        }\n        if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            return true;\n        }\n        const desiredSize = ReadableStreamDefaultControllerGetDesiredSize(controller);\n        if (desiredSize > 0) {\n            return true;\n        }\n        return false;\n    }\n    function ReadableStreamDefaultControllerClearAlgorithms(controller) {\n        controller._pullAlgorithm = undefined;\n        controller._cancelAlgorithm = undefined;\n        controller._strategySizeAlgorithm = undefined;\n    }\n    // A client of ReadableStreamDefaultController may use these functions directly to bypass state check.\n    function ReadableStreamDefaultControllerClose(controller) {\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return;\n        }\n        const stream = controller._controlledReadableStream;\n        controller._closeRequested = true;\n        if (controller._queue.length === 0) {\n            ReadableStreamDefaultControllerClearAlgorithms(controller);\n            ReadableStreamClose(stream);\n        }\n    }\n    function ReadableStreamDefaultControllerEnqueue(controller, chunk) {\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return;\n        }\n        const stream = controller._controlledReadableStream;\n        if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            ReadableStreamFulfillReadRequest(stream, chunk, false);\n        }\n        else {\n            let chunkSize;\n            try {\n                chunkSize = controller._strategySizeAlgorithm(chunk);\n            }\n            catch (chunkSizeE) {\n                ReadableStreamDefaultControllerError(controller, chunkSizeE);\n                throw chunkSizeE;\n            }\n            try {\n                EnqueueValueWithSize(controller, chunk, chunkSize);\n            }\n            catch (enqueueE) {\n                ReadableStreamDefaultControllerError(controller, enqueueE);\n                throw enqueueE;\n            }\n        }\n        ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n    }\n    function ReadableStreamDefaultControllerError(controller, e) {\n        const stream = controller._controlledReadableStream;\n        if (stream._state !== 'readable') {\n            return;\n        }\n        ResetQueue(controller);\n        ReadableStreamDefaultControllerClearAlgorithms(controller);\n        ReadableStreamError(stream, e);\n    }\n    function ReadableStreamDefaultControllerGetDesiredSize(controller) {\n        const state = controller._controlledReadableStream._state;\n        if (state === 'errored') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    // This is used in the implementation of TransformStream.\n    function ReadableStreamDefaultControllerHasBackpressure(controller) {\n        if (ReadableStreamDefaultControllerShouldCallPull(controller)) {\n            return false;\n        }\n        return true;\n    }\n    function ReadableStreamDefaultControllerCanCloseOrEnqueue(controller) {\n        const state = controller._controlledReadableStream._state;\n        if (!controller._closeRequested && state === 'readable') {\n            return true;\n        }\n        return false;\n    }\n    function SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm) {\n        controller._controlledReadableStream = stream;\n        controller._queue = undefined;\n        controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._started = false;\n        controller._closeRequested = false;\n        controller._pullAgain = false;\n        controller._pulling = false;\n        controller._strategySizeAlgorithm = sizeAlgorithm;\n        controller._strategyHWM = highWaterMark;\n        controller._pullAlgorithm = pullAlgorithm;\n        controller._cancelAlgorithm = cancelAlgorithm;\n        stream._readableStreamController = controller;\n        const startResult = startAlgorithm();\n        uponPromise(promiseResolvedWith(startResult), () => {\n            controller._started = true;\n            ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n        }, r => {\n            ReadableStreamDefaultControllerError(controller, r);\n        });\n    }\n    function SetUpReadableStreamDefaultControllerFromUnderlyingSource(stream, underlyingSource, highWaterMark, sizeAlgorithm) {\n        const controller = Object.create(ReadableStreamDefaultController.prototype);\n        let startAlgorithm = () => undefined;\n        let pullAlgorithm = () => promiseResolvedWith(undefined);\n        let cancelAlgorithm = () => promiseResolvedWith(undefined);\n        if (underlyingSource.start !== undefined) {\n            startAlgorithm = () => underlyingSource.start(controller);\n        }\n        if (underlyingSource.pull !== undefined) {\n            pullAlgorithm = () => underlyingSource.pull(controller);\n        }\n        if (underlyingSource.cancel !== undefined) {\n            cancelAlgorithm = reason => underlyingSource.cancel(reason);\n        }\n        SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm);\n    }\n    // Helper functions for the ReadableStreamDefaultController.\n    function defaultControllerBrandCheckException$1(name) {\n        return new TypeError(`ReadableStreamDefaultController.prototype.${name} can only be used on a ReadableStreamDefaultController`);\n    }\n\n    function ReadableStreamTee(stream, cloneForBranch2) {\n        if (IsReadableByteStreamController(stream._readableStreamController)) {\n            return ReadableByteStreamTee(stream);\n        }\n        return ReadableStreamDefaultTee(stream);\n    }\n    function ReadableStreamDefaultTee(stream, cloneForBranch2) {\n        const reader = AcquireReadableStreamDefaultReader(stream);\n        let reading = false;\n        let readAgain = false;\n        let canceled1 = false;\n        let canceled2 = false;\n        let reason1;\n        let reason2;\n        let branch1;\n        let branch2;\n        let resolveCancelPromise;\n        const cancelPromise = newPromise(resolve => {\n            resolveCancelPromise = resolve;\n        });\n        function pullAlgorithm() {\n            if (reading) {\n                readAgain = true;\n                return promiseResolvedWith(undefined);\n            }\n            reading = true;\n            const readRequest = {\n                _chunkSteps: chunk => {\n                    // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                    // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                    // successful synchronously-available reads get ahead of asynchronously-available errors.\n                    queueMicrotask(() => {\n                        readAgain = false;\n                        const chunk1 = chunk;\n                        const chunk2 = chunk;\n                        // There is no way to access the cloning code right now in the reference implementation.\n                        // If we add one then we'll need an implementation for serializable objects.\n                        // if (!canceled2 && cloneForBranch2) {\n                        //   chunk2 = StructuredDeserialize(StructuredSerialize(chunk2));\n                        // }\n                        if (!canceled1) {\n                            ReadableStreamDefaultControllerEnqueue(branch1._readableStreamController, chunk1);\n                        }\n                        if (!canceled2) {\n                            ReadableStreamDefaultControllerEnqueue(branch2._readableStreamController, chunk2);\n                        }\n                        reading = false;\n                        if (readAgain) {\n                            pullAlgorithm();\n                        }\n                    });\n                },\n                _closeSteps: () => {\n                    reading = false;\n                    if (!canceled1) {\n                        ReadableStreamDefaultControllerClose(branch1._readableStreamController);\n                    }\n                    if (!canceled2) {\n                        ReadableStreamDefaultControllerClose(branch2._readableStreamController);\n                    }\n                    if (!canceled1 || !canceled2) {\n                        resolveCancelPromise(undefined);\n                    }\n                },\n                _errorSteps: () => {\n                    reading = false;\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n            return promiseResolvedWith(undefined);\n        }\n        function cancel1Algorithm(reason) {\n            canceled1 = true;\n            reason1 = reason;\n            if (canceled2) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function cancel2Algorithm(reason) {\n            canceled2 = true;\n            reason2 = reason;\n            if (canceled1) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function startAlgorithm() {\n            // do nothing\n        }\n        branch1 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel1Algorithm);\n        branch2 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel2Algorithm);\n        uponRejection(reader._closedPromise, (r) => {\n            ReadableStreamDefaultControllerError(branch1._readableStreamController, r);\n            ReadableStreamDefaultControllerError(branch2._readableStreamController, r);\n            if (!canceled1 || !canceled2) {\n                resolveCancelPromise(undefined);\n            }\n        });\n        return [branch1, branch2];\n    }\n    function ReadableByteStreamTee(stream) {\n        let reader = AcquireReadableStreamDefaultReader(stream);\n        let reading = false;\n        let readAgainForBranch1 = false;\n        let readAgainForBranch2 = false;\n        let canceled1 = false;\n        let canceled2 = false;\n        let reason1;\n        let reason2;\n        let branch1;\n        let branch2;\n        let resolveCancelPromise;\n        const cancelPromise = newPromise(resolve => {\n            resolveCancelPromise = resolve;\n        });\n        function forwardReaderError(thisReader) {\n            uponRejection(thisReader._closedPromise, r => {\n                if (thisReader !== reader) {\n                    return;\n                }\n                ReadableByteStreamControllerError(branch1._readableStreamController, r);\n                ReadableByteStreamControllerError(branch2._readableStreamController, r);\n                if (!canceled1 || !canceled2) {\n                    resolveCancelPromise(undefined);\n                }\n            });\n        }\n        function pullWithDefaultReader() {\n            if (IsReadableStreamBYOBReader(reader)) {\n                ReadableStreamReaderGenericRelease(reader);\n                reader = AcquireReadableStreamDefaultReader(stream);\n                forwardReaderError(reader);\n            }\n            const readRequest = {\n                _chunkSteps: chunk => {\n                    // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                    // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                    // successful synchronously-available reads get ahead of asynchronously-available errors.\n                    queueMicrotask(() => {\n                        readAgainForBranch1 = false;\n                        readAgainForBranch2 = false;\n                        const chunk1 = chunk;\n                        let chunk2 = chunk;\n                        if (!canceled1 && !canceled2) {\n                            try {\n                                chunk2 = CloneAsUint8Array(chunk);\n                            }\n                            catch (cloneE) {\n                                ReadableByteStreamControllerError(branch1._readableStreamController, cloneE);\n                                ReadableByteStreamControllerError(branch2._readableStreamController, cloneE);\n                                resolveCancelPromise(ReadableStreamCancel(stream, cloneE));\n                                return;\n                            }\n                        }\n                        if (!canceled1) {\n                            ReadableByteStreamControllerEnqueue(branch1._readableStreamController, chunk1);\n                        }\n                        if (!canceled2) {\n                            ReadableByteStreamControllerEnqueue(branch2._readableStreamController, chunk2);\n                        }\n                        reading = false;\n                        if (readAgainForBranch1) {\n                            pull1Algorithm();\n                        }\n                        else if (readAgainForBranch2) {\n                            pull2Algorithm();\n                        }\n                    });\n                },\n                _closeSteps: () => {\n                    reading = false;\n                    if (!canceled1) {\n                        ReadableByteStreamControllerClose(branch1._readableStreamController);\n                    }\n                    if (!canceled2) {\n                        ReadableByteStreamControllerClose(branch2._readableStreamController);\n                    }\n                    if (branch1._readableStreamController._pendingPullIntos.length > 0) {\n                        ReadableByteStreamControllerRespond(branch1._readableStreamController, 0);\n                    }\n                    if (branch2._readableStreamController._pendingPullIntos.length > 0) {\n                        ReadableByteStreamControllerRespond(branch2._readableStreamController, 0);\n                    }\n                    if (!canceled1 || !canceled2) {\n                        resolveCancelPromise(undefined);\n                    }\n                },\n                _errorSteps: () => {\n                    reading = false;\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n        }\n        function pullWithBYOBReader(view, forBranch2) {\n            if (IsReadableStreamDefaultReader(reader)) {\n                ReadableStreamReaderGenericRelease(reader);\n                reader = AcquireReadableStreamBYOBReader(stream);\n                forwardReaderError(reader);\n            }\n            const byobBranch = forBranch2 ? branch2 : branch1;\n            const otherBranch = forBranch2 ? branch1 : branch2;\n            const readIntoRequest = {\n                _chunkSteps: chunk => {\n                    // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                    // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                    // successful synchronously-available reads get ahead of asynchronously-available errors.\n                    queueMicrotask(() => {\n                        readAgainForBranch1 = false;\n                        readAgainForBranch2 = false;\n                        const byobCanceled = forBranch2 ? canceled2 : canceled1;\n                        const otherCanceled = forBranch2 ? canceled1 : canceled2;\n                        if (!otherCanceled) {\n                            let clonedChunk;\n                            try {\n                                clonedChunk = CloneAsUint8Array(chunk);\n                            }\n                            catch (cloneE) {\n                                ReadableByteStreamControllerError(byobBranch._readableStreamController, cloneE);\n                                ReadableByteStreamControllerError(otherBranch._readableStreamController, cloneE);\n                                resolveCancelPromise(ReadableStreamCancel(stream, cloneE));\n                                return;\n                            }\n                            if (!byobCanceled) {\n                                ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                            }\n                            ReadableByteStreamControllerEnqueue(otherBranch._readableStreamController, clonedChunk);\n                        }\n                        else if (!byobCanceled) {\n                            ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                        }\n                        reading = false;\n                        if (readAgainForBranch1) {\n                            pull1Algorithm();\n                        }\n                        else if (readAgainForBranch2) {\n                            pull2Algorithm();\n                        }\n                    });\n                },\n                _closeSteps: chunk => {\n                    reading = false;\n                    const byobCanceled = forBranch2 ? canceled2 : canceled1;\n                    const otherCanceled = forBranch2 ? canceled1 : canceled2;\n                    if (!byobCanceled) {\n                        ReadableByteStreamControllerClose(byobBranch._readableStreamController);\n                    }\n                    if (!otherCanceled) {\n                        ReadableByteStreamControllerClose(otherBranch._readableStreamController);\n                    }\n                    if (chunk !== undefined) {\n                        if (!byobCanceled) {\n                            ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                        }\n                        if (!otherCanceled && otherBranch._readableStreamController._pendingPullIntos.length > 0) {\n                            ReadableByteStreamControllerRespond(otherBranch._readableStreamController, 0);\n                        }\n                    }\n                    if (!byobCanceled || !otherCanceled) {\n                        resolveCancelPromise(undefined);\n                    }\n                },\n                _errorSteps: () => {\n                    reading = false;\n                }\n            };\n            ReadableStreamBYOBReaderRead(reader, view, readIntoRequest);\n        }\n        function pull1Algorithm() {\n            if (reading) {\n                readAgainForBranch1 = true;\n                return promiseResolvedWith(undefined);\n            }\n            reading = true;\n            const byobRequest = ReadableByteStreamControllerGetBYOBRequest(branch1._readableStreamController);\n            if (byobRequest === null) {\n                pullWithDefaultReader();\n            }\n            else {\n                pullWithBYOBReader(byobRequest._view, false);\n            }\n            return promiseResolvedWith(undefined);\n        }\n        function pull2Algorithm() {\n            if (reading) {\n                readAgainForBranch2 = true;\n                return promiseResolvedWith(undefined);\n            }\n            reading = true;\n            const byobRequest = ReadableByteStreamControllerGetBYOBRequest(branch2._readableStreamController);\n            if (byobRequest === null) {\n                pullWithDefaultReader();\n            }\n            else {\n                pullWithBYOBReader(byobRequest._view, true);\n            }\n            return promiseResolvedWith(undefined);\n        }\n        function cancel1Algorithm(reason) {\n            canceled1 = true;\n            reason1 = reason;\n            if (canceled2) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function cancel2Algorithm(reason) {\n            canceled2 = true;\n            reason2 = reason;\n            if (canceled1) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function startAlgorithm() {\n            return;\n        }\n        branch1 = CreateReadableByteStream(startAlgorithm, pull1Algorithm, cancel1Algorithm);\n        branch2 = CreateReadableByteStream(startAlgorithm, pull2Algorithm, cancel2Algorithm);\n        forwardReaderError(reader);\n        return [branch1, branch2];\n    }\n\n    function convertUnderlyingDefaultOrByteSource(source, context) {\n        assertDictionary(source, context);\n        const original = source;\n        const autoAllocateChunkSize = original === null || original === void 0 ? void 0 : original.autoAllocateChunkSize;\n        const cancel = original === null || original === void 0 ? void 0 : original.cancel;\n        const pull = original === null || original === void 0 ? void 0 : original.pull;\n        const start = original === null || original === void 0 ? void 0 : original.start;\n        const type = original === null || original === void 0 ? void 0 : original.type;\n        return {\n            autoAllocateChunkSize: autoAllocateChunkSize === undefined ?\n                undefined :\n                convertUnsignedLongLongWithEnforceRange(autoAllocateChunkSize, `${context} has member 'autoAllocateChunkSize' that`),\n            cancel: cancel === undefined ?\n                undefined :\n                convertUnderlyingSourceCancelCallback(cancel, original, `${context} has member 'cancel' that`),\n            pull: pull === undefined ?\n                undefined :\n                convertUnderlyingSourcePullCallback(pull, original, `${context} has member 'pull' that`),\n            start: start === undefined ?\n                undefined :\n                convertUnderlyingSourceStartCallback(start, original, `${context} has member 'start' that`),\n            type: type === undefined ? undefined : convertReadableStreamType(type, `${context} has member 'type' that`)\n        };\n    }\n    function convertUnderlyingSourceCancelCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (reason) => promiseCall(fn, original, [reason]);\n    }\n    function convertUnderlyingSourcePullCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => promiseCall(fn, original, [controller]);\n    }\n    function convertUnderlyingSourceStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => reflectCall(fn, original, [controller]);\n    }\n    function convertReadableStreamType(type, context) {\n        type = `${type}`;\n        if (type !== 'bytes') {\n            throw new TypeError(`${context} '${type}' is not a valid enumeration value for ReadableStreamType`);\n        }\n        return type;\n    }\n\n    function convertReaderOptions(options, context) {\n        assertDictionary(options, context);\n        const mode = options === null || options === void 0 ? void 0 : options.mode;\n        return {\n            mode: mode === undefined ? undefined : convertReadableStreamReaderMode(mode, `${context} has member 'mode' that`)\n        };\n    }\n    function convertReadableStreamReaderMode(mode, context) {\n        mode = `${mode}`;\n        if (mode !== 'byob') {\n            throw new TypeError(`${context} '${mode}' is not a valid enumeration value for ReadableStreamReaderMode`);\n        }\n        return mode;\n    }\n\n    function convertIteratorOptions(options, context) {\n        assertDictionary(options, context);\n        const preventCancel = options === null || options === void 0 ? void 0 : options.preventCancel;\n        return { preventCancel: Boolean(preventCancel) };\n    }\n\n    function convertPipeOptions(options, context) {\n        assertDictionary(options, context);\n        const preventAbort = options === null || options === void 0 ? void 0 : options.preventAbort;\n        const preventCancel = options === null || options === void 0 ? void 0 : options.preventCancel;\n        const preventClose = options === null || options === void 0 ? void 0 : options.preventClose;\n        const signal = options === null || options === void 0 ? void 0 : options.signal;\n        if (signal !== undefined) {\n            assertAbortSignal(signal, `${context} has member 'signal' that`);\n        }\n        return {\n            preventAbort: Boolean(preventAbort),\n            preventCancel: Boolean(preventCancel),\n            preventClose: Boolean(preventClose),\n            signal\n        };\n    }\n    function assertAbortSignal(signal, context) {\n        if (!isAbortSignal(signal)) {\n            throw new TypeError(`${context} is not an AbortSignal.`);\n        }\n    }\n\n    function convertReadableWritablePair(pair, context) {\n        assertDictionary(pair, context);\n        const readable = pair === null || pair === void 0 ? void 0 : pair.readable;\n        assertRequiredField(readable, 'readable', 'ReadableWritablePair');\n        assertReadableStream(readable, `${context} has member 'readable' that`);\n        const writable = pair === null || pair === void 0 ? void 0 : pair.writable;\n        assertRequiredField(writable, 'writable', 'ReadableWritablePair');\n        assertWritableStream(writable, `${context} has member 'writable' that`);\n        return { readable, writable };\n    }\n\n    /**\n     * A readable stream represents a source of data, from which you can read.\n     *\n     * @public\n     */\n    class ReadableStream {\n        constructor(rawUnderlyingSource = {}, rawStrategy = {}) {\n            if (rawUnderlyingSource === undefined) {\n                rawUnderlyingSource = null;\n            }\n            else {\n                assertObject(rawUnderlyingSource, 'First parameter');\n            }\n            const strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n            const underlyingSource = convertUnderlyingDefaultOrByteSource(rawUnderlyingSource, 'First parameter');\n            InitializeReadableStream(this);\n            if (underlyingSource.type === 'bytes') {\n                if (strategy.size !== undefined) {\n                    throw new RangeError('The strategy for a byte stream cannot have a size function');\n                }\n                const highWaterMark = ExtractHighWaterMark(strategy, 0);\n                SetUpReadableByteStreamControllerFromUnderlyingSource(this, underlyingSource, highWaterMark);\n            }\n            else {\n                const sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n                const highWaterMark = ExtractHighWaterMark(strategy, 1);\n                SetUpReadableStreamDefaultControllerFromUnderlyingSource(this, underlyingSource, highWaterMark, sizeAlgorithm);\n            }\n        }\n        /**\n         * Whether or not the readable stream is locked to a {@link ReadableStreamDefaultReader | reader}.\n         */\n        get locked() {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('locked');\n            }\n            return IsReadableStreamLocked(this);\n        }\n        /**\n         * Cancels the stream, signaling a loss of interest in the stream by a consumer.\n         *\n         * The supplied `reason` argument will be given to the underlying source's {@link UnderlyingSource.cancel | cancel()}\n         * method, which might or might not use it.\n         */\n        cancel(reason = undefined) {\n            if (!IsReadableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$1('cancel'));\n            }\n            if (IsReadableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot cancel a stream that already has a reader'));\n            }\n            return ReadableStreamCancel(this, reason);\n        }\n        getReader(rawOptions = undefined) {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('getReader');\n            }\n            const options = convertReaderOptions(rawOptions, 'First parameter');\n            if (options.mode === undefined) {\n                return AcquireReadableStreamDefaultReader(this);\n            }\n            return AcquireReadableStreamBYOBReader(this);\n        }\n        pipeThrough(rawTransform, rawOptions = {}) {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('pipeThrough');\n            }\n            assertRequiredArgument(rawTransform, 1, 'pipeThrough');\n            const transform = convertReadableWritablePair(rawTransform, 'First parameter');\n            const options = convertPipeOptions(rawOptions, 'Second parameter');\n            if (IsReadableStreamLocked(this)) {\n                throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked ReadableStream');\n            }\n            if (IsWritableStreamLocked(transform.writable)) {\n                throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked WritableStream');\n            }\n            const promise = ReadableStreamPipeTo(this, transform.writable, options.preventClose, options.preventAbort, options.preventCancel, options.signal);\n            setPromiseIsHandledToTrue(promise);\n            return transform.readable;\n        }\n        pipeTo(destination, rawOptions = {}) {\n            if (!IsReadableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$1('pipeTo'));\n            }\n            if (destination === undefined) {\n                return promiseRejectedWith(`Parameter 1 is required in 'pipeTo'.`);\n            }\n            if (!IsWritableStream(destination)) {\n                return promiseRejectedWith(new TypeError(`ReadableStream.prototype.pipeTo's first argument must be a WritableStream`));\n            }\n            let options;\n            try {\n                options = convertPipeOptions(rawOptions, 'Second parameter');\n            }\n            catch (e) {\n                return promiseRejectedWith(e);\n            }\n            if (IsReadableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked ReadableStream'));\n            }\n            if (IsWritableStreamLocked(destination)) {\n                return promiseRejectedWith(new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked WritableStream'));\n            }\n            return ReadableStreamPipeTo(this, destination, options.preventClose, options.preventAbort, options.preventCancel, options.signal);\n        }\n        /**\n         * Tees this readable stream, returning a two-element array containing the two resulting branches as\n         * new {@link ReadableStream} instances.\n         *\n         * Teeing a stream will lock it, preventing any other consumer from acquiring a reader.\n         * To cancel the stream, cancel both of the resulting branches; a composite cancellation reason will then be\n         * propagated to the stream's underlying source.\n         *\n         * Note that the chunks seen in each branch will be the same object. If the chunks are not immutable,\n         * this could allow interference between the two branches.\n         */\n        tee() {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('tee');\n            }\n            const branches = ReadableStreamTee(this);\n            return CreateArrayFromList(branches);\n        }\n        values(rawOptions = undefined) {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('values');\n            }\n            const options = convertIteratorOptions(rawOptions, 'First parameter');\n            return AcquireReadableStreamAsyncIterator(this, options.preventCancel);\n        }\n    }\n    Object.defineProperties(ReadableStream.prototype, {\n        cancel: { enumerable: true },\n        getReader: { enumerable: true },\n        pipeThrough: { enumerable: true },\n        pipeTo: { enumerable: true },\n        tee: { enumerable: true },\n        values: { enumerable: true },\n        locked: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStream',\n            configurable: true\n        });\n    }\n    if (typeof SymbolPolyfill.asyncIterator === 'symbol') {\n        Object.defineProperty(ReadableStream.prototype, SymbolPolyfill.asyncIterator, {\n            value: ReadableStream.prototype.values,\n            writable: true,\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableStream.\n    // Throws if and only if startAlgorithm throws.\n    function CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark = 1, sizeAlgorithm = () => 1) {\n        const stream = Object.create(ReadableStream.prototype);\n        InitializeReadableStream(stream);\n        const controller = Object.create(ReadableStreamDefaultController.prototype);\n        SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm);\n        return stream;\n    }\n    // Throws if and only if startAlgorithm throws.\n    function CreateReadableByteStream(startAlgorithm, pullAlgorithm, cancelAlgorithm) {\n        const stream = Object.create(ReadableStream.prototype);\n        InitializeReadableStream(stream);\n        const controller = Object.create(ReadableByteStreamController.prototype);\n        SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, 0, undefined);\n        return stream;\n    }\n    function InitializeReadableStream(stream) {\n        stream._state = 'readable';\n        stream._reader = undefined;\n        stream._storedError = undefined;\n        stream._disturbed = false;\n    }\n    function IsReadableStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readableStreamController')) {\n            return false;\n        }\n        return x instanceof ReadableStream;\n    }\n    function IsReadableStreamLocked(stream) {\n        if (stream._reader === undefined) {\n            return false;\n        }\n        return true;\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamCancel(stream, reason) {\n        stream._disturbed = true;\n        if (stream._state === 'closed') {\n            return promiseResolvedWith(undefined);\n        }\n        if (stream._state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        ReadableStreamClose(stream);\n        const reader = stream._reader;\n        if (reader !== undefined && IsReadableStreamBYOBReader(reader)) {\n            reader._readIntoRequests.forEach(readIntoRequest => {\n                readIntoRequest._closeSteps(undefined);\n            });\n            reader._readIntoRequests = new SimpleQueue();\n        }\n        const sourceCancelPromise = stream._readableStreamController[CancelSteps](reason);\n        return transformPromiseWith(sourceCancelPromise, noop);\n    }\n    function ReadableStreamClose(stream) {\n        stream._state = 'closed';\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return;\n        }\n        defaultReaderClosedPromiseResolve(reader);\n        if (IsReadableStreamDefaultReader(reader)) {\n            reader._readRequests.forEach(readRequest => {\n                readRequest._closeSteps();\n            });\n            reader._readRequests = new SimpleQueue();\n        }\n    }\n    function ReadableStreamError(stream, e) {\n        stream._state = 'errored';\n        stream._storedError = e;\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return;\n        }\n        defaultReaderClosedPromiseReject(reader, e);\n        if (IsReadableStreamDefaultReader(reader)) {\n            reader._readRequests.forEach(readRequest => {\n                readRequest._errorSteps(e);\n            });\n            reader._readRequests = new SimpleQueue();\n        }\n        else {\n            reader._readIntoRequests.forEach(readIntoRequest => {\n                readIntoRequest._errorSteps(e);\n            });\n            reader._readIntoRequests = new SimpleQueue();\n        }\n    }\n    // Helper functions for the ReadableStream.\n    function streamBrandCheckException$1(name) {\n        return new TypeError(`ReadableStream.prototype.${name} can only be used on a ReadableStream`);\n    }\n\n    function convertQueuingStrategyInit(init, context) {\n        assertDictionary(init, context);\n        const highWaterMark = init === null || init === void 0 ? void 0 : init.highWaterMark;\n        assertRequiredField(highWaterMark, 'highWaterMark', 'QueuingStrategyInit');\n        return {\n            highWaterMark: convertUnrestrictedDouble(highWaterMark)\n        };\n    }\n\n    // The size function must not have a prototype property nor be a constructor\n    const byteLengthSizeFunction = (chunk) => {\n        return chunk.byteLength;\n    };\n    Object.defineProperty(byteLengthSizeFunction, 'name', {\n        value: 'size',\n        configurable: true\n    });\n    /**\n     * A queuing strategy that counts the number of bytes in each chunk.\n     *\n     * @public\n     */\n    class ByteLengthQueuingStrategy {\n        constructor(options) {\n            assertRequiredArgument(options, 1, 'ByteLengthQueuingStrategy');\n            options = convertQueuingStrategyInit(options, 'First parameter');\n            this._byteLengthQueuingStrategyHighWaterMark = options.highWaterMark;\n        }\n        /**\n         * Returns the high water mark provided to the constructor.\n         */\n        get highWaterMark() {\n            if (!IsByteLengthQueuingStrategy(this)) {\n                throw byteLengthBrandCheckException('highWaterMark');\n            }\n            return this._byteLengthQueuingStrategyHighWaterMark;\n        }\n        /**\n         * Measures the size of `chunk` by returning the value of its `byteLength` property.\n         */\n        get size() {\n            if (!IsByteLengthQueuingStrategy(this)) {\n                throw byteLengthBrandCheckException('size');\n            }\n            return byteLengthSizeFunction;\n        }\n    }\n    Object.defineProperties(ByteLengthQueuingStrategy.prototype, {\n        highWaterMark: { enumerable: true },\n        size: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ByteLengthQueuingStrategy.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ByteLengthQueuingStrategy',\n            configurable: true\n        });\n    }\n    // Helper functions for the ByteLengthQueuingStrategy.\n    function byteLengthBrandCheckException(name) {\n        return new TypeError(`ByteLengthQueuingStrategy.prototype.${name} can only be used on a ByteLengthQueuingStrategy`);\n    }\n    function IsByteLengthQueuingStrategy(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_byteLengthQueuingStrategyHighWaterMark')) {\n            return false;\n        }\n        return x instanceof ByteLengthQueuingStrategy;\n    }\n\n    // The size function must not have a prototype property nor be a constructor\n    const countSizeFunction = () => {\n        return 1;\n    };\n    Object.defineProperty(countSizeFunction, 'name', {\n        value: 'size',\n        configurable: true\n    });\n    /**\n     * A queuing strategy that counts the number of chunks.\n     *\n     * @public\n     */\n    class CountQueuingStrategy {\n        constructor(options) {\n            assertRequiredArgument(options, 1, 'CountQueuingStrategy');\n            options = convertQueuingStrategyInit(options, 'First parameter');\n            this._countQueuingStrategyHighWaterMark = options.highWaterMark;\n        }\n        /**\n         * Returns the high water mark provided to the constructor.\n         */\n        get highWaterMark() {\n            if (!IsCountQueuingStrategy(this)) {\n                throw countBrandCheckException('highWaterMark');\n            }\n            return this._countQueuingStrategyHighWaterMark;\n        }\n        /**\n         * Measures the size of `chunk` by always returning 1.\n         * This ensures that the total queue size is a count of the number of chunks in the queue.\n         */\n        get size() {\n            if (!IsCountQueuingStrategy(this)) {\n                throw countBrandCheckException('size');\n            }\n            return countSizeFunction;\n        }\n    }\n    Object.defineProperties(CountQueuingStrategy.prototype, {\n        highWaterMark: { enumerable: true },\n        size: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(CountQueuingStrategy.prototype, SymbolPolyfill.toStringTag, {\n            value: 'CountQueuingStrategy',\n            configurable: true\n        });\n    }\n    // Helper functions for the CountQueuingStrategy.\n    function countBrandCheckException(name) {\n        return new TypeError(`CountQueuingStrategy.prototype.${name} can only be used on a CountQueuingStrategy`);\n    }\n    function IsCountQueuingStrategy(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_countQueuingStrategyHighWaterMark')) {\n            return false;\n        }\n        return x instanceof CountQueuingStrategy;\n    }\n\n    function convertTransformer(original, context) {\n        assertDictionary(original, context);\n        const flush = original === null || original === void 0 ? void 0 : original.flush;\n        const readableType = original === null || original === void 0 ? void 0 : original.readableType;\n        const start = original === null || original === void 0 ? void 0 : original.start;\n        const transform = original === null || original === void 0 ? void 0 : original.transform;\n        const writableType = original === null || original === void 0 ? void 0 : original.writableType;\n        return {\n            flush: flush === undefined ?\n                undefined :\n                convertTransformerFlushCallback(flush, original, `${context} has member 'flush' that`),\n            readableType,\n            start: start === undefined ?\n                undefined :\n                convertTransformerStartCallback(start, original, `${context} has member 'start' that`),\n            transform: transform === undefined ?\n                undefined :\n                convertTransformerTransformCallback(transform, original, `${context} has member 'transform' that`),\n            writableType\n        };\n    }\n    function convertTransformerFlushCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => promiseCall(fn, original, [controller]);\n    }\n    function convertTransformerStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => reflectCall(fn, original, [controller]);\n    }\n    function convertTransformerTransformCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (chunk, controller) => promiseCall(fn, original, [chunk, controller]);\n    }\n\n    // Class TransformStream\n    /**\n     * A transform stream consists of a pair of streams: a {@link WritableStream | writable stream},\n     * known as its writable side, and a {@link ReadableStream | readable stream}, known as its readable side.\n     * In a manner specific to the transform stream in question, writes to the writable side result in new data being\n     * made available for reading from the readable side.\n     *\n     * @public\n     */\n    class TransformStream {\n        constructor(rawTransformer = {}, rawWritableStrategy = {}, rawReadableStrategy = {}) {\n            if (rawTransformer === undefined) {\n                rawTransformer = null;\n            }\n            const writableStrategy = convertQueuingStrategy(rawWritableStrategy, 'Second parameter');\n            const readableStrategy = convertQueuingStrategy(rawReadableStrategy, 'Third parameter');\n            const transformer = convertTransformer(rawTransformer, 'First parameter');\n            if (transformer.readableType !== undefined) {\n                throw new RangeError('Invalid readableType specified');\n            }\n            if (transformer.writableType !== undefined) {\n                throw new RangeError('Invalid writableType specified');\n            }\n            const readableHighWaterMark = ExtractHighWaterMark(readableStrategy, 0);\n            const readableSizeAlgorithm = ExtractSizeAlgorithm(readableStrategy);\n            const writableHighWaterMark = ExtractHighWaterMark(writableStrategy, 1);\n            const writableSizeAlgorithm = ExtractSizeAlgorithm(writableStrategy);\n            let startPromise_resolve;\n            const startPromise = newPromise(resolve => {\n                startPromise_resolve = resolve;\n            });\n            InitializeTransformStream(this, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm);\n            SetUpTransformStreamDefaultControllerFromTransformer(this, transformer);\n            if (transformer.start !== undefined) {\n                startPromise_resolve(transformer.start(this._transformStreamController));\n            }\n            else {\n                startPromise_resolve(undefined);\n            }\n        }\n        /**\n         * The readable side of the transform stream.\n         */\n        get readable() {\n            if (!IsTransformStream(this)) {\n                throw streamBrandCheckException('readable');\n            }\n            return this._readable;\n        }\n        /**\n         * The writable side of the transform stream.\n         */\n        get writable() {\n            if (!IsTransformStream(this)) {\n                throw streamBrandCheckException('writable');\n            }\n            return this._writable;\n        }\n    }\n    Object.defineProperties(TransformStream.prototype, {\n        readable: { enumerable: true },\n        writable: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(TransformStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'TransformStream',\n            configurable: true\n        });\n    }\n    function InitializeTransformStream(stream, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm) {\n        function startAlgorithm() {\n            return startPromise;\n        }\n        function writeAlgorithm(chunk) {\n            return TransformStreamDefaultSinkWriteAlgorithm(stream, chunk);\n        }\n        function abortAlgorithm(reason) {\n            return TransformStreamDefaultSinkAbortAlgorithm(stream, reason);\n        }\n        function closeAlgorithm() {\n            return TransformStreamDefaultSinkCloseAlgorithm(stream);\n        }\n        stream._writable = CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, writableHighWaterMark, writableSizeAlgorithm);\n        function pullAlgorithm() {\n            return TransformStreamDefaultSourcePullAlgorithm(stream);\n        }\n        function cancelAlgorithm(reason) {\n            TransformStreamErrorWritableAndUnblockWrite(stream, reason);\n            return promiseResolvedWith(undefined);\n        }\n        stream._readable = CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, readableHighWaterMark, readableSizeAlgorithm);\n        // The [[backpressure]] slot is set to undefined so that it can be initialised by TransformStreamSetBackpressure.\n        stream._backpressure = undefined;\n        stream._backpressureChangePromise = undefined;\n        stream._backpressureChangePromise_resolve = undefined;\n        TransformStreamSetBackpressure(stream, true);\n        stream._transformStreamController = undefined;\n    }\n    function IsTransformStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_transformStreamController')) {\n            return false;\n        }\n        return x instanceof TransformStream;\n    }\n    // This is a no-op if both sides are already errored.\n    function TransformStreamError(stream, e) {\n        ReadableStreamDefaultControllerError(stream._readable._readableStreamController, e);\n        TransformStreamErrorWritableAndUnblockWrite(stream, e);\n    }\n    function TransformStreamErrorWritableAndUnblockWrite(stream, e) {\n        TransformStreamDefaultControllerClearAlgorithms(stream._transformStreamController);\n        WritableStreamDefaultControllerErrorIfNeeded(stream._writable._writableStreamController, e);\n        if (stream._backpressure) {\n            // Pretend that pull() was called to permit any pending write() calls to complete. TransformStreamSetBackpressure()\n            // cannot be called from enqueue() or pull() once the ReadableStream is errored, so this will will be the final time\n            // _backpressure is set.\n            TransformStreamSetBackpressure(stream, false);\n        }\n    }\n    function TransformStreamSetBackpressure(stream, backpressure) {\n        // Passes also when called during construction.\n        if (stream._backpressureChangePromise !== undefined) {\n            stream._backpressureChangePromise_resolve();\n        }\n        stream._backpressureChangePromise = newPromise(resolve => {\n            stream._backpressureChangePromise_resolve = resolve;\n        });\n        stream._backpressure = backpressure;\n    }\n    // Class TransformStreamDefaultController\n    /**\n     * Allows control of the {@link ReadableStream} and {@link WritableStream} of the associated {@link TransformStream}.\n     *\n     * @public\n     */\n    class TransformStreamDefaultController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the desired size to fill the readable side’s internal queue. It can be negative, if the queue is over-full.\n         */\n        get desiredSize() {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('desiredSize');\n            }\n            const readableController = this._controlledTransformStream._readable._readableStreamController;\n            return ReadableStreamDefaultControllerGetDesiredSize(readableController);\n        }\n        enqueue(chunk = undefined) {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('enqueue');\n            }\n            TransformStreamDefaultControllerEnqueue(this, chunk);\n        }\n        /**\n         * Errors both the readable side and the writable side of the controlled transform stream, making all future\n         * interactions with it fail with the given error `e`. Any chunks queued for transformation will be discarded.\n         */\n        error(reason = undefined) {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('error');\n            }\n            TransformStreamDefaultControllerError(this, reason);\n        }\n        /**\n         * Closes the readable side and errors the writable side of the controlled transform stream. This is useful when the\n         * transformer only needs to consume a portion of the chunks written to the writable side.\n         */\n        terminate() {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('terminate');\n            }\n            TransformStreamDefaultControllerTerminate(this);\n        }\n    }\n    Object.defineProperties(TransformStreamDefaultController.prototype, {\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        terminate: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(TransformStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'TransformStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Transform Stream Default Controller Abstract Operations\n    function IsTransformStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledTransformStream')) {\n            return false;\n        }\n        return x instanceof TransformStreamDefaultController;\n    }\n    function SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm) {\n        controller._controlledTransformStream = stream;\n        stream._transformStreamController = controller;\n        controller._transformAlgorithm = transformAlgorithm;\n        controller._flushAlgorithm = flushAlgorithm;\n    }\n    function SetUpTransformStreamDefaultControllerFromTransformer(stream, transformer) {\n        const controller = Object.create(TransformStreamDefaultController.prototype);\n        let transformAlgorithm = (chunk) => {\n            try {\n                TransformStreamDefaultControllerEnqueue(controller, chunk);\n                return promiseResolvedWith(undefined);\n            }\n            catch (transformResultE) {\n                return promiseRejectedWith(transformResultE);\n            }\n        };\n        let flushAlgorithm = () => promiseResolvedWith(undefined);\n        if (transformer.transform !== undefined) {\n            transformAlgorithm = chunk => transformer.transform(chunk, controller);\n        }\n        if (transformer.flush !== undefined) {\n            flushAlgorithm = () => transformer.flush(controller);\n        }\n        SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm);\n    }\n    function TransformStreamDefaultControllerClearAlgorithms(controller) {\n        controller._transformAlgorithm = undefined;\n        controller._flushAlgorithm = undefined;\n    }\n    function TransformStreamDefaultControllerEnqueue(controller, chunk) {\n        const stream = controller._controlledTransformStream;\n        const readableController = stream._readable._readableStreamController;\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(readableController)) {\n            throw new TypeError('Readable side is not in a state that permits enqueue');\n        }\n        // We throttle transform invocations based on the backpressure of the ReadableStream, but we still\n        // accept TransformStreamDefaultControllerEnqueue() calls.\n        try {\n            ReadableStreamDefaultControllerEnqueue(readableController, chunk);\n        }\n        catch (e) {\n            // This happens when readableStrategy.size() throws.\n            TransformStreamErrorWritableAndUnblockWrite(stream, e);\n            throw stream._readable._storedError;\n        }\n        const backpressure = ReadableStreamDefaultControllerHasBackpressure(readableController);\n        if (backpressure !== stream._backpressure) {\n            TransformStreamSetBackpressure(stream, true);\n        }\n    }\n    function TransformStreamDefaultControllerError(controller, e) {\n        TransformStreamError(controller._controlledTransformStream, e);\n    }\n    function TransformStreamDefaultControllerPerformTransform(controller, chunk) {\n        const transformPromise = controller._transformAlgorithm(chunk);\n        return transformPromiseWith(transformPromise, undefined, r => {\n            TransformStreamError(controller._controlledTransformStream, r);\n            throw r;\n        });\n    }\n    function TransformStreamDefaultControllerTerminate(controller) {\n        const stream = controller._controlledTransformStream;\n        const readableController = stream._readable._readableStreamController;\n        ReadableStreamDefaultControllerClose(readableController);\n        const error = new TypeError('TransformStream terminated');\n        TransformStreamErrorWritableAndUnblockWrite(stream, error);\n    }\n    // TransformStreamDefaultSink Algorithms\n    function TransformStreamDefaultSinkWriteAlgorithm(stream, chunk) {\n        const controller = stream._transformStreamController;\n        if (stream._backpressure) {\n            const backpressureChangePromise = stream._backpressureChangePromise;\n            return transformPromiseWith(backpressureChangePromise, () => {\n                const writable = stream._writable;\n                const state = writable._state;\n                if (state === 'erroring') {\n                    throw writable._storedError;\n                }\n                return TransformStreamDefaultControllerPerformTransform(controller, chunk);\n            });\n        }\n        return TransformStreamDefaultControllerPerformTransform(controller, chunk);\n    }\n    function TransformStreamDefaultSinkAbortAlgorithm(stream, reason) {\n        // abort() is not called synchronously, so it is possible for abort() to be called when the stream is already\n        // errored.\n        TransformStreamError(stream, reason);\n        return promiseResolvedWith(undefined);\n    }\n    function TransformStreamDefaultSinkCloseAlgorithm(stream) {\n        // stream._readable cannot change after construction, so caching it across a call to user code is safe.\n        const readable = stream._readable;\n        const controller = stream._transformStreamController;\n        const flushPromise = controller._flushAlgorithm();\n        TransformStreamDefaultControllerClearAlgorithms(controller);\n        // Return a promise that is fulfilled with undefined on success.\n        return transformPromiseWith(flushPromise, () => {\n            if (readable._state === 'errored') {\n                throw readable._storedError;\n            }\n            ReadableStreamDefaultControllerClose(readable._readableStreamController);\n        }, r => {\n            TransformStreamError(stream, r);\n            throw readable._storedError;\n        });\n    }\n    // TransformStreamDefaultSource Algorithms\n    function TransformStreamDefaultSourcePullAlgorithm(stream) {\n        // Invariant. Enforced by the promises returned by start() and pull().\n        TransformStreamSetBackpressure(stream, false);\n        // Prevent the next pull() call until there is backpressure.\n        return stream._backpressureChangePromise;\n    }\n    // Helper functions for the TransformStreamDefaultController.\n    function defaultControllerBrandCheckException(name) {\n        return new TypeError(`TransformStreamDefaultController.prototype.${name} can only be used on a TransformStreamDefaultController`);\n    }\n    // Helper functions for the TransformStream.\n    function streamBrandCheckException(name) {\n        return new TypeError(`TransformStream.prototype.${name} can only be used on a TransformStream`);\n    }\n\n    exports.ByteLengthQueuingStrategy = ByteLengthQueuingStrategy;\n    exports.CountQueuingStrategy = CountQueuingStrategy;\n    exports.ReadableByteStreamController = ReadableByteStreamController;\n    exports.ReadableStream = ReadableStream;\n    exports.ReadableStreamBYOBReader = ReadableStreamBYOBReader;\n    exports.ReadableStreamBYOBRequest = ReadableStreamBYOBRequest;\n    exports.ReadableStreamDefaultController = ReadableStreamDefaultController;\n    exports.ReadableStreamDefaultReader = ReadableStreamDefaultReader;\n    exports.TransformStream = TransformStream;\n    exports.TransformStreamDefaultController = TransformStreamDefaultController;\n    exports.WritableStream = WritableStream;\n    exports.WritableStreamDefaultController = WritableStreamDefaultController;\n    exports.WritableStreamDefaultWriter = WritableStreamDefaultWriter;\n\n    Object.defineProperty(exports, '__esModule', { value: true });\n\n})));\n//# sourceMappingURL=ponyfill.es2018.js.map\n","'use strict'\nmodule.exports = function (Yallist) {\n  Yallist.prototype[Symbol.iterator] = function* () {\n    for (let walker = this.head; walker; walker = walker.next) {\n      yield walker.value\n    }\n  }\n}\n","'use strict'\nmodule.exports = Yallist\n\nYallist.Node = Node\nYallist.create = Yallist\n\nfunction Yallist (list) {\n  var self = this\n  if (!(self instanceof Yallist)) {\n    self = new Yallist()\n  }\n\n  self.tail = null\n  self.head = null\n  self.length = 0\n\n  if (list && typeof list.forEach === 'function') {\n    list.forEach(function (item) {\n      self.push(item)\n    })\n  } else if (arguments.length > 0) {\n    for (var i = 0, l = arguments.length; i < l; i++) {\n      self.push(arguments[i])\n    }\n  }\n\n  return self\n}\n\nYallist.prototype.removeNode = function (node) {\n  if (node.list !== this) {\n    throw new Error('removing node which does not belong to this list')\n  }\n\n  var next = node.next\n  var prev = node.prev\n\n  if (next) {\n    next.prev = prev\n  }\n\n  if (prev) {\n    prev.next = next\n  }\n\n  if (node === this.head) {\n    this.head = next\n  }\n  if (node === this.tail) {\n    this.tail = prev\n  }\n\n  node.list.length--\n  node.next = null\n  node.prev = null\n  node.list = null\n\n  return next\n}\n\nYallist.prototype.unshiftNode = function (node) {\n  if (node === this.head) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var head = this.head\n  node.list = this\n  node.next = head\n  if (head) {\n    head.prev = node\n  }\n\n  this.head = node\n  if (!this.tail) {\n    this.tail = node\n  }\n  this.length++\n}\n\nYallist.prototype.pushNode = function (node) {\n  if (node === this.tail) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var tail = this.tail\n  node.list = this\n  node.prev = tail\n  if (tail) {\n    tail.next = node\n  }\n\n  this.tail = node\n  if (!this.head) {\n    this.head = node\n  }\n  this.length++\n}\n\nYallist.prototype.push = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    push(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.unshift = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    unshift(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.pop = function () {\n  if (!this.tail) {\n    return undefined\n  }\n\n  var res = this.tail.value\n  this.tail = this.tail.prev\n  if (this.tail) {\n    this.tail.next = null\n  } else {\n    this.head = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.shift = function () {\n  if (!this.head) {\n    return undefined\n  }\n\n  var res = this.head.value\n  this.head = this.head.next\n  if (this.head) {\n    this.head.prev = null\n  } else {\n    this.tail = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.forEach = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.head, i = 0; walker !== null; i++) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.next\n  }\n}\n\nYallist.prototype.forEachReverse = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.tail, i = this.length - 1; walker !== null; i--) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.prev\n  }\n}\n\nYallist.prototype.get = function (n) {\n  for (var i = 0, walker = this.head; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.next\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.getReverse = function (n) {\n  for (var i = 0, walker = this.tail; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.prev\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.map = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.head; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.next\n  }\n  return res\n}\n\nYallist.prototype.mapReverse = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.tail; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.prev\n  }\n  return res\n}\n\nYallist.prototype.reduce = function (fn, initial) {\n  var acc\n  var walker = this.head\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.head) {\n    walker = this.head.next\n    acc = this.head.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = 0; walker !== null; i++) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.next\n  }\n\n  return acc\n}\n\nYallist.prototype.reduceReverse = function (fn, initial) {\n  var acc\n  var walker = this.tail\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.tail) {\n    walker = this.tail.prev\n    acc = this.tail.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = this.length - 1; walker !== null; i--) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.prev\n  }\n\n  return acc\n}\n\nYallist.prototype.toArray = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.head; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.next\n  }\n  return arr\n}\n\nYallist.prototype.toArrayReverse = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.tail; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.prev\n  }\n  return arr\n}\n\nYallist.prototype.slice = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = 0, walker = this.head; walker !== null && i < from; i++) {\n    walker = walker.next\n  }\n  for (; walker !== null && i < to; i++, walker = walker.next) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.sliceReverse = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = this.length, walker = this.tail; walker !== null && i > to; i--) {\n    walker = walker.prev\n  }\n  for (; walker !== null && i > from; i--, walker = walker.prev) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.splice = function (start, deleteCount, ...nodes) {\n  if (start > this.length) {\n    start = this.length - 1\n  }\n  if (start < 0) {\n    start = this.length + start;\n  }\n\n  for (var i = 0, walker = this.head; walker !== null && i < start; i++) {\n    walker = walker.next\n  }\n\n  var ret = []\n  for (var i = 0; walker && i < deleteCount; i++) {\n    ret.push(walker.value)\n    walker = this.removeNode(walker)\n  }\n  if (walker === null) {\n    walker = this.tail\n  }\n\n  if (walker !== this.head && walker !== this.tail) {\n    walker = walker.prev\n  }\n\n  for (var i = 0; i < nodes.length; i++) {\n    walker = insert(this, walker, nodes[i])\n  }\n  return ret;\n}\n\nYallist.prototype.reverse = function () {\n  var head = this.head\n  var tail = this.tail\n  for (var walker = head; walker !== null; walker = walker.prev) {\n    var p = walker.prev\n    walker.prev = walker.next\n    walker.next = p\n  }\n  this.head = tail\n  this.tail = head\n  return this\n}\n\nfunction insert (self, node, value) {\n  var inserted = node === self.head ?\n    new Node(value, null, node, self) :\n    new Node(value, node, node.next, self)\n\n  if (inserted.next === null) {\n    self.tail = inserted\n  }\n  if (inserted.prev === null) {\n    self.head = inserted\n  }\n\n  self.length++\n\n  return inserted\n}\n\nfunction push (self, item) {\n  self.tail = new Node(item, self.tail, null, self)\n  if (!self.head) {\n    self.head = self.tail\n  }\n  self.length++\n}\n\nfunction unshift (self, item) {\n  self.head = new Node(item, null, self.head, self)\n  if (!self.tail) {\n    self.tail = self.head\n  }\n  self.length++\n}\n\nfunction Node (value, prev, next, list) {\n  if (!(this instanceof Node)) {\n    return new Node(value, prev, next, list)\n  }\n\n  this.list = list\n  this.value = value\n\n  if (prev) {\n    prev.next = this\n    this.prev = prev\n  } else {\n    this.prev = null\n  }\n\n  if (next) {\n    next.prev = this\n    this.next = next\n  } else {\n    this.next = null\n  }\n}\n\ntry {\n  // add if support for Symbol.iterator is present\n  require('./iterator.js')(Yallist)\n} catch (er) {}\n","/* c8 ignore start */\n// 64 KiB (same size chrome slice theirs blob into Uint8array's)\nconst POOL_SIZE = 65536\n\nif (!globalThis.ReadableStream) {\n  // `node:stream/web` got introduced in v16.5.0 as experimental\n  // and it's preferred over the polyfilled version. So we also\n  // suppress the warning that gets emitted by NodeJS for using it.\n  try {\n    const process = require('node:process')\n    const { emitWarning } = process\n    try {\n      process.emitWarning = () => {}\n      Object.assign(globalThis, require('node:stream/web'))\n      process.emitWarning = emitWarning\n    } catch (error) {\n      process.emitWarning = emitWarning\n      throw error\n    }\n  } catch (error) {\n    // fallback to polyfill implementation\n    Object.assign(globalThis, require('web-streams-polyfill/dist/ponyfill.es2018.js'))\n  }\n}\n\ntry {\n  // Don't use node: prefix for this, require+node: is not supported until node v14.14\n  // Only `import()` can use prefix in 12.20 and later\n  const { Blob } = require('buffer')\n  if (Blob && !Blob.prototype.stream) {\n    Blob.prototype.stream = function name (params) {\n      let position = 0\n      const blob = this\n\n      return new ReadableStream({\n        type: 'bytes',\n        async pull (ctrl) {\n          const chunk = blob.slice(position, Math.min(blob.size, position + POOL_SIZE))\n          const buffer = await chunk.arrayBuffer()\n          position += buffer.byteLength\n          ctrl.enqueue(new Uint8Array(buffer))\n\n          if (position === blob.size) {\n            ctrl.close()\n          }\n        }\n      })\n    }\n  }\n} catch (error) {}\n/* c8 ignore end */\n","module.exports = require(\"assert\");","module.exports = require(\"buffer\");","module.exports = require(\"crypto\");","module.exports = require(\"events\");","module.exports = require(\"fs\");","module.exports = require(\"fs/promises\");","module.exports = require(\"http\");","module.exports = require(\"https\");","module.exports = require(\"net\");","module.exports = require(\"node:process\");","module.exports = require(\"node:stream/web\");","module.exports = require(\"os\");","module.exports = require(\"path\");","module.exports = require(\"stream\");","module.exports = require(\"string_decoder\");","module.exports = require(\"tls\");","module.exports = require(\"util\");","module.exports = require(\"worker_threads\");","module.exports = require(\"zlib\");","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar threw = true;\n\ttry {\n\t\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\t\tthrew = false;\n\t} finally {\n\t\tif(threw) delete __webpack_module_cache__[moduleId];\n\t}\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = (chunkId) => {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks\n__webpack_require__.u = (chunkId) => {\n\t// return url for filenames based on template\n\treturn \"\" + chunkId + \".index.js\";\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","\nif (typeof __webpack_require__ !== 'undefined') __webpack_require__.ab = __dirname + \"/\";","// no baseURI\n\n// object to store loaded chunks\n// \"1\" means \"loaded\", otherwise not loaded yet\nvar installedChunks = {\n\t179: 1\n};\n\n// no on chunks loaded\n\nvar installChunk = (chunk) => {\n\tvar moreModules = chunk.modules, chunkIds = chunk.ids, runtime = chunk.runtime;\n\tfor(var moduleId in moreModules) {\n\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t}\n\t}\n\tif(runtime) runtime(__webpack_require__);\n\tfor(var i = 0; i < chunkIds.length; i++)\n\t\tinstalledChunks[chunkIds[i]] = 1;\n\n};\n\n// require() chunk loading for javascript\n__webpack_require__.f.require = (chunkId, promises) => {\n\t// \"1\" is the signal for \"already loaded\"\n\tif(!installedChunks[chunkId]) {\n\t\tif(true) { // all chunks have JS\n\t\t\tinstallChunk(require(\"./\" + __webpack_require__.u(chunkId)));\n\t\t} else installedChunks[chunkId] = 1;\n\t}\n};\n\n// no external install chunk\n\n// no HMR\n\n// no HMR manifest","// startup\n// Load entry module and return exports\n// This entry module is referenced by other modules so it can't be inlined\nvar __webpack_exports__ = __webpack_require__(3109);\n"],"mappings":";;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACp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vTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACzDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxhBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;;;;;;ACtKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;;;;;;;;;;;;;;;AChDA;;ACAA;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;;;;;;;;ACzPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACraA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC/iBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC3VA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACfA;;ACAA;;ACAA;;ACAA;;ACAA;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpDA;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC5YA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC1QA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC5IA;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACRA;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACn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zZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC/RA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACt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heA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC9NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC52BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC5gBA;;;A;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACvQA;AACA;AACA;AACA;AACA;AACA,KACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxm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zaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClDA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACRA;AACA;AACA;AACA;AACA;;;;;ACJA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACNA;AACA;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACrCA;AACA;AACA;AACA;;;;A","sourceRoot":""}